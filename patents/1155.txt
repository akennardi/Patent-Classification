                                       ABSTRACT
A system and method for a vehicle mounted camera that provides an image that adjusts in
response to at least one vehicle mounted sensor.

WO 2014/159868                                  PCT/US2014/025362
                             3/12
                                                   20
                Receiving Image Data from a
                     Vehicle Mounted Camera
                Receiving Data from at least
                 one Vehicle Mounted Sensor         24
                     Adjusting Image Horizon     -    26
               Utilizing the Data Received from
                       at least one Vehicle
                          Mounted Sensor
                             FIG. 3

    WO 2014/159868                                                          PCT/US2014/025362
       SYSTEM AND METHOD FOR ADJUSTING AN IMAGE FOR A VEHICLE
                                      MOUNTED CAMERA
CROSS-REFERENCE TO RELATED APPLICATIONS
[0001] This application claims the benefit of U.S. provisional patent application serial
number 61/778,641 filed March 13, 2013, which is a continuation-in-part of U.S. Patent
Application Serial No. 13/567,323, filed August 6, 2012 and claims priority to U.S. Patent
Application Serial Nos. 61/515,549, filed August 5, 20011 and 61/563,126, filed November
23, 2011, the entire contents of which are incorporated herein by reference.
TECHNICAL FIELD
[0002] The present invention is generally related to vehicle mounted cameras. More
particularly, example embodiments of the present invention are related systems and methods
for adjusting an image, e.g., an image horizon, for a vehicle mounted camera.
BACKGROUND OF THE INVENTION
[0003] Vehicle mounted cameras are utilized in a variety of applications, from personal use
to record street or track or flight performance to professional use in racecars.
[0004] Referring to Prior Art Figures 1 and 2, a traditional camera image in NASCAR is
illustrated generally at 10, with Figures 1 and 2 illustrating a fixed image horizon (note
virtual image horizon line 12 provided across the image to show the fixed perspective of the
image) relative to the hood 14 of the racecar between a straightaway and a turn. However,
this virtual line 12 shows a change in horizon relative to the sky 16 due to a change in angle
of the track.
[0005] What is needed in the art is a system and method that permits adjustment of an image
from a vehicle mounted camera in a desired fashion.
SUMMARY OF THE INVENTION
                                                 1

    WO 2014/159868                                                            PCT/US2014/025362
[0006] The present system and method for adjusting an image for a vehicle mounted camera
overcomes and alleviates the problems and disadvantages in the prior art by providing an
adjustable image that adjusts in response to at least one vehicle mounted sensor.
[0007] In exemplary embodiments, telemetry of a vehicle from a plurality of sensors may be
used to automatically adjust an image, e.g. an image horizon, in a desired way.
[0008] In other exemplary embodiments, data from at least one sensor is used to
automatically adjust an image horizon to match a skyline horizon during tilting of a vehicle,
for example as a racecar banks around a turn off of a straightaway.
[0009] In other exemplary embodiments, both image horizon and zoom are automatically
adjusted during tilting of a vehicle.
[0010] In exemplary embodiments, such image horizon adjustment may be provided as a
digital video effect, alleviating the need to actually adjust the angle of a camera during
vehicle tilt.
[0011] The above and other exemplary embodiments will be discussed in more detail below
in the detailed description of the invention.
BRIEF DESCRIPTION OF THE DRAWINGS
[0012] Many aspects of the invention can be better understood with reference to the
following drawings. The components in the drawings are not necessarily to scale, emphasis
instead being placed upon clearly illustrating the principles of the present invention.
Moreover, in the drawings, like reference numerals designate corresponding parts throughout
the several views. In the FIGURES:
[0013] PRIOR ART FIGURE 1 is a view of a racecar camera image with a fixed image
horizon on a racetrack straightaway;
[0014] PRIOR ART FIGURE 2 is a view of the racecar camera image with a fixed image
horizon on a banked turn of a racetrack;
[0015] FIGURE 3 is a flowchart of an exemplary method for adjusting the image horizon of
a vehicle mounted camera;
[0016] FIGURE 4 is a view of a racecar camera image with an adjustable image horizon on a
racetrack straightaway;
                                                  2

    WO 2014/159868                                                         PCT/US2014/025362
[0017] FIGURE 5 is a view of a racecar camera image with an adjusted image horizon on a
racetrack turn with zoom remaining constant;
[0018] FIGURE 6 is a view of a racecar camera image with an adjustable image horizon on a
racetrack straightaway;
[0019] FIGURE 7 is a view of a racecar camera image with an adjusted image horizon on a
racetrack turn adjusted zoom;
[0020] FIGURE 8 is an exemplary system for adjusting image for a vehicle mounted camera;
[0021] PRIOR ART FIGURE 9 is a diagram comparing relative pixel dimensions of high
definition and greater than high definition images;
[0022] FIGURE 10 is an exemplary graphical user interface of a 4K captured image with a
720p selectable extraction window;
[0023] FIGURE 11 is an exemplary first system for capturing and transporting a 4K image to
an offsite processor and graphical user interface; and
[0024] FIGURE 12 is an exemplary second system for capturing and processing a 4K image
onsite, followed by transport of a high definition image offsite.
DETAILED DESCRIPTION OF THE INVENTION
[0025] Further to the brief description provided above and associated textual detail of each of
the FIGURES, the following description provides additional details of example embodiments
of the present invention. It should be understood, however, that there is no intent to limit
example embodiments to the particular forms and particular details disclosed, but to the
contrary, example embodiments are to cover all modifications, equivalents, and alternatives
falling within the scope of example embodiments and claims. Like numbers refer to like
elements throughout the description of the FIGURES.
[0026] It will be understood that, although the terms first, second, etc. may be used herein to
describe various steps or calculations, these steps or calculations should not be limited by
these terms. These terms are only used to distinguish one step or calculation from another.
For example, a first calculation could be termed a second calculation, and, similarly, a second
step could be termed a first step, without departing from the scope of this disclosure. As used
                                                 3

    WO 2014/159868                                                            PCT/US2014/025362
herein, the term "and/or" includes any and all combinations of one or more of the associated
listed items.
[0027] As used herein, the singular forms "a", "an" and "the" are intended to include the
plural forms as well, unless the context clearly indicates otherwise. It will be further
understood that the terms "comprises", "comprising,", "includes" and/or "including", when
used herein, specify the presence of stated features, integers, steps, operations, elements,
and/or components, but do not preclude the presence or addition of one or more other
features, integers, steps, operations, elements, components, and/or groups thereof.
[0028] It should also be noted that in some alternative implementations, the functions/acts
noted may occur out of the order noted in the FIGURES. For example, two FIGURES shown
in succession, or steps illustrated within any given FIGURE, may in fact be executed
substantially concurrently or may sometimes be executed in the reverse order, depending
upon the functionality/acts involved.
[0029] Hereinafter, exemplary embodiments of the present invention are described in detail.
[0030] As we noted above, the present invention relates to adjusting an image, e.g., an image
horizon, for a vehicle mounted camera by providing an image that adjusts in response to at
least one vehicle mounted sensor.
[0031] In exemplary embodiments, telemetry of a vehicle from a plurality of sensors may be
used to automatically adjust an image horizon in a desired way. Sensor data may include any
convenient type of data, including gyro data, vehicle angle, attitude, altitude, speed,
acceleration, traction, etc., data, navigational data, or the like. Sensor data may also comprise
data that describes environmental conditions for the vehicle, such as weather, sensed track
conditions, wind, including turbulence, shear, etc., temperature, and others, including any
sensed data that may be useful in adjusting an image.
[0032] Such adjusting of an image may include, as in specific examples described below,
adjustment of an image horizon, or another type of image adjustment, such as crop, selection
of image portions, tracking of objects of interest in images, rendering selective high
definition images from greater than high definition cameras, selective capture of image points
of interest, adjustment of the image responsive to environmental conditions, etc. Examples
are described by co-pending U.S. Patent Application Serial No. 13/567,323 to the present
inventor, filed August 6, 2012 and claiming priority to U.S. Patent Application Serial Nos.
61/515,549, filed August 5, 20011 and 61/563,126, filed November 23, 2011, the entire
                                                  4

   WO 2014/159868                                                            PCT/US2014/025362
contents of which are incorporated herein by reference. A selection from 13/567,323 relating
to selective capture and presentation of native image portions follows:
[0033] Common image or video formats are typically referred to either in terms of vertical
resolution or horizontal resolution. Prior Art FIGURE 9 shows an example of relative pixel
dimensions at a 2.39:1 aspect ratio, with 720p and 1080p formats being letterboxed.
[0034] Examples of vertical high resolution designators are 720p (1280 x 720 pixels), 1080i
(utilizing an interlace of two fields of 1920 x 540 pixels for a total resolution of 1920 x 1080
pixels) or 1080p (representing a progressive scan of 1920 x 1080 pixels).
[0035] Examples of horizontal high resolution designators, which are more common to
digital cinema terminology, include 2K (2048 pixels wide) and 4K (4096 pixels wide).
Overall resolution would depend on the image aspect ratio, e.g. a 2K image with a Standard
or Academy ratio of 4:3 would have an overall ratio of 2048 x 1536 pixels, whereas an image
with a Panavision ratio of 2.39:1 would have an overall ratio of 2048 x 856 pixels. PRIOR
ART FIGURE 9 illustrates a comparison of relative pixel dimensions for 720p, 1080p, 2K
and 4K captured images.
[0036] Currently, technologies exist for greater than high definition capture for digital
cinema, e.g. up to 2K, 4K and beyond. However, for consumer home viewing of the captured
digital cinema, the captured image is compressed down at the distributing studio to a version
that is specific to traditional usable consumer high definition formats for broadcast or other
distribution, e.g., at 720p, 1080i or 1080p.
[0037] Also, while digital cinema has utilized large resolution capture, traditional broadcast
capture has not. This broadcast capture is performed at the desired consumer display
resolution, e.g., 1080p, both due to limitations at the consumer display device as well as to
bandwidth restrictions of broadcast carriers. Thus, in scenarios calling for magnification of
the broadcast image, for example to better show selected detail within an image, the display
resolution is considerably less than the native image captured at the venue.
[0038] In exemplary embodiments related to selective capture, a first image or video is
captured at a first resolution, which resolution is greater than high definition and higher than
a predetermined broadcast display resolution. A desired portion of the first image or video is
then displayed at a second, lower resolution, which resolution is less than and closer to the
predetermined broadcast display resolution. Accordingly, a selected portion of the captured
image may be displayed at or near the predetermined broadcast display resolution (i.e.,
                                                 5

    WO 2014/159868                                                         PCT/US2014/025362
minimizing or eliminating loss of image detail relative to the predetermined broadcast display
resolution).
[0039] An example of this is illustrated at FIGURE 10, which shows a screenshot of a full
raster 4K moving video image 1110. A portion of the 4K image, illustrated as a 720p moving
video selectable extraction window 1112, is then selected for presentation. Thus, native
image capture occurs at a greater than high definition resolution, and portions of that greater
than high definition image are selected for presentation via the 720p extraction window.
While, FIGURE 10 specifically illustrates 4K capture and a 720p extraction window, it
should be recognized that both or either of the captured image and extraction window may be
provided at or sized to other resolutions.
[0040] Also, while one extraction window is illustrated in FIGURE 10, the present disclosure
contemplates simultaneous multiple extraction windows that may be applied to the same
captured image.
[0041] In further exemplary embodiments, the selectable extraction window (1112 in
FIGURE 10) is provided at a graphical user interface ("GUI") (1114 in FIGURES 11 and 12)
that is configured to allow an operator to navigate within a captured image and select portions
of the captured image for presentation. In exemplary embodiments, the extraction window is
configured to allow the operator to adjust the size and position of the extraction window. In
other exemplary embodiments, the extraction window is configured to track or scan across
moving images, e.g., to follow a play or subject of interest during a sporting event. In other
exemplary embodiments, plural operators may extract from the same images via the same or
via plural GUIs.
[0042] Referring now to FIGURES 11 and 12, processing of the captured images may occur
either offsite (FIGURE 11) or onsite (FIGURE 12). Referring to FIGURE 11, an exemplary
system is illustrated wherein a camera 1116 captures 4K images onsite, e.g., at a field (shown
generally at 1118) for a sporting event. A transport mechanism 1120, e.g. a fiber capable of
transporting a full bandwidth 4K video, transports the captured images to an operations base
("OB") (shown generally at 1122), e.g., a production truck away from the field 1118.
[0043] An image recorder 1124 records the captured images, e.g., as a data stream on a
server, and is configured to allow an operator to go back in time relative to the recording and
examine selected portions of the captured image as described above. Such control is
provided to an operator via the GUI 1114 through a processor 1126 interfacing with the GUI
                                                6

    WO 2014/159868                                                           PCT/US2014/025362
1114 and recorder 1124. In exemplary embodiments, the recorder, processor and GUI are
configured to allow the operator to go back instantaneously or near-instantaneously to select
portions of the recorded image for presentation.
[0044] For example, with regard to FIGURE 10, an operator in a truck would use a GUI to
navigate the full raster 4K image and maneuver the selective 16:9 extraction window, in a
manner similar to a cursor, to select an area of interest. In exemplary embodiments, the GUI
is configured such that the extraction window may select an area of interest in one or both of
live and recorded video. Also, as has been noted above, the present disclosure contemplates
sizing and zooming capabilities for the extraction window. In other exemplary embodiments,
the system is configured to mark keyframes and establish mapping for desired moves, e.g.,
pans and zooms, among others, around the image.
[0045] Referring again to FIGURE 11, in exemplary embodiments, the output 1128 of the
system (e.g., a 720p/59.94 output relative to a 4K capture) is provided to a router 1130 that
allows the output to be taken live to a switcher 1132 or to be ingested at a server 1134
("EVS") for later playout. Also, in exemplary embodiments, a resulting image can be slowed
down for replay or rendered as a still image, if desired, either at the server 1134 or at the
operator's position (via processor 1126).
[0046] FIGURE 12 provides an alternate exemplary embodiment, wherein capture, transport
and recording of the native image (in this example 4K images) occurs onsite, e.g., at the field
1118 of a sporting event). An onsite processor 1126 provides or interfaces with an operator
GUI 1114 in an operations base 1122 (e.g., a truck, though the GUI could be accessed from
any convenient location) and provides a reference video 1138 of the image to allow the
operator to navigate the image via the extraction window. The output 1128 is then
transported from the field to an offsite router 1130.
[0047] In another embodiment, at least one GUI is accessed by a tablet controller as a
navigation tool for the system. Such tablet controller may be wireless and portable to allow
for flexible a primary or supplemental navigation tool.
[0048] In other exemplary embodiments, multiple cameras may be positioned to capture
images from different points of view, and extraction windows may be provided relative to the
multiple image captures in a system for selectively displaying portions of native images from
different points of view.
                                                 7

    WO 2014/159868                                                            PCT/US2014/025362
[0049]       Further exemplary embodiments provide real time or near real time tracking of
subjects of interest (e.g., identified, selected or pre-tagged players of interest or automatic
tracking of a ball in a game). Additional exemplary embodiments also provide virtual
directing of operated and automatically tracked subjects of interest for cutting into a full live
broadcast, utilizing backend software and tracking technology to provide a virtual viewfinder
that operates in manners similar to otherwise human camera operators. Such processes may
also use artificial technology for simple tracking, e.g., of a single identified object, or for
more complex operations approximating motions utilized by human camera operators, e.g.,
pan, tilt and zoom of the extraction window in a manner similar to human operators. For
those examples using 4K (or the like) capture, camera capture could utilize a specifically
designed 4K camera. A camera may also use wider lensing to capture more of the subject,
with possible reconstituting or flattening in post production. Also, different lensing can be
used specific to different applications.
[0050] Such processes may use the above-described multiple cameras and/or multiple
extraction windows, or may run with specific regard to one camera and/or one extraction
window. In such a way, an artificial intelligence can automatically capture, extract and
display material for broadcast, utilizing the extraction window(s) as virtual viewfinders.
[0051] Additional exemplary embodiments also provide for virtual 3D extraction, e.g. via s
single camera at 4K or 8K with a two window output.
[0052] In other exemplary embodiments, an increased image capture frame rates relative to a
broadcast frame rate along with or in lieu of an increased image capture resolution, as has
been discussed above.
[0053] In such embodiments, a first video is captured at a first frame rate, which frame rate is
higher than a predetermined broadcast frame rate. A desired portion of the first video is then
displayed at a second, lower frame rate, which frame rate is less than and closer to the
predetermined broadcast frame rate. The desired portion of the first video is captured by an
extraction window that extracts frames across the native captured video. In such a way, the
extracted video provides smooth and clear video, without edgy or blurred frames. Such
captured first video may be at any frame rate that is above the predetermined broadcast frame
rate.
[0054] In further exemplary embodiments, the first video is captured at a first frame rate that
is in super motion or hyper motion. In traditional video, this equates to approximately 180
                                                   8

    WO 2014/159868                                                         PCT/US2014/025362
("supermotion") frames per second or above ("hypermotion" or "ultramotion") in a
progressive frame rate. In exemplary embodiments, hypermotion is recorded in discrete
times sufficient to capture a triggered instance of an action of camera subject for playback.
In other exemplary embodiments, the present system performs a full time record of a camera
in hypermotion, e.g., of sufficient length for replay playback archiving, such as more than
fifteen minutes, more than thirty minutes, more than an hour, more than an hour and a half, or
more than two hours, among others.
[0055] In other exemplary embodiments, raw data from at least one camera is manipulated to
adjust the image quality (make it "paintable") to broadcast specifications. In exemplary
embodiments, broadcast "handles" may be integrated into the system to affect the raw data in
a manner that is more germane to broadcast color temperatures, hues and gamma variables.
[0056] The present disclosure thus advantageously provides systems and methods for
selective capture of and presentation of native image portions, for broadcast production or
other applications. By providing exemplary embodiments using a selectable extraction
window through a GUI, an operator has complete control over portions within the native
images that the operator desires for presentation. Also, by providing exemplary embodiments
with image capture greater than high definition (e.g., 4K), desired portions of the image
selected by an operator may be presented at or relatively near high definition quality (i.e.,
without relative degradation of image quality). Further, by providing exemplary
embodiments with image capture frame rates greater than that of a predetermined broadcast
frame rate, extracted video therefrom provides smooth and clear video, without edgy or
blurred frames. Finally, various exemplary embodiments utilizing enhanced GUI features,
such as automatic tracking of subjects of interests, plural GUIs or extraction windows for one
or plural (for different points of view) captured images provide advantageous production
flexibilities and advantages.
[0057] Referring now to FIGURE 3, an exemplary method for adjusting an image for a
vehicle mounted camera is illustrated generally at 20, including receiving image data from a
vehicle mounted camera (described at box 22), receiving data from at least one vehicle
mounted sensor (described at box 24), and adjusting the image horizon utilizing the data
received from the at least one vehicle mounted sensor (described at box 26).
[0058] In exemplary embodiments, such adjusting of the image horizon may be applied as a
digital video effect, such that actual manipulation of a vehicle mounted camera is
                                                 9

    WO 2014/159868                                                           PCT/US2014/025362
unnecessary. Further, any type of image horizon adjustment is contemplated, whether or not
such adjustment results in matching image horizon with a skyline horizon.
[0059] Additionally, it should be recognized that some or all of image adjustment may be
performed on the vehicle. For example, an on-board (on the vehicle) processor may perform
some or all of the image adjustment based upon data from the at least one sensor. Allocating
processing power to the vehicle may be particularly useful, e.g., in wireless transmission
applications where a reduced data package can take advantage of bandwidth limitations.
Further, in exemplary embodiments, an operator can communicate with an on-board
processor over a separate channel, leaving one or more wireless transmission channels from
the vehicle substantially dedicated to video output.
[0060] Additionally, exemplary embodiments contemplate automatic adjustment of image
horizon based upon received vehicle telemetry data.
[0061] In other exemplary embodiments, data from at least one sensor is used to
automatically adjust an image horizon to match a skyline horizon during tilting of a vehicle,
for example as a racecar banks around a turn off of a straightaway. Reference is made to
FIGURES 4 and 5, as compared to PRIOR ART FIGURES 1 and 2. FIGURES 4 and 5 show
exemplary adjustment of an image horizon 12 such that it matches a skyline horizon (shown
as line 28) during tilting of a racecar as it transitions from a straightaway to a banked turn.
[0062] In other exemplary embodiments, both image horizon and zoom are automatically
adjusted during tilting of a vehicle. Reference is made to FIGURES 6 and 7, as compared to
PRIOR ART FIGURES 1 and 2. FIGURES 6 and 7 show exemplary adjustment of an image
horizon 12 such that it matches a skyline horizon (shown as line 28) during tilting of a
racecar as it transitions from a straightaway to a banked turn, with an increase in zoom during
the turn.
[0063] FIGURE 8 illustrates an exemplary system for adjusting an image horizon from a
vehicle mounted camera. The system 100 may include a server 101. The server 101 may
include a plurality of information, including but not limited to, vehicle telemetry information,
static and continuous video images from a vehicle mounted camera, algorithms and
processing modules and other data storage. The server 101 may be in communication with a
network 106 via a communication channel 110.
[0064] Additionally, the system 100 may access or interface with additional, third party data
sources or servers 103. Third party sources of data 103 may be in communication with the
                                                  10

   WO 2014/159868                                                           PCT/US2014/025362
network 106 via a communication channel 111. It is noted that although illustrated as
separate, the source 103 may include a server substantially similar to server 101. The server
101 or source 103 may include a data service provider, for example, a cellular service
provider, a business information provider, or any other suitable provider or repository. The
server 101 or source 103 may also include an application server providing applications and/or
computer executable code implementing any of the interfaces/methodologies described
herein. The server 101 or source 103 may present a plurality of application defaults, choices,
set-ups, and/or configurations such that a device may receive and process the application
accordingly. The server 101 or source 103 may present any application on a viewer interface
or web-browser of a device for relatively easy selection by a viewer of the device.
[0065] Alternately, another server component or local computer apparatus, e.g., 104, 105
and/or 106, may produce the viewer interface and control connectivity to the server 101 or
source 103. Also, the server 101 or one or more of the local computer apparatus 104, 105
and 106 may be configured to periodically access the source 103 and cache data relevant to
data used in embodiments of the present invention.
[0066] The network 106 may be any suitable network, including the Internet, wide area
network, and/or a local network. The server 101 and the source 103 may be in
communication with the network 106 over communication channels 110, 111. The
communication channels 110, 111 may be any suitable communication channels including
wireless, satellite, wired, or otherwise.
[0067] An exemplary system 100 further includes computer apparatus 105 in communication
with the network 106, over communication channel 112. The computer apparatus 105 may be
any suitable computer apparatus including a personal computer (fixed location), a laptop or
portable computer, a personal digital assistant, a cellular telephone, a portable tablet
computer, a portable audio player, or otherwise. For example, the system 100 may include
computer apparatuses 104 and 106, which are embodied as a portable cellular telephone and a
tablet, respectively. The apparatuses 104 and 106 may include display means 141, 161,
and/or buttons/controls 142. The controls 142 may operate independently or in combination
with any of the controls noted above.
[0068] Further, the apparatuses 104, 105, and 106 may be in communication with each other
over communication channels 115, 116 (for example, wired, wireless, Bluetooth channels,
                                               11

    WO 2014/159868                                                           PCT/US2014/025362
etc); and may further be in communication with the network 106 over communication
channels 112, 113, and 114.
[0069] Therefore, the apparatuses 104, 105, and 106 may all be in communication with one
or both of the server 101 and the source 103, as well as each other. Each of the apparatuses
may be in severable communication with the network 106 and each other, such that the
apparatuses 104, 105, and 106 may be operated without constant communication with the
network 106 (e.g., using data connection controls of an interface). For example, if there is no
data availability or if a viewer directs an apparatus to work offline, the data used by any of
the apparatuses 104, 105, and 106 may be based on stored or cached information/parameters.
It follows that each of the apparatuses 104, 105, and 106 may be configured to perform the
methodologies described in the various exemplary embodiments.
[0070] Furthermore, using any of the illustrated communication mediums, the apparatuses
104, 105, and 106 may manipulate, share, transmit, and/or receive different data previously or
currently produced at any one of the illustrated elements of the system 100. For example, data
may be available on the server 101 and/or the source 103. Moreover, viewers of any of the
devices 104, 105, and 106 may independently manipulate, transmit, etc., data, e.g., to
separately determine a current value of the index at a given time. Thus, any suitable device
may be utilized to use vehicle telemetry data from at least one vehicle sensor to adjust image
horizon from a vehicle mounted camera.
[0071] It should be emphasized that the above-described embodiments of the present
invention, particularly, any detailed discussion of particular examples, are merely possible
examples of implementations, and are set forth for a clear understanding of the principles of
the invention. Many variations and modifications may be made to the above-described
embodiment(s) of the invention without departing from the spirit and scope of the invention.
All such modifications and variations are intended to be included herein within the scope of
this disclosure and the present invention and protected by the following claims.
[0072] What is claimed is:
                                                 12

    WO 2014/159868                                                            PCT/US2014/025362
CLAIMS
1.      A method for adjusting image horizon for a vehicle mounted camera, comprising:
        providing a camera mounted in a vehicle;
        providing at least one sensor in said vehicle, the sensor detecting a change in tilt of
said vehicle; and
        adjusting an image horizon in response to said detected change in tilt of said vehicle.
2.      A method in accordance with claim 1, wherein said image horizon automatically
adjusts in response to said detected change in tilt of said vehicle.
3.      A method in accordance with claim 2, wherein said image horizon is adjusted as a
digital video effect.
4.      A method in accordance with claim 1, wherein said detected change in tilt is provided
as vehicle telemetry data.
5.      A method in accordance with claim 2, wherein said image horizon is adjusted to
match or approximate a skyline horizon during tilting of said vehicle.
6.      A method in accordance with claim 2, wherein said image horizon is adjusted with a
variation in zoom of the image.
7.      A method in accordance with claim 1, further comprising:
        capturing a first image or video at a first resolution, which resolution is greater than
high definition and higher than a predetermined second, output display resolution;
         selecting a first desired portion of the captured, native first image or video, wherein
said first portion is at a resolution lower than that of the captured first image or video; and
        displaying said selected first portion at said second, output resolution.
8.      A method in accordance with claim 7, wherein said selecting of a desired first portion
of the first image or video is provided by a graphical user interface having a selectable
extraction window.
                                                   13

    WO 2014/159868                                                            PCT/US2014/025362
9.       A method in accordance with claim 8, wherein said extraction window is configured
to allow an operator to navigate within said captured image or video and select portions
thereof for presentation.
10.      A system for adjusting image horizon for a vehicle mounted camera, comprising:
         a camera mounted in a vehicle;
         at least one sensor in said vehicle, the sensor configured to a change in tilt of said
vehicle;
         a processor configured to access camera image data and data indicating tilt of said
vehicle; and
         a digital video effects component, the digital video effects component configured to
adjust an image horizon in response to said detected change in tilt of said vehicle.
11.      A system in accordance with claim 10, wherein said digital video effects component
is configured to automatically adjust image horizon in response to said detected change in tilt
of said vehicle.
12.      A system in accordance with claim 11, wherein said detected change in tilt is
provided as vehicle telemetry data.
13.      A system in accordance with claim 11, wherein said image horizon is adjusted to
match or approximate a skyline horizon during tilting of said vehicle.
14.      A system in accordance with claim 10, wherein said image horizon is adjusted with a
variation in zoom of the image.
15.      A system in accordance with claim 10, wherein said camera is configured to capture a
first image or video at a first resolution, which resolution is greater than high definition and
higher than a predetermined second, output display resolution, the system further comprising:
         a processor in communication with a graphical user interface, said interface
configured to select a first desired portion of the native, first image or video, wherein said
first portion is at a resolution lower than that of the captured first image or video; and
                                                  14

    WO 2014/159868                                                           PCT/US2014/025362
        an output mechanism configured to transport said selected first portion to a router,
switcher or server at said second, output resolution.
16.     A system in accordance with claim 15, wherein said graphical user interface has a
selectable extraction window.
17.     A system in accordance with claim 16, wherein said extraction window is configured
to allow an operator to navigate within said captured image or video and select portions
thereof for presentation.
18.     A method for adjusting an image for a vehicle mounted camera, comprising:
        providing a camera mounted in a vehicle;
        providing at least one sensor in said vehicle, the sensor detecting a data of interest
relative to said vehicle; and
        adjusting an image in response to said detected data of said vehicle.
19.     A method in accordance with claim 18, wherein said sensor data includes one or more
of: gyro data; vehicle angle; attitude; altitude; speed; acceleration; traction; and navigational
data.
20.     A method in accordance with claim 18, wherein said sensor data includes
environmental conditions for the vehicle, including one or more of: weather; sensed track
conditions; wind; and temperature.
21.     A method in accordance with claim 18, wherein said image adjustment includes one
or more of:
        adjustment of an image horizon;
        adjustment of image crop; selection of image portions;
        tracking of objects of interest in images;
        rendering selective high definition images from greater than high definition cameras;
                                                 15

    WO 2014/159868                                                            PCT/US2014/025362
         selective capture of image points of interest; or adjustment of the image responsive to
environmental conditions.
22.     A method in accordance with claim 21, wherein said image adjustment is provided as
a digital video effect.
23.     A method in accordance with claim 22, wherein said at least a portion of said image
adjustment is performed by an on-board vehicle processor.
24.     A method in accordance with claim 23, wherein said adjusted image is transmitted via
wireless protocol to an external computing device.
25.     A method in accordance with claim 18, further comprising:
        capturing a first image or video at a first resolution, which resolution is greater than
high definition and higher than a predetermined second, output display resolution;
         selecting a first desired portion of the captured, native first image or video, wherein
said first portion is at a resolution lower than that of the captured first image or video; and
        displaying said selected first portion at said second, output resolution.
26.     A method in accordance with claim 25, wherein said selecting of a desired first
portion of the first image or video is provided by a graphical user interface having a
selectable extraction window.
27.     A method in accordance with claim 26, wherein said extraction window is configured
to allow an operator to navigate within said captured image or video and select portions
thereof for presentation.
                                                   16

 <removed-date>
 <removed-apn>
This data, for application number 2014244374, is current as of 2018-03-15 21:00 AEST

 <removed-date>
 <removed-apn>
This data, for application number 2014244374, is current as of 2018-03-15 21:00 AEST

 <removed-date>
 <removed-apn>
This data, for application number 2014244374, is current as of 2018-03-15 21:00 AEST

 <removed-date>
 <removed-apn>
This data, for application number 2014244374, is current as of 2018-03-15 21:00 AEST

 <removed-date>
 <removed-apn>
This data, for application number 2014244374, is current as of 2018-03-15 21:00 AEST

 <removed-date>
 <removed-apn>
This data, for application number 2014244374, is current as of 2018-03-15 21:00 AEST

 <removed-date>
 <removed-apn>
This data, for application number 2014244374, is current as of 2018-03-15 21:00 AEST

 <removed-date>
 <removed-apn>
This data, for application number 2014244374, is current as of 2018-03-15 21:00 AEST

 <removed-date>
 <removed-apn>
This data, for application number 2014244374, is current as of 2018-03-15 21:00 AEST

 <removed-date>
 <removed-apn>
This data, for application number 2014244374, is current as of 2018-03-15 21:00 AEST

 <removed-date>
 <removed-apn>
This data, for application number 2014244374, is current as of 2018-03-15 21:00 AEST

 <removed-date>
 <removed-apn>
This data, for application number 2014244374, is current as of 2018-03-15 21:00 AEST

