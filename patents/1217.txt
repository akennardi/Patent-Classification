                                          ABSTRACT
        When a channel signal, such as a 22.2 channel signal, is rendered into a 5.1 channel
signal, a three-dimensional (3D) audio may be reproduced by using a two-dimensional (2D)
output channel, however, when an elevation angle of an input channel is different from a
standard elevation angle, if elevation rendering parameters according to the standard
elevation angle are used, distortion may occur in a sound image. In order to solve the
aforementioned problem according to the related art and to prevent front-back confusion due
to a surround output channel, an embodiment of the present invention provides a method of
rendering an audio signal, the method including receiving a multichannel signal including a
plurality of input channels to be converted to a plurality of output channels; adding a preset
delay to a frontal height input channel so as to allow each of the plurality of output channels
to provide a sound image having an elevation at a reference elevation angle; changing, based
on the added delay, an elevation rendering parameter with respect to the frontal height input
channel; and preventing front-back confusion by generating, based on the changed elevation
rendering parameter, an elevation-rendered surround output channel delayed with respect to
the frontal height input channel.

          METHOD AND DEVICE FOR RENDERING ACOUSTIC SIGNAL, AND
                     COMPUTER-READABLE RECORDING MEDIUM
[0001]      The present application is a divisional application from Australian Patent
Application No. 2015280809, the entire disclosure of which is incorporated herein by
reference.
                                      TECHNICAL FIELD
[0002]      The present invention relates to a method and apparatus for rendering an audio
signal, and more particularly, to a rendering method and apparatus for further accurately
representing a position of a sound image and a timbre by modifying an elevation panning
coefficient or an elevation filter coefficient, when an elevation of an input channel is higher
or lower than an elevation according to a standard layout.
                                     BACKGROUND ART
[0003]      3D audio means audio that allows a listener to have an immersive feeling by
reproducing not only an elevation of audio and a tone color but also reproducing a direction
or a distance, and to which spatial information is added, wherein the spatial information
makes the listener, who is not located in a space where an audio source occurred, have a
directional perception, a distance perception, and a spatial perception.
[0004]      When a channel signal, such as a 22.2 channel signal, is rendered into a 5.1
channel    signal, a three-dimensional      (3D)   audio   may be     reproduced   by using a
two-dimensional (2D) output channel, however, when an elevation angle of an input channel
is different from a standard elevation angle, if an input signal is rendered by using rendering
parameters determined according to the standard elevation angle, distortion may occur in a
sound image.
                     DETAILED DESCRIPTION OF THE INVENTION
                                    TECHNICAL PROBLEM
[0005]      As described above, when a multichannel signal, such as a 22.2 channel signal, is
rendered into a 5.1 channel signal, a three-dimensional (3D) surround sound may be
                                                 1

reproduced by using a two-dimensional (2D) output channel, however, when an elevation
angle of an input channel is different from a standard elevation angle, if an input signal is
rendered by using rendering parameters determined according to the standard elevation angle,
distortion may occur in a sound image.
[0006]       In order to solve the aforementioned problem according to the related art, the
present invention is provided to decrease distortion of a sound image even if an elevation of
an input channel is higher or lower than a standard elevation.
                                    TECHNICAL SOLUTION
[0007]       In order to achieve the objective, the present invention includes embodiments
below.
[0008]       According to embodiment first aspect of the present invention, there is provided a
method of elevation rendering an audio signal, the method comprising: receiving
multichannel signals including at least one height input channel signal; obtaining first
elevation rendering parameters for the multichannel signals; obtaining a delayed height input
channel signal by applying a predetermined delay to a height input channel signal, wherein a
label of the height input channel signal is one of frontal height channel labels; obtaining
second elevation rendering parameters based on the label of the height input channel signal
and labels of two output channel signals, wherein the labels of the two output channel signals
are surround channel labels; and elevation rendering the multichannel signals and the delayed
height input channel signal to output a plurality of output channel signals based on the first
elevation rendering parameters and the second elevation rendering parameters, wherein the
first elevation rendering parameters and the second elevation rendering parameters comprise
at least one of a panning gain and an elevation filter coefficient..
[0009]       The plurality of output channels may be horizontal channels.
[0010]       The elevation rendering parameters may include at least one of panning gains and
elevation filter coefficients.
[0011]       The frontal height input channel may include at least one of CH_U_L030,
CH_U_R030, CH_U_L045, CH_U_R045, and CH_U_000 channels.
[0012]       The surround output channel may include at least one of CH_M_L 10 and
CH_M_R10 channels.
[0013]       The predetermined delay may be determined based on a sampling rate.
                                                  2

[0014]      According to embodiment second aspect of the present invention, there is
provided an apparatus for rendering an audio signal, the apparatus comprising: a receiving
unit configured to receive multichannel signals including at least one height input channel
signal; a rendering unit configured to: obtain first elevation rendering parameters for the
multichannel signals, obtain a delayed height input channel signal by applying a
predetermined delay to a height input channel signal, wherein a label of the height input
channel signal is one of frontal height channel labels, obtain second elevation rendering
parameters based on the label of the height input channel signal and labels of two output
channel signals, wherein the labels of the two output channel signals are surround channel
labels, and elevation render the multichannel signals and the delayed height input channel
signal to output a plurality of output channel signals based on the first elevation rendering
parameters and the second elevation rendering parameters, wherein the first elevation
rendering parameters and the second elevation rendering parameters comprise at least one of
a panning gain and an elevation filter coefficient.
[0015]      The plurality of output channels may be horizontal channels.
[0016]      The elevation rendering parameters may include at least one of panning gains and
elevation filter coefficients.
[0017]      The frontal height input channel may include at least one of CH_U_L030,
CH_U_R030, CH_U_L045, CH_U_R045, and CH_U_000 channels.
[0018]      The frontal height channel may include at least one of CH_U_L030, CH_U_R030,
CH_U_L045, CH_U_R045, and CH_U_000 channels.
[0019]      The predetermined delay may be determined based on a sampling rate.
[0020]      According to another embodiment of the present invention, there is provided a
method of rendering an audio signal, the method including receiving a multichannel signal
including a plurality of input channels to be converted to a plurality of output channels;
obtaining elevation rendering parameters with respect to a height input channel so as to allow
the plurality of output channels to provide elevated sound image at a reference elevation
angle; and updating the elevation rendering parameters with respect to a height input channel
having a predetermined elevation angle rather than the reference elevation angle, wherein the
updating of the elevation rendering parameters includes updating elevation panning gains for
panning a height input channel at a top front center to a surround output channel.
[0021]      The plurality of output channels may be horizontal channels.
[0022]      The elevation rendering parameters may include at least one of the elevation
panning gains and an elevation filter coefficients.
                                                 3

[0023]      The updating of the elevation rendering parameters may include updating the
elevation panning gains, based on the reference elevation angle and the predetermined
elevation angle.
[0024]      When the predetermined elevation angle is less than the reference elevation angle,
updated elevation panning gains from among the updated elevation panning gains which is to
be applied to an ipsilateral output channel of an output channel having the predetermined
elevation angle may be greater than the elevation panning gains before the updating, and a
total sum of squares of the updated elevation panning gains to be respectively applied to the
plurality of input channels may be 1.
[0025]      When the predetermined elevation angle is greater than the reference elevation
angle, an updated elevation panning gain from among the updated elevation panning gains
which is to be applied to an ipsilateral output channel of an output channel having the
predetermined elevation angle may be less than the elevation panning gains before the
updating, and a total sum of squares of the updated elevation panning gains to be respectively
applied to the plurality of input channels may be 1.
[0026]      According to another embodiment of the present invention, there is provided an
apparatus for rendering an audio signal, the apparatus including a receiving unit configured to
receive a multichannel signal including a plurality of input channels to be converted to a
plurality of output channels; and a rendering unit configured to obtain elevation rendering
parameters with respect to a height input channel so as to allow the plurality of output
channels to provide elevated sound image at a reference elevation angle, and to update the
elevation rendering parameters with respect to a height input channel having a predetermined
elevation angle rather than the reference elevation angle, wherein the updated elevation
rendering parameters includes elevation panning gains for panning a height input channel at a
top front center to a surround output channel.
[0027]      The plurality of output channels may be horizontal channels.
[0028]      The elevation rendering parameters may include at least one of the elevation
panning gains and an elevation filter coefficient.
[0029]      The updated elevation rendering parameters may include the elevation panning
gains updated based on the reference elevation angle and the predetermined elevation angle.
[0030]      When the predetermined elevation angle is less than the reference elevation angle,
updated elevation panning gains from among the updated elevation panning gains which is to
be applied to an ipsilateral output channel of an output channel having the predetermined
elevation angle may be greater than the elevation panning gains before the update, and a total
                                                 4

sum of squares of the updated elevation panning gains to be respectively applied to the
plurality of input channels may be 1.
[0031]      When the predetermined elevation angle is greater than the reference elevation
angle, updated elevation panning gains from among the updated elevation panning gains
which is to be applied to an ipsilateral output channel of an output channel having the
predetermined elevation angle may be less than the elevation panning gains that are not
updated, and a total sum of squares of the updated elevation panning gains to be respectively
applied to the plurality of input channels may be 1.
[0032]      According to another embodiment of the present invention, there is provided a
method of rendering an audio signal, the method including receiving a multichannel signal
including a plurality of input channels to be converted to a plurality of output channels;
obtaining elevation rendering parameters with respect to a height input channel so as to allow
the plurality of output channels to provide elevated sound image at a reference elevation
angle; and updating the elevation rendering parameters with respect to a height input channel
having a predetermined elevation angle rather than the reference elevation angle, wherein the
updating of the elevation rendering parameters includes obtaining elevation panning gains
updated with respect to a frequency range including a low frequency band, based on a
location of the height input channel.
[0033]      The updated elevation panning gains may be panning gains with respect to a rear
height input channel.
[0034]      The plurality of output channels may be horizontal channels.
[0035]      The elevation rendering parameters may include at least one of the elevation
panning gains and an elevation filter coefficients.
[0036]      The updating of the elevation rendering parameters may include applying a weight
to the elevation filter coefficients, based on the reference elevation angle and the
predetermined elevation angle.
[0037]      When the predetermined elevation angle is less than the reference elevation angle,
the weight may be determined so that an elevation filter characteristic may be smoothly
exhibited, and when the predetermined elevation angle is greater than the reference elevation
angle, the weight may be determined so that the elevation filter characteristic may be sharply
exhibited.
[0038]      The updating of the elevation rendering parameters may include updating the
elevation panning gains, based on the reference elevation angle and the predetermined
elevation angle.
                                                  5

[0039]      When the predetermined elevation angle is less than the reference elevation angle,
an updated elevation panning gain from among the updated elevation panning gains which is
to be applied to an ipsilateral output channel of an output channel having the predetermined
elevation angle may be greater than the elevation panning gains before the updating, and a
total sum of squares of the updated elevation panning gains to be respectively applied to the
plurality of input channels may be 1.
[0040]      When the predetermined elevation angle is greater than the reference elevation
angle, an updated elevation panning gain from among the updated elevation panning gains
which is to be applied to an ipsilateral output channel of an output channel having the
predetermined elevation angle may be less than the elevation panning gains before the
updating, and a total sum of squares of the updated elevation panning gains to be respectively
applied to the plurality of input channels may be 1.
[0041]      According to another embodiment of the present invention, there is provided an
apparatus for rendering an audio signal, the apparatus including a receiving unit configured to
receive a multichannel signal including a plurality of input channels to be converted to a
plurality of output channels; and a rendering unit configured to obtain elevation rendering
parameters with respect to a height input channel so as to allow the plurality of output
channels to provide elevated sound image at a reference elevation angle, and to update the
elevation rendering parameters with respect to a height input channel having a predetermined
elevation angle rather than the reference elevation angle, wherein the updated elevation
rendering parameters include elevation panning gains updated with respect to a frequency
range including a low frequency band, based on a location of the height input channel.
[0042]      The updated elevation panning gains may be panning gains with respect to a rear
height input channel.
[0043]      The plurality of output channels may be horizontal channels.
[0044]      The elevation rendering parameters may include at least one of the elevation
panning gains and an elevation filter coefficients.
[0045]      The updated elevation rendering parameters may include the elevation filter
coefficients to which a weight is applied based on the reference elevation angle and the
predetermined elevation angle.
[0046]      When the predetermined elevation angle is less than the reference elevation angle,
the weight may be determined so that an elevation filter characteristic may be smoothly
exhibited, and when the predetermined elevation angle is greater than the reference elevation
                                                 6

angle, the weight may be determined so that the elevation filter characteristic may be sharply
exhibited.
[0047]      The updated elevation rendering parameters may include the elevation panning
gains updated based on the reference elevation angle and the predetermined elevation angle.
[0048]      When the predetermined elevation angle is less than the reference elevation angle,
updated elevation panning gains from among the updated elevation panning gains which is to
be applied to an ipsilateral output channel of an output channel having the predetermined
elevation angle may be greater than the elevation panning gains before the update, and a total
sum of squares of the updated elevation panning gains to be respectively applied to the
plurality of input channels may be 1.
[0049]      When the predetermined elevation angle is greater than the reference elevation
angle, updated elevation panning gains from among the plurality of updated elevation
panning gains which is to be applied to an ipsilateral output channel of an output channel
having the predetermined elevation angle may be less than the elevation panning gains before
the updating, and a total sum of squares of the updated elevation panning gains to be
respectively applied to the plurality of input channels may 1.
[0050]      According to another embodiment of the present invention, there are provided a
program for executing the aforementioned methods and a computer-readable recording
medium having recorded thereon the program.
[0051]      In addition, there are provided another method, another system, and a
computer-readable recording medium having recorded thereon a computer program for
executing the method.
                                 ADVANTAGEOUS EFFECTS
[0052]      According to the present invention, a 3D audio signal may be rendered in a
manner that distortion of a sound image is decreased even if an elevation of an input channel
is higher or lower than a standard elevation. In addition, according to the present invention, a
front-back confusion phenomenon due to surround output channels may be prevented.
                         BRIEF DESCRIPTION OF THE DRAWINGS
[0053]      FIG. 1 is a block diagram illustrating an internal structure of a 3D audio
reproducing apparatus, according to an embodiment.
                                                 7

[0054]      FIG. 2 is a block diagram illustrating a configuration of a renderer in the 3D audio
reproducing apparatus, according to an embodiment.
[0055]      FIG. 3 illustrates a layout of channels when a plurality of input channels are
downmixed to a plurality of output channels, according to an embodiment.
[0056]      FIG. 4 illustrates a panning unit in an example where a positional deviation occurs
between a standard layout and an arrangement layout of output channels, according to an
embodiment.
[0057]      FIG. 5 is a block diagram illustrating configurations of a decoder and a 3D audio
renderer in the 3D audio reproducing apparatus, according to an embodiment.
[0058]      FIGS. 6 through 8 illustrate layouts of upper layer channels according to
elevations of upper layers in a channel layout, according to an embodiment.
[0059]      FIGS. 9 through 11 illustrate variation of a sound image and variation of an
elevation filter, according to elevations of a channel, according to an embodiment.
[0060]      FIG. 12 is a flowchart of a method of rendering a 3D audio signal, according to an
embodiment.
[0061]      FIG. 13 illustrates a phenomenon where left and right sound images are reversed
when an elevation angle of an input channel is equal to or greater than a threshold value,
according to an embodiment.
[0062]      FIG. 14 illustrates horizontal channels and frontal height channels, according to an
embodiment.
[0063]      FIG. 15 illustrates a perception percentage of frontal height channels, according to
an embodiment.
[0064]      FIG. 16 is a flowchart of a method of preventing front-back confusion, according
to an embodiment.
[0065]      FIG. 17 illustrates horizontal channels and frontal height channels when a delay is
added to surround output channels, according to an embodiment.
[0066]      FIG. 18 illustrates a horizontal channel and a top front center (TFC) channel,
according to an embodiment.
                                           BEST MODE
[0067]      In order to achieve the objective, the present invention includes embodiments
below.
                                                 8

[0068]      According to an embodiment, there is provided a method of rendering an audio
signal, the method including receiving a multichannel signal including a plurality of input
channels to be converted to a plurality of output channels; adding a predetermined delay to a
frontal height input channel so as to allow the plurality of output channels to provide elevated
sound image at a reference elevation angle; modifying, based on the added delay, elevation
rendering parameters with respect to the frontal height input channel; and preventing
front-back confusion by generating, based on the modified elevation rendering parameters, an
elevation-rendered surround output channel delayed with respect to the frontal height input
channel.
                                 MODE OF THE INVENTION
[0069]      The detailed descriptions of the invention are referred to with the attached
drawings illustrating particular embodiments of the invention. These embodiments are
provided so that this disclosure will be thorough and complete, and will fully convey the
concept of the invention to one of ordinary skill in the art. It will be understood that various
embodiments of the invention are different from each other and are not exclusive with respect
to each other.
[0070]      For example, a particular shape, a particular structure, and a particular feature
described in the specification may be changed from an embodiment to another embodiment
without departing from the spirit and scope of the invention. Also, it will be understood that a
position or layout of each element in each embodiment may be changed without departing
from the spirit and scope of the invention. Therefore, the detailed descriptions should be
considered in a descriptive sense only and not for purposes of limitation and the scope of the
invention is defined not by the detailed description of the invention but by the appended
claims, and all differences within the scope will be construed as being included in the present
invention.
[0071]      Like reference numerals in the drawings denote like or similar elements
throughout the specification. In the following description and the attached drawings,
well-known functions or constructions are not described in detail since they would obscure
the present invention with unnecessary detail. Also, like reference numerals in the drawings
denote like or similar elements throughout the specification.
[0072]      Hereinafter, the present invention will be described in detail by explaining
exemplary embodiments of the invention with reference to the attached drawings. The
                                                9

invention may, however, be embodied in many different forms, and should not be construed
as being limited to the embodiments set forth herein; rather, these embodiments are provided
so that this disclosure will be thorough and complete, and will fully convey the concept of the
invention to those of ordinary skill in the art.
[0073]       Throughout the specification, when an element is referred to as being "connected
to" or "coupled with" another element, it can be "directly connected to or coupled with" the
other element, or it can be "electrically connected to or coupled with" the other element by
having an intervening element interposed therebetween. Also, when a part "includes" or
"comprises" an element, unless there is a particular description contrary thereto, the part can
further include other elements, not excluding the other elements.
[0074]       Hereinafter, the exemplary embodiments of the present invention will be
described with reference to the attached drawings.
[0075]       FIG. 1 is a block diagram illustrating an internal structure of a 3D audio
reproducing apparatus, according to an embodiment.
[0076]       A 3D audio reproducing apparatus 100 according to an embodiment may output a
multichannel audio signal in which a plurality of input channels are mixed to a plurality of
output channels for reproduction. Here, if the number of output channels is less than the
number of input channels, the input channels are downmixed to correspond to the number of
output channels.
[0077]       3D audio means audio that allows a listener to have an immersive feeling by
reproducing not only an elevation of audio and a tone color but also reproducing a direction
or a distance, and to which spatial information is added, wherein the spatial information
makes the listener, who is not located in a space where an audio source occurred, have a
directional perception, a distance perception, and a spatial perception.
[0078]       In the descriptions below, output channels of an audio signal may mean the
number of speakers through which audio is output. The higher the number of output channels,
the higher the number of speakers through which audio is output. The 3D audio reproducing
apparatus 100 according to an embodiment may render and mix the multichannel audio signal
to an output channel for reproduction, so that the multichannel audio signal having the large
number of input channels may be output and reproduced in an environment where the number
of output channels is small. In this regard, the multichannel audio signal may include a
channel capable of outputting an elevated sound.
[0079]       The channel capable of outputting an elevated sound may indicate a channel
capable of outputting an audio signal via a speaker positioned above a head of a listener so as
                                                 10

to make the listener feel elevated. A horizontal channel may indicate a channel capable of
outputting an audio signal via a speaker positioned on a horizontal plane with respect to the
listener.
[0080]       The aforementioned environment where the number of output channels is small
may indicate an environment that does not include an output channel capable of outputting
the elevated sound and in which audio may be output via a speaker arranged on the horizontal
plane.
[0081]       Also, in the descriptions below, a horizontal channel may indicate a channel
including an audio signal to be output via a speaker positioned on the horizontal plane. An
overhead channel may indicate a channel including an audio signal to be output via a speaker
that is not positioned on the horizontal plane but is positioned on an elevated plane so as to
output an elevated sound.
[0082]       Referring to FIG. 1, the 3D audio reproducing apparatus 100 according to an
embodiment may include an audio core 110, a renderer 120, a mixer 130, and a
post-processing unit 140.
[0083]       According to an embodiment, the 3D audio reproducing apparatus 100 may output
may render, mix, and output a multichannel input audio signal to an output channel for
reproduction. For example, the multichannel input audio signal may be a 22.2 channel signal,
and the output channel for reproduction may be 5.1 or 7.1 channels. The 3D audio
reproducing apparatus 100 may perform rendering by setting output channels to be
respectively mapped to channels of the multichannel input audio signal, and may mix
rendered audio signals by mixing signals of the channels respectively mapped to channels for
reproduction and outputting a final signal.
[0084]       An encoded audio signal is input in the form of bitstream to the audio core 110,
and the audio core 110 selects a decoder appropriate for a format of the encoded audio signal
and decodes the input audio signal.
[0085]       The renderer 120 may render the multichannel input audio signal to multichannel
output channels according to channels and frequencies. The renderer 120 may perform
three-dimensional (3D) rendering and two-dimensional (2D) rendering on each of signals
according to overhead channels and horizontal channels. A configuration of a render and a
rendering method will be described in detail with reference to FIG. 2.
[0086]       The mixer 130 may mix the signals of the channels respectively mapped to the
horizontal channels, by the renderer 120, and may output the final signal. The mixer 130 may
                                                 11

mix the signals of the channels according to each of predetermined periods. For example, the
mixer 130 may mix the signals of each of the channels according to one frame.
[0087]       The mixer 130 according to an embodiment may perform mixing, based on a
power value of the signals respectively rendered to the channels for reproduction. In other
words, the mixer 130 may determine amplitude of the final signal or a gain to be applied to
the final signal, based on the power value of the signals respectively rendered to the channels
for reproduction.
[0088]       The post-processing unit 140 performs a dynamic range control with respect to a
multiband signal and binauralizing on the output signal from the mixer 130, according to
each reproducing apparatus (a speaker, a headphone, etc.). An output audio signal output
from the post-processing unit 140 may be output via an apparatus such as a speaker, and may
be reproduced in a 2D or 3D manner after processing of each configuration element.
[0089]       The 3D audio reproducing apparatus 100 according to an embodiment shown in
FIG. 1 is shown with respect to a configuration of its audio decoder, and an additional
configuration is skipped.
[0090]       FIG. 2 is a block diagram illustrating a configuration of a renderer in the 3D audio
reproducing apparatus, according to an embodiment.
[0091]       The renderer 120 includes a filtering unit 121 and a panning unit 123.
[0092]       The filtering unit 121 may compensate for a tone color or the like of a decoded
audio signal, according to a location, and may filter an input audio signal by using a
Head-Related Transfer Function (HRTF) filter.
[0093]       In order to perform 3D rendering on an overhead channel, the filtering unit 121
may render the overhead channel, which has passed the HRTF filter, by using different
methods according to frequencies.
[0094]       The HRTF filter makes 3D audio recognizable according to a phenomenon in
which not only a simple path difference such as an Interaural Level Differences (ILD)
between both ears, Interaural Time Differences (ITD) between both ears with respect to an
audio arrival time, or the like but also complicated path properties such as diffraction at a
head surface, reflection due to an earflap, or the like are changed according to a direction in
which audio arrives. The HRTF filter may process audio signals included in the overhead
channel by changing a sound quality of an audio signal, so as to make the 3D audio
recognizable.
[0095]       The panning unit 123 obtains a panning coefficient to be applied to each of
frequency bands and each of channels and applies the panning coefficient, so as to pan the
                                                 12

input audio signal with respect to each of output channels. To perform panning on an audio
signal means to control magnitude of a signal applied to each output channel, so as to render
an audio source at a particular location between two output channels. The panning coefficient
may be referred to as the panning gain.
[0096]      The panning unit 123 may perform rendering on a low frequency signal from
among overhead channel signals by using an add-to-the-closest-channel method, and may
perform rendering on a high frequency signal by using a multichannel panning method.
According to the multichannel panning method, a gain value that is set to differ in channels to
be rendered to each of channel signals is applied to signals of each of channels of a
multichannel audio signal, so that each of the signals may be rendered to at least one
horizontal channel. The signals of each channel to which the gain value is applied may be
synthesized via mixing and may be output as a final signal.
[0097]      The low frequency signals are highly diffractive, even if the channels of the
multichannel audio signal are not divided and rendered to several channels according to the
multichannel panning method but are rendered to only one channel, the low frequency signals
may have sound qualities that are similarly recognized by a listener. Therefore, the 3D audio
reproducing apparatus 100 according to an embodiment may render the low frequency signals
by using the add-to-the-closest-channel method and thus may prevent sound quality
deterioration that may occur when several channels are mixed to one output channel. That is,
when several channels are mixed to one output channel, a sound quality may be amplified or
decreased due to interference between channel signals and thus may deteriorate, and in this
regard, the sound quality deterioration may be prevented by mixing one channel to one output
channel.
[0098]      According to the add-to-the-closest-channel method, channels of the multichannel
audio signal may not be rendered to several channels but may each be rendered to a closest
channel from among channels for reproduction.
[0099]      In addition, the 3D audio reproducing apparatus 100 may expand a sweet spot
without the sound quality deterioration by performing rendering by using different methods
according to frequencies. That is, the low frequency signals that are highly diffractive are
rendered according to the add-to-the-closest-channel method, so that the sound quality
deterioration occurring when several channels are mixed to one output channel may be
prevented. The sweet spot means a predetermined range where the listener may optimally
listen to 3D audio without distortion.
                                               13

[00100]      When the sweet spot is large, the listener may optimally listen to the 3D audio
without distortion in a large range, and when the listener is not located in the sweet spot, the
listener may listen to audio in which a sound quality or a sound image is distorted.
[00101]      FIG. 3 illustrates a layout of channels when a plurality of input channels are
downmixed to a plurality of output channels, according to an embodiment.
[00102]      A technology has been being developed to provide 3D audio with a 3D surround
image so as to provide live and immersive feelings, such as a 3D image, which are same as
reality or are further exaggerated. 3D audio means an audio signal having elevation and
spatial perception with respect to sound, and at least two loudspeakers, i.e., output channels,
are required so as to reproduce the 3D audio. In addition, except for binaural 3D audio using
an HRTF, the large number of output channels is required so as to further accurately realize
elevation, a directional perception, and a spatial perception with respect to sound.
[00103]      Therefore, followed by a stereo system having 2 channel output, various
multichannel systems such as a 5.1 channel system, the Auro 3D system, the Holman 10.2
channel system, the ETRI/Samsung 10.2 channel system, the NHK 22.2 channel system, and
the like are provided and developed.
[00104]      FIG. 3 illustrates an example in which a 22.2 channel 3D audio signal is
reproduced via a 5.1 channel output system.
[00105]      The 5.1 channel system is a general name of a 5 channel surround multichannel
sound system, and is commonly spread and used as an in-house home theater and a sound
system for theaters. All 5.1 channels include a front left (FL) channel, a center (C) channel, a
front right (FR) channel, a surround left (SL) channel, and a surround right (SR) channel. As
shown in FIG. 3, since outputs from 5.1 channels are all present on a same plane, the 5.1
channel system corresponds to a 2D system in a physical manner, and in order for the 5.1
channel system to reproduce a 3D audio signal, a rendering process has to be performed to
apply a 3D effect to a signal to be reproduced.
[00106]      The 5.1 channel system is widely used in various fields including movies, DVD
videos, DVD audios, Super Audio Compact Discs (SACDs), digital broadcasting, and the like.
However, even if the 5.1 channel system provides an improved spatial perception, compared
to the stereo system, the 5.1 channel system has many limits in forming a larger hearing space.
In particular, a sweet spot is narrowly formed, and a vertical sound image having an elevation
angle cannot be provided, such that the 5.1 channel system may not be appropriate for a
large-scale hearing space such as a theater.
                                                 14

[00107]     The 22.2 channel system presented by the NHK consists of three layers of output
channels as shown in FIG. 3. An upper layer 310 includes Voice of God (VOG), TO, T180,
TL45, TL90, TL135, TR45, TR90, and TR45 channels. Here, an index T at the front of a
name of each channel means an upper layer, an index L or R means a left side or a right side,
and a number at the rear means an azimuth angle from a center channel. The upper layer is
commonly called the top layer.
[00108]     The VOG channel is a channel that is above a head of a listener, has an elevation
angle of 90 degrees, and does not have an azimuth angle. When a location of the VOG
channel is slightly changed, the VOG channel has the azimuth angle and has an elevation
angle that is not 90 degrees, and in this case, the VOG channel may no longer be a VOG
channel.
[00109]     A middle layer 320 is on a same plane as the 5.1 channels, and includes ML60,
ML90, ML135, MR60, MR90, and MR135 channels, in addition to output channels of the 5.1
channels. Here, an index M at the front of a name of each channel means a middle layer, and
a number at the rear means an azimuth angle from a center channel.
[00110]     A low layer 330 includes LO, LL45, and LR45 channels. Here, an index L at the
front of a name of each channel means a low layer, and a number at the rear means an
azimuth angle from a center channel.
[00111]     In the 22.2 channels, the middle layer is called a horizontal channel, and the VOG,
TO, T180, T180, M180, L, and C channels whose azimuth angle is 0 degree or 180 degrees
are called vertical channels.
[00112]     When a 22.2 channel input signal is reproduced via the 5.1 channel system, the
most general scheme is to distribute signals to channels by using a downmix formula.
Alternatively, by performing rendering to provide a virtual elevation, the 5.1 channel system
may reproduce an audio signal having an elevation.
[00113]     FIG. 4 illustrates a panning unit in an example where a positional deviation occurs
between a standard layout and an arrangement layout of output channels, according to an
embodiment.
[00114]     When a multichannel input audio signal is reproduced by using the number of
output channels smaller than the number of channels of an input signal, an original sound
image may be distorted, and in order to compensate for the distortion, various techniques are
being studied.
[00115]     General rendering techniques are designed to perform rendering, provided that
speakers, i.e., output channels, are arranged according to the standard layout. However, when
                                                 15

the output channels are not arranged to accurately match the standard layout, distortion of a
location of a sound image and distortion of a sound quality occur.
[00116]     The distortion of the sound image widely includes distortion of the elevation,
distortion of a phase angle, or the like that are not sensitive in a relatively low level. However,
due to a physical characteristic of a human body where both ears are located in left and right
sides, if sound images of left-center-right sides are changed, the distortion of the sound image
may be sensitively perceived. In particular, a sound image of a front side may be further
sensitively perceived.
[00117]     Therefore, as shown in FIG. 3, when the 22.2 channels are realized via the 5.1
channels, it is particularly required not to change sound images of the VOG, TO, T180, T180,
M180, L, and C channels located at 0 degree or 180 degrees, rather than left and right
channels.
[00118]     When an audio input signal is panned, basically, two processes are performed.
The first process corresponds to an initializing process in which a panning coefficient with
respect to an input multichannel signal is calculated according to a standard layout of output
channels. In the second process, a calculated coefficient is modified based on a layout with
which the output channels are actually arranged. After the panning coefficient modifying
process is performed, a sound image of an output signal may be present at a more accurate
location.
[00119]     Therefore, in order for the panning unit 123 to perform processing, information
about the standard layout of the output channels and information about the arrangement
layout of the output channels are required, in addition to the audio input signal. In a case
where the C channel is rendered from the L channel and the R channel, the audio input signal
indicates an input signal to be reproduced via the C channel, and an audio output signal
indicates modified panning signals output from the L channel and the R channel according to
the arrangement layout.
[00120]     When an elevation deviation is present between the standard layout and the
arrangement layout of the output channels, a 2D panning method considering only an azimuth
deviation does not compensate for an effect due to the elevation deviation. Therefore, if the
elevation deviation is present between the standard layout and the arrangement layout of the
output channels, an elevation increase effect due to the elevation deviation has to be
compensated for by using an elevation effect compensating unit 124 of FIG. 4.
[00121]     FIG. 5 is a block diagram illustrating configurations of a decoder and a 3D audio
renderer in the 3D audio reproducing apparatus, according to an embodiment.
                                                 16

[00122]     Referring to FIG. 5, the 3D audio reproducing apparatus 100 according to an
embodiment is shown with respect to configurations of a decoder 110 and a 3D audio
renderer 120, and other configurations are omitted.
[00123]     An audio signal input to the 3D audio reproducing apparatus 100 is an encoded
signal that is input in a bitstream form. The decoder 110 selects a decoder appropriate for a
format of the encoded audio signal, decodes the input audio signal, and transmits the decoded
audio signal to the 3D audio renderer 120.
[00124]     The 3D audio renderer 120 consists of an initializing unit 125 configured to obtain
and update a filter coefficient and a panning coefficient, and a rendering unit 127 configured
to perform filtering and panning.
[00125]     The rendering unit 127 performs filtering and panning on the audio signal
transmitted from the decoder 110. A filtering unit 1271 processes information about a
location of audio and thus makes the rendered audio signal reproduced at a desired location,
and a panning unit 1272 processes information about a sound quality of audio and thus makes
the rendered audio signal have a sound quality mapped to the desired location.
[00126]     The filtering unit 1271 and the panning unit 1272 perform similar functions as
those of the filtering unit 121 and the panning unit 123 described with reference to FIG. 2.
However, the filtering unit 121 and the panning unit 123 of FIG. 2 are displayed in simple
forms where an initializing unit, or the like to obtain a filter coefficient and a panning
coefficient may be omitted.
[00127]     Here, the filter coefficient for performing filtering and the panning coefficient for
performing panning are provided from the initializing unit 125. The initializing unit 125
consists of an elevation rendering parameter obtaining unit 1251 and an elevation rendering
parameter updating unit 1252.
[00128]     The elevation rendering parameter obtaining unit 1251 obtains an initial value of
an elevation rendering parameter by using a configuration and arrangement of an output
channel, i.e., a loudspeaker. Here, the initial value of the elevation rendering parameter may
be calculated based on a configuration of an output channel according to the standard layout
and a configuration of an input channel according to elevation rendering setting, or an initial
value previously stored according to a mapping relationship between input/output channels is
read. The elevation rendering parameter may include the filter coefficient to be used by the
elevation rendering parameter obtaining unit 1251 or the panning coefficient to be used by
the elevation rendering parameter updating unit 1252.
                                                  17

[00129]     However, as described above, an elevation setting value for rendering an elevation
may have a deviation with respect to setting of the input channel. In this case, if a fixed
elevation setting value is used, it is difficult to achieve an objective of virtual rendering for
similarly three-dimensionally reproducing an original 3D audio signal by using an output
channel different from an input channel.
[00130]     For example, when an elevation is too high, a sound image is small and a sound
quality deteriorates, and when the elevation is too low, it is difficult to feel an effect of virtual
rendering. Accordingly, it is required to adjust the elevation according to a user's setting or a
virtual rendering level appropriate for the input channel.
[00131]     The elevation rendering parameter updating unit 1252 updates initial values of the
elevation rendering parameter, which were obtained by the elevation rendering parameter
obtaining unit 1251, based on elevation information of the input channel or a user-set
elevation. Here, if a speaker layout of an output channel has a deviation with respect to the
standard layout, a process for compensating for an effect due to the difference may be added.
The deviation of the output channel may include deviation information according to a
difference between elevation angles or azimuth angles.
[00132]     An output audio signal that is filtered and panned by the rendering unit 127 using
the elevation rendering parameter obtained and updated by the initializing unit 125 is
reproduced via speakers corresponding to the output channels, respectively.
[00133]     FIGS. 6 through 8 illustrate layouts of upper layer channels according to
elevations of upper layers in a channel layout, according to an embodiment.
[00134]     When it is assumed that an input channel signal is a 22.2 channel 3D audio signal
and is arranged according to the layout shown in FIG. 3, an upper layer of an input channel
has a layout shown in FIG. 4, according to elevation angles. Here, it is assumed that the
elevation angles are 0 degree, 25 degrees, 35 degrees, and 45 degrees, and a VOG channel
corresponding to 90 degrees of an elevation angle is omitted. Upper layer channels having an
elevation angle of 0 degree are present on a horizontal plane (the middle layer 320).
[00135]     FIG. 6 illustrates a front view layout of upper layer channels.
[00136]     Referring to FIG. 6, each of eight upper layer channels has an azimuth angle
difference of 45 degrees, thus, when the upper layer channels are viewed at a front side with
respect to a vertical channel axis, in six channels excluding a TL90 channel and a TR90
channel, each two channels, i.e., a TL45 channel and a TL135 channel, a TO channel and a
T180 channel, and a TR45 channel and a TR135 channel, are overlapped. This is more
apparent compared to FIG. 8.
                                                   18

[00137]      FIG. 7 illustrates a top view layout of the upper layer channels. FIG. 8 illustrates a
3D view layout of the upper layer channels. It is possible to see that the eight upper layer
channels are arranged at regular intervals while each having an azimuth angle difference of
45 degrees.
[00138]      When content to be reproduced with 3D audio via elevation rendering is fixed to
have an elevation angle of 35 degrees, the elevation rendering with the elevation angle of 35
degrees may be performed on all input audio signals, so that an optimal result will be
achieved.
[00139]      However, an elevation angle may be differently applied to a 3D audio of content,
depending on a plurality of pieces of content, and as shown in FIGS. 6 through 8, according
to an elevation of each of channels, locations and distances of the channels vary, and signal
characteristics due to the variance also vary.
[00140]      Therefore, when virtual rendering is performed at a fixed elevation angle,
distortion of a sound image occurs , and in order to achieve an optimal rendering performance,
it is necessary to perform rendering, in consideration of an elevation angle of an input 3D
audio signal, i.e., an elevation angle of an input channel.
[00141]      FIGS. 9 through 11 illustrate variation of a sound image and variation of an
elevation filter, according to elevations of a channel, according to an embodiment.
[00142]      FIG. 9 illustrates locations of channels when elevations of height channels are 0
degree, 35 degrees, and 45 degrees, respectively. FIG. 9 is taken at a rear of a listener, and
each of the illustrated channels is a ML90 channel or a TL90 channel. When an elevation
angle is 0 degree, a channel is present on a horizontal plane and corresponds to the ML90
channel, and when the elevation angle is 35 degrees and 45 degrees, channels are upper layer
channels and correspond to the TL90 channel.
[00143]      FIG. 10 illustrates a signal difference between left and right ears of a listener,
when audio signals are output from respective channels located as shown in FIG. 9.
[00144]      When the audio signal is output from an ML90 having no elevation angle,
theoretically, the audio signal is perceived only via the left ear and is not perceived via the
right ear.
[00145]      However, as an elevation is increased, a difference between audio signals
perceived via the left ear and the right ear is decreased, and when an elevation angle of a
channel is increased and thus becomes 90 degrees, the channel becomes a VOG channel
above a head of the listener, thus, both ears perceive a same audio signal.
                                                  19

[00146]     Therefore, variation with respect to an audio signal perceived by both ears
according to elevation angles is as shown FIG. 7B.
[00147]     With respect to an audio signal perceived via the left ear when the elevation angle
is 0 degree, only the left ear perceives the audio signal whereas the right ear does not perceive
the audio signal. In this case, Interaural Level Differences (ILD) and Interaural Time
Differences (ITD) are maximal, and the listener perceives the audio signal as a sound image
of the ML90 channel existing on a left horizontal plane channel.
[00148]     With respect to a difference between audio signals perceived via the left and right
ears when the elevation angle is 35 degrees and audio signals perceived via the left and right
ears when the elevation angle is 45 degree, since the elevation angle is increased, the
difference between the audio signals perceived via the left and right ears is decreased, and
due to the difference, the listener may feel a difference of elevations in the output audio
signal.
[00149]     An output signal from a channel with the elevation angle of 35 degrees is
characterized in a large sound image, a large sweet spot, and a natural sound quality,
compared to an output signal from a channel with the elevation angle of 45 degrees, and the
output signal from the channel with the elevation angle of 45 degrees is characterized in a
small sound image, a small sweet spot, and a sound field feeling providing an intense
immersive feeling, compared to the output signal from the channel with the elevation angle of
35 degrees.
[00150]     As described above, as the elevation angle is increased, the elevation is also
increased, so that the immersive feeling becomes intense, but a width of an audio signal is
decreased. This is because, as the elevation angle is increased, a physical location of a
channel becomes closer and thus is close to the listener.
[00151]     Therefore, an update of a panning coefficient according to the variance of the
elevation angle is determined below. As the elevation angle is increased, the panning
coefficient is updated to make the sound image larger, and as the elevation angle is decreased,
the panning coefficient is updated to make the sound image smaller.
[00152]     For example, it is assumed that a basically-set elevation angle is 45 degrees for
virtual rendering, and the virtual rendering is to be performed by decreasing the elevation
angle to 35 degrees. In this case, a rendering panning coefficient to be applied to a virtual
channel to be rendered and an ipsilateral output channel is increased, and a panning
coefficient to be applied to residual channels is determined via power normalization.
                                                20

[00153]     For more specific description, it is assumed that a 22.2 input multichannel signal
is to be reproduced via 5.1 output channels (speakers). In this case, from among 22.2 input
channels, input channels to which the virtual rendering is applied and have elevation angles
are nine channels that are CH_U_000(TO), CH_U_L45(TL45), CH_U_R45(TR45),
CH_UL90(TL90), CHUR90(TR90), CHUL135(TL135), CH_U_R135(TR135),
CH_U_180(T180), and CH_T_000(VOG), and the 5.1 output channels are five channels
(except for a woofer channel) that are CH_M_000, CHM_L030, CH_M_R030,
CH_M_Li 10, and CH_R_110 existing on a horizontal plane.
[00154]     In this manner, in a case where the CH_U_L45 channel is rendered by using the
5.1 output channels, when the basically-set elevation angle is 45 degrees and the elevation
angle is attempted to be decreased to 35 degrees, the panning coefficient to be applied to
CH_M_L030 and CH_M_Li 10 that are ipsilateral output channels of the CH_U_L45 channel
is updated to be increased by 3 dB, and the panning coefficient of residual three channels is
updated to be decreased, so that             is satisfied. Here, N indicates the number of
output channels for rendering a random virtual channel, and gindicates a panning coefficient
to be applied to each output channel.
[00155]     This process has to be performed on each of height input channel.
[00156]     On the other hand, it is assumed that the basically-set elevation angle is 45
degrees for virtual rendering, and the virtual rendering is to be performed by increasing the
elevation angle to 55 degrees. In this case, the rendering panning coefficient to be applied to a
virtual channel to be rendered and an ipsilateral output channel is decreased, and the panning
coefficient to be applied to residual channels is determined via power normalization.
[00157]     When the CH_U_L45 channel is rendered by using the 5.1 output channels, if the
basically-set elevation angle is increased from 45 degrees to 55 degrees, the panning
coefficient to be applied to CH_M_L030 and CH_M_Li 10 that are the ipsilateral output
channels of the CH_U_L45 channel is updated to be decreased by 3 dB, and the panning
                                                                                  N
                                                                                   1g,=
coefficient of the residual three channels is updated to be increased, so that   i=1      is
satisfied. Here, N indicates the number of output channels for rendering a random virtual
channel, and giindicates a panning coefficient to be applied to each output channel.
                                                 21

[00158]       However, when the elevation is increased in the aforementioned manner, it is
necessary not to reverse left and right sound images due to the update of the panning
coefficient, and this is described with reference to FIG. 8.
[00159]       Hereinafter, a method of updating a tone color filter coefficient will be described
with reference to FIG. 11.
[00160]       FIG. 11 illustrates characteristics of a tone color filter according to frequencies
when an elevation angle of a channel is 35 degrees and an elevation angle is 45 degrees.
[00161]       As illustrated in FIG. 11, it is apparent that a characteristic due to an elevation
angle is highly noticeable in the tone color filter of the channel with the elevation angle of 45
degrees, compared to the tone color filter of the channel with the elevation angle of 35
degrees.
[00162]       In a case where virtual rendering is performed to have an elevation angle greater
than a reference elevation angle, when rendering is performed on the reference elevation
angle, a more increase (an updated filter coefficient is increased to be greater than 1) occurs
in a frequency band (where an original filter coefficient is greater than 1) whose magnitude is
required to be increased, and a more decrease (the updated filter coefficient is decreased to be
less than 1) occurs in a frequency band (where the original filter coefficient is less than 1)
whose magnitude is required to be decreased.
[00163]       When filter magnitude characteristics are expressed in a decibel scale, as shown in
FIG. 11, the tone color filter has a positive value is shown in a frequency band where
magnitude of an output signal is required to be increased, and has a negative value in a
frequency band where magnitude of an output signal is required to be decreased. In addition,
as apparent in FIG. 11, as an elevation angle is decreased, a shape of filter magnitude
becomes flat.
[00164]       When a height channel is virtually rendered by using a horizontal plane channel,
as the elevation angle is decreased, the height channel has a tone color similar to a signal of a
horizontal plane, and as the elevation angle is increased, a change in an elevation is
significant, so that, as the elevation angle is increased, an effect according to the tone color
filter is increased so that an elevation effect due to an increase in the elevation angle is
emphasized. On the other hand, as the elevation angle is increased, the effect according to the
tone color filter is decreased so that the elevation effect may be decreased.
[00165]       Therefore, the update of the filter coefficient according to the change in the
elevation angle is performed by updating the original filter coefficient by using a basically-set
elevation angle and a weight based on an elevation angle to be actually rendered.
                                                   22

[00166]      In a case where the basically-set elevation angle for virtual rendering is 45 degrees,
and an elevation is decreased by performing rendering to 35 degrees lower than the basic
elevation angle, coefficients corresponding to a filter of 45 degrees of FIG. 11 are determined
as initial values and are required to be updated to coefficients corresponding to a filter of 35
degrees.
[00167]      Therefore, in a case where it is attempted to decrease an elevation by performing
rendering to 35 degrees that is the elevation angle lower than 45 degrees that is the basic
elevation angle, the filter coefficient has to be updated so that a valley and floor of a filter
according to a frequency band are modified to be more smooth than those of the filter of 45
degrees.
[00168]      On the other hand, in a case where the basically-set elevation angle is 45 degrees,
and an elevation is increased by performing rendering to 55 degrees higher than the basic
elevation angle, the filter coefficient has to be updated so that a valley and floor of a filter
according to a frequency band are modified to be more sharp than those of the filter of 45
degrees.
[00169]      FIG. 12 is a flowchart of a method of rendering a 3D audio signal, according to an
embodiment.
[00170]      A renderer receives a multichannel audio signal including a plurality of input
channels (1210). The input multichannel audio signal is converted to a plurality of output
channel signals via rendering, and in a downmix example where the number of output
channels is smaller than the number of input channels, an input signal having 22.2 channels is
converted to an output channel having 5.1 channels.
[00171]      In this manner, when a 3D audio input signal is rendered by using 2D output
channels, general rendering is applied to input channels on a horizontal plane, and virtual
rendering is applied to height channels each having an elevation angle so as to apply an
elevation thereto.
[00172]      In order to perform rendering, a filter coefficient to be used in filtering and a
panning coefficient to be used in panning are required. Here, in an initialization process, a
rendering parameter is obtained according to a standard layout of an output channel and a
basically-set elevation angle for the virtual rendering (1220). The basically-set elevation
angle may be variously determined according to the renderer, but when the virtual rendering
is performed at a fixed elevation angle, satisfaction and an effect of the virtual rendering may
be decreased according to user's preference or a characteristic of an input signal.
                                                  23

[00173]      Therefore, when a configuration of an output channel has a deviation with respect
to a standard layout of the output channel, or when an elevation at which the virtual rendering
is to be performed is different from the basically-set elevation angle of the renderer, the
rendering parameter is updated (1230).
[00174]      Here, the updated rendering parameter may include a filter coefficient updated by
adding, to an initial value of the filter coefficient, a weight determined based on an elevation
angle deviation, or may include a panning coefficient updated by increasing or decreasing an
initial value of a panning coefficient according to a result of comparing an elevation angle of
an input channel with the basically-set elevation angle.
[00175]      A detailed method of updating the filter coefficient and the panning coefficient is
already described with reference to FIGS. 9 through 11, and thus descriptions are omitted. In
this regard, the updated filter coefficient and the updated panning coefficient may be
additionally modified or extended, and descriptions thereof will be provided in detail at a
later time.
[00176]      If a speaker layout of the output channel has a deviation with respect to the
standard layout, a process for compensating for an effect due to the deviation may be added
but descriptions of a detailed method thereof are omitted here. The deviation of the output
channel may include deviation information according to a difference between elevation
angles or azimuth angles.
[00177]      FIG. 13 illustrates a phenomenon where left and right sound images are reversed
when an elevation angle of an input channel is equal to or greater than a threshold value,
according to an embodiment.
[00178]      A person distinguishes between locations of sound images, according to time
differences, level differences, and frequency differences of sounds that arrive at both ears of
the person. When differences between characteristics of signals that arrive at both ears are
great, the person may easily localize the locations, and even if a small error occurs,
front-back confusion or left-right confusion with respect to the sound images does not occur.
However, a virtual audio source located in a right rear side or right front side of a head has a
very small time difference and a very small level difference, so that the person has to localize
the location by using only a difference between frequencies.
[00179]      As in FIG. 10, in FIG. 13, a square-shape channel is a CH_U_L90 channel in the
rear side of a listener. Here, when an elevation angle of CH_U_L90 is (P, as q is increased,
ILD and ITD of audio signals that arrive at a left ear and a right ear of the listener are
                                                   24

decreased, and the audio signals perceived by both ears have similar sound images. A
maximum value of the elevation angle (p is 90 degrees, and when p is 90 degrees, the
CH_U_L90 becomes a VOG channel existing above a head of the listener, thus, same audio
signals are received via both ears.
[00180]      As shown in a left diagram of FIG. 13, if (p has a significantly great value, an
elevation is increased so that the listener may feel a sound field feeling providing an intense
immersive feeling. However, when the elevation is increased, a sound image becomes small
and a sweet spot becomes small, such that, even if a location of the listener is slightly
changed or a channel is slightly moved, a left-right reversal phenomenon may occur with
respect to the sound image.
[00181]      A right diagram of FIG. 13 illustrates locations of the listener and the channel
when the listener slightly moved left. This is a case where an elevation is highly formed since
the elevation angle (p of the channel has a large value, thus, even if the listener slightly
moves, relative locations of left and right channels are significantly changed, and in a worst
case, although it is a left-side channel, a signal that arrives at the right ear is further
significantly perceived, such that a left-right reversal of a sound image as shown in FIG. 13
may occur.
[00182]      In a rendering process, it is more important to maintain a left and right balance of
a sound image and to localize left and right locations of the sound image than to apply an
elevation, thus, in order to prevent the aforementioned phenomenon, it may be necessary to
limit an elevation angle for virtual rendering within a predetermined range.
[00183]      Therefore, in a case where a panning coefficient is decreased when an elevation
angle is increased to achieve a higher elevation than a basically-set elevation angle for
rendering, it is necessary to set a minimum threshold value of the panning coefficient not to
be equal to or lower than a predetermined value.
[00184]      For example, even if a rendering elevation of 60 degrees is increased to be equal
to or greater than 60 degrees, when panning is performed by compulsorily applying a panning
coefficient that is updated with respect to a threshold elevation angle of 60 degrees, the
left-right reversal phenomenon of the sound image may be prevented.
[00185]      When 3D audio is generated by using virtual rendering, a front-back confusion
phenomenon of an audio signal may occur due to a reproduction component of a surround
                                                  25

channel. The front-back confusion phenomenon means a phenomenon by which it is difficult
to determine whether a virtual audio source in the 3D audio is present in the front side or the
back side.
[00186]     With reference to FIG. 13, it is assumed that the listener moved, however, it is
obvious to one of ordinary skill in the art that, as a sound image is increased, even if the
listener does not move, there is a high possibility that the left-right confusion or the
front-back confusion occurs due to a characteristic of an auditory organ of each person.
[00187]     Hereinafter, a method of initializing and updating an elevation rendering
parameter, i.e., an elevation panning coefficient and an elevation filter coefficient, will be
described in detail.
[00188]     When an elevation angle elv of a height input channel ignis greater than 35
degrees, if i,. is a frontal channel (an azimuth angle is between - 90 degrees through + 90
degrees), an updated elevation filter coefficient EQsR(eq(i 1.)) is determined according to
Equations 1 through 3.
[00189]     [Equation 1]
                              =  20 x log     EQj.(eq(i)))
                                              0
                                                                    - 0.05 X logf2 (fk X f/6000)
[00190]     EQ d(el))
[00191]     [Equation 2]
            EQ2,db(eq(-.)) = EQkta(eq(ij)) X (mi             (max(elv - 35,0), 25) X 0.3)
[00192]
[00193]     [Equation 3]
[00194]     EQR (eq0jn)) =      10 $(EQdb                      2 (fkxf1 /6000)
                                              "q(i.)))/20-0.OSXs
[00195]     On the other hand, when the elevation angle elv of the height input channel i 1 is
greater than 35 degrees, if is is a rear channel (the azimuth angle is between - 180 degrees
through - 90 degrees or 90 degrees through 180 degrees ), the updated elevation filter
coefficient EQtaR(eq(0in)) is determined according to Equations 4 through 6.
[00196]     [Equation 4]
                                                 26

                                                                                   x log 2 (fk X f./6000)
[00197]     E       eEQdb(q(n)    =  20 x log,, (EQkai.(eq(ii.))) + 0.07
[00198]     [Equation 5]
[00199]     EQk,(eq(n))           =  EQXb(eq(iin)) X (min (max(elv             -  35,0),25) x 0.3)
[00200]     [Equation 6]
[00201]     EQ    (eq(n)) = 10 (Q*db               "(i.)))/20-0.07XIog
                                                                     2 (fiXf,/600)
where, fk is a normalized center frequency of a kh frequency band, fs is a sampling
frequency, and EQ106n(eq(i.)) is an initial value of the elevation filter coefficient at a
reference elevation angle.
[00202]     When an elevation angle for elevation rendering is not the reference elevation
angle, an elevation panning coefficient with respect to height input channels except for the
TBC channel (CH_U_180) and the VOG channel (CHT_000) have to be updated.
[00203]     When the reference elevation angle is 35 degrees and i,                 is the TFC channel
(CHU_000), the updated elevation panning coefficients GV0S(t)                      and G,6(tfl) are
determined according to Equations 7 and 8, respectively.
[00204]     [Equation 7]
[00205]     G'HS tf.) =     10   (O.2sxmin (max(elv-3sO),2s))/20   x GVH'otil)
[00206]     [Equation 8]
[00207]     GvH6,(xe) =     1  0 (O.2sxmin (max(elv-35,O),25))/20  X   GHo,6 (i)
where, GvHOsAtn) is a panning coefficient of an SL output channel for virtually rendering a
TFC channel by using the reference elevation angle of 35 degrees, and GVHo,6(tf)                    is a
panning coefficient of an SR output channel for virtually rendering the TFC channel by using
the reference elevation angle of 35 degrees.
                                                      27

[00208]     With respect to the TFC channel, it is impossible to adjust left and right channel
gains so as to control an elevation, thus, a ratio of a gain with respect to the SL channel and
the SR channel that are rear channels of the frontal channel is adjusted so as to control the
elevation. Detailed descriptions are provided below.
[00209]     With respect to other channels except for the TFC channel, when an elevation
angle of a height input channel is greater than the reference elevation angle of 35 degrees, a
gain of an ipsilateral channel of an input channel is decreased, and a gain of a contralateral
channel of the input channel is increased, due to a gain difference between g,(elv) and
gc (elv).
[00210]     For example, when the input channel is a CH_U_L045 channel, an ipsilateral
output channel of the input channel is CH_M_L030 and CH_M_L1 10, and a contralateral
output channel of the input channel is CH_M_R030 and CH_M_R 110.
[00211]     Hereinafter, a method of obtaining g,(elv) and ge (elv) and updating an
elevation panning gain therefrom, when an input channel is a side channel, a frontal channel,
or a rear channel, will be described in detail.
[00212]     When the input channel having an elevation angle elv is the side channel (an
azimuth angle is between - 110 degrees through - 70 degrees or 70 degrees through 110
degrees), g,(elv) and gc(elv) are determined according to Equations 9 and 10,
respectively.
[00213]     [Equation 9]
[00214]     g 1 (elv) = 1o(-O.OSs22xmin(max(Clv-3s,O),2s)/20
[00215]     [Equation 10]
[00216]     gc (elv)  = 1 OL4179Xmin   (max( eIv-3O),2s))/20
[00217]     When the input channel having the elevation angle elv is the frontal channel (the
azimuth angle is between - 70 degrees through + 70 degrees) or the rear channel (the azimuth
angle is between - 180 degrees through - 110 degrees or 110 degrees through 180 degrees),
g,(elv) and gc(elv) are determined according to Equations 11 and 12, respectively.
                                                  28

[00218]     [Equation 11]
[00219]     g 1 (elv) =  10 -0.047401 xmin (ax(e-3s.O),2s))/20
[00220]     [Equation 12]
[00221]     ge(elv) =    10  (O.1498sxmin (max(elv-3s,0),25))/20
[00222]     Based on gr(elv) and gc(elv) calculated by using Equations 9 through and 12,
the elevation panning coefficients may be updated.
[00223]     An updated elevation panning coefficient GVHI(n)       with respect to the ipsilateral
output channel of the input channel, and an updated elevation panning coefficient GvH,cijn)
with respect to the contralateral output channel of the input channel are determined according
to Equations 13 and 14, respectively.
[00224]     [Equation 13]
[00225]     GvHI(iin) =    g, (elv) x GHoji)
[00226]     [Equation 14]
[00227]     GvH,CAin) = gc(elv) X GVHO,cif.)
[00228]     In order to constantly maintain an energy level of an output signal, the panning
coefficients obtained by using Equations 13 and 14 are normalized according to Equations 15
and 16.
[00229]     [Equation 15]
[00230]     PGvH (n                 G        )
[00231]     [Equation 16]
[00232]     Gv,1.. 6 (i)    =       GvH,1-61n)
                               ~GvH
[00233]     In this manner, a power normalize process is performed so that a total sum of a
square of the panning coefficients of the input channel becomes 1, and by doing so, an energy
level of an output signal before the panning coefficients are updated and an energy level of
the output signal after the panning coefficients are updated may be equally maintained.
                                                    29

[00234]      In GVHAJ.in) and GvncH(in4), an index H indicates that an elevation panning
coefficient is updated only in a high frequency domain. The updated elevation panning
coefficients of Equations 13 and 14 are applied only to a high frequency band, 2.8 kHz
through 10 kHz bands. However, when the elevation panning coefficient is updated with
respect to a surround channel, the elevation panning coefficient is updated not only with
respect to the high frequency band but also with respect to a low frequency band.
[00235]      When the input channel having the elevation angle elv is the surround channel
(the azimuth angle is between - 160 degrees through - 110 degrees or 110 degrees through
160 degrees), an updated elevation panning coefficient G, ,(is) with respect to an
ipsilateral output channel of the input channel in a low frequency band of 2.8 kHz or below,
and an updated elevation panning coefficient GVLc 0(.) with respect to a contralateral output
channel of the input channel are determined according to Equations 17 and 18, respectively.
[00236]      [Equation 17]
[00237]      GvLrfln)  =  gE(elv) X  GvLOr(ifi)
[00238]      [Equation 18]
[00239]      GvLCe i)   -- g(elv) X GvLo,C if)
[00240]      As in the high frequency band, in order for the updated elevation panning gain of
the low frequency band to constantly maintain an energy level of an output signal, the
panning coefficients obtained by using Equations 15 and 16 are power normalized according
to Equations 19 and 20.
[00241]      [Equation 19]
[00242]      PvL (in)  =          G L(if)
[00243]      [Equation 20]
[00244]      GvLl(igl) =       I  GvLA.(in)
                             PGvL
[00245]      In this manner, the power normalize process is performed so that a total sum of a
square of the panning coefficients of the input channel becomes 1, and by doing so, an energy
                                                30

level of an output signal before the panning coefficients are updated and an energy level of
the output signal after the panning coefficients are updated may be equally maintained.
[00246]     FIGS. 14 through 17 are diagrams for describing a method of preventing
front-back confusion of a sound image, according to an embodiment.
[00247]     FIG. 14 illustrates horizontal channels and frontal height channels, according to an
embodiment.
[00248]     Referring to the embodiment shown in FIG. 14, it is assumed that an output
channel is 5.0 channels (a woofer channel is now shown) and frontal height input channels
are rendered to horizontal output channels. The 5.0 channels are present on a horizontal plane
1410 and include a Front Center (FC) channel, a Front Left (FL) channel, a Front Right (FR)
channel, a Surround Left (SL) channel, and a Surround Right (SR) channel.
[00249]     The frontal height channels are channels corresponding to an upper layer 1420 of
FIG. 14, and in the embodiment shown in FIG. 14, the frontal height channels include a Top
Front Center (TFC) channel, a Top Front Left (TFL) channel, and a Top Front Right (TFR)
channel.
[00250]     When it is assumed that, in the embodiment shown in FIG. 14, an input channel is
22.2 channels, input signals of 24 channels are rendered (downmixed) to generate output
signals of 5 channels. Here, components that respectively correspond to the input signals of
the 24 channels are distributed in the 5 channel output signal according to a rendering rule.
Therefore, the output channels, i.e., the Front Center (FC) channel, the Front Left (FL)
channel, the Front Right (FR) channel, the Surround Left (SL) channel, and the Surround
Right (SR) channel respectively include components corresponding to the input signals.
[00251]     In this regard, the number of the frontal height channels, the number of the
horizontal channels, azimuth angles, and elevation angles of height channels may be
variously determined according to a channel layout. When the input channel is the 22.2
channels or 22.0 channels, the frontal height channel may include at least one of CH_U_L030,
CH_U_R030, CH_U_L045, CH_U_R045, and CH_U_000. When the output channel is the
5.0 channels or 5.1 channels, the surround channel may include at least one of CH_M_L110
and CH_M_R10.
[00252]     However, it is obvious to one of ordinary skill in the art that, even if input and
output multiple channels do not match the standard layout, a multichannel layout may be
variously configured according to an elevation angle and an azimuth angle of each channel.
[00253]     When a height input channel signal is virtually rendered by using the horizontal
output channels, a surround output channel acts to increase an elevation of a sound image by
                                                31

applying the elevation to sound. Therefore, when signals from the horizontal height input
channels are virtually rendered to the 5.0 output channels that are the horizontal channels, the
elevation may be applied and adjusted by output signals from the SL channel and the SR
channels that are the surround output channels.
[00254]      However, since the HRTF is unique to each person, a front-back confusion
phenomenon may occur, in which a signal that was virtually rendered to the frontal height
channel is perceived as it sounds in the rear side according to an HRTF characteristic of a
listener.
[00255]      FIG. 15 illustrates a perception percentage of frontal height channels, according to
an embodiment.
[00256]      FIG. 15 illustrates a percentage that, when a frontal height channel, i.e., a TFR
channel, is virtually rendered by using a horizontal output channel, a user localizes a location
(front and rear) of a sound image. With reference to FIG. 15, a height recognized by the user
corresponds to a height channel 1420 and a size of a circle is in proportion to a value of the
possibility.
[00257]      Referring to FIG. 15, although most users localize the sound image at 45 degrees
on the right side which is a location of a virtually rendered channel, many users localize the
sound image at another location rather than 45 degrees. As described above, this phenomenon
occurs since the HRTF characteristic differs in people, it is possible to see that a certain user
even localizes the sound image at the rear side further extending than 90 degrees on the right
side.
[00258]      The HRTF indicates a transfer path of audio from an audio source in a point in
space adjacent to a head to an eardrum, which is mathematically expressed as a transfer
function. The HRTF significantly varies according to a location of the audio source relative
to a center of the head, and a size or shape of the head or pinna. In order to accurately portray
a virtual audio source, the HRTFs of target people have to be individually measured and used,
which is actually impossible. Thus, in general, a non-individualized HRTF measured by
arranging a microphone at an eardrum position of a mannequin similar to a human body is
used.
[00259]      When the virtual audio source is reproduced by using the non-individualized
HRTF, if a head or pinna of a person does not match the mannequin or a dummy head
microphone system, various problems related to sound image localization occur. A deviation
of localized degrees on a horizontal plane may be compensated for by taking into account a
                                                 32

head size of a person, but since a size or shape of the pinna differs in people, it is difficult to
compensate for a deviation of an elevation or a front-back confusion phenomenon.
[00260]      As described above, each person has his/her own HRTF according to a size or
shape of a head, however, it is actually difficult to apply different HRTFs to people,
respectively. Therefore, the non-individualized HRTF, i.e., a common HRTF, is used, and in
this case, the front-back confusion phenomenon may occur.
[00261]      Here, when a predetermined time delay is added to a surround output channel
signal, the front-back confusion phenomenon may be prevented.
[00262]      Sound is not equally perceived by everyone and is differently perceived according
to an ambient environment or a psychological state of a listener. This is because a physical
event in space where the sound is delivered is perceived by the listener in a subjective and
sensory manner. An audio signal that is perceived by a listener according to a subjective or
psychological factor is referred to as psychoacoustic. The psychoacoustic is influenced by not
only physical variables including an acoustic pressure, a frequency, a time, etc., but also
affected by subjective variables including loudness, a pitch, a tone color, an experience with
respect to sound, etc.
[00263]      The psychoacoustic may have many effects according to situations, and for
example, may include a masking effect, a cocktail effect, a direction perception effect, a
distance perception effect, and a precedence effect. A technique based on the psychoacoustic
is used in various fields so as to provide a more appropriate audio signal to a listener.
[00264]      The precedence effect is also referred to as the Hass effect in which, when
different sounds are sequentially generated by a time delay of 1 ms through 30 ms, a listener
may perceive that the sounds are generated in a location where first-arriving sound is
generated. However, if a time delay between generation times of two sounds is equal to or
greater than 50 ms, the two sounds are perceived in different directions.
[00265]      For example, when a sound image is localized, if an output signal of a right
channel is delayed, the sound image is moved to the left and thus is perceived as a signal
reproduced in the right side, and this phenomenon is called the precedence effect or the Hass
effect.
[00266]      A surround output channel is used to add an elevation to the sound image, and as
illustrated in FIG. 15, due to a surround output channel signal, the front-back confusion
phenomenon occurs such that some listeners may perceive that a frontal channel signal comes
from a rear side.
                                                33

[00267]     By using the aforementioned precedence effect, the above problem may be solved.
When a predetermined time delay is added to the surround output channel signal to reproduce
a frontal height input channel, compared to signals from frontal output channels which are
present at - 90 degrees through + 90 degrees with respect to the front and are from among
output signals for reproducing a frontal height input channel signal, signals from surround
output channels which are present at - 180 degrees through - 90 degrees or + 90 degrees
through + 180 degrees with respect to the front are reproduced with a delay.
[00268]     Accordingly, even if an audio signal from the frontal input channel may be
perceived as it is reproduced in the rear side, due to a unique HRTF of a listener, the audio
signal is perceived as it is reproduced in the front side where an audio signal is first
reproduced according to the precedence effect.
[00269]     FIG. 16 is a flowchart of a method of preventing front-back confusion, according
to an embodiment.
[00270]     A renderer receives a multichannel audio signal including a plurality of input
channels (1610). The input multichannel audio signal is converted to a plurality of output
channel signals via rendering, and in a downmix example in which the number of output
channels is smaller than the number of input channels, an input signal having 22.2 channels is
converted to an output signal having 5.1 channels or 5.0 channels.
[00271]     In this manner, when a 3D audio input signal is rendered by using a 2D output
channel, general rendering is applied to input channels on a horizontal plane, and virtual
rendering is applied to height channels each having an elevation angle so as to apply an
elevation thereto.
[00272]     In order to perform rendering, a filter coefficient to be used in filtering and a
panning coefficient to be used in panning are required. Here, in an initialization process, a
rendering parameter is obtained according to a standard layout of an output channel and a
basically-set elevation angle for the virtual rendering. The basically-set elevation angle may
be variously determined according to the renderer, and when a predetermined elevation angle,
not the basically-set elevation angle, is set according to user's preference or a characteristic of
an input signal, satisfaction and an effect of the virtual rendering may be improved.
[00273]     In order to prevent the front-back confusion due to a surround channel, a time
delay is added to a surround output channel with respect to a frontal height channel (1620).
[00274]     When a predetermined time delay is added to the surround output channel signal
to reproduce a frontal height input channel, compared to signals from frontal output channels
which are present at - 90 degrees through + 90 degrees with respect to the front and are from
                                                 34

among output signals for reproducing a frontal height input channel signal, signals from
surround output channels which are present at - 180 degrees through - 90 degrees or + 90
degrees through + 180 degrees with respect to the front are reproduced with a delay.
[00275]     Accordingly, even if an audio signal from the frontal input channel may be
perceived as it is reproduced in the rear side, due to a unique HRTF of a listener, the audio
signal is perceived as it is reproduced in the front side where an audio signal is first
reproduced according to the precedence effect.
[00276]     As described above, in order to reproduce the frontal height channel by delaying
the surround output channel with respect to the frontal height channel, the renderer changes
an elevation rendering parameter, based on a delay added to the surround output channel
(1630).
[00277]     When the elevation rendering parameter is changed, the renderer generates an
elevation-rendered surround output channel, based on the changed elevation rendering
parameter (1640). In more detail, rendering is performed by applying the changed elevation
rendering parameter to a height input channel signal, so that a surround output channel signal
is generated. In this manner, the elevation-rendered surround output channel that is delayed
with respect to the frontal height input channel, based on the changed elevation rendering
parameter, may prevent the front-back confusion due to the surround output channel.
[00278]     The time delay applied to the surround output channel is preferably about 2.7 ms
and about 91.5 cm in distance, which corresponds to 128 samples, i.e., two Quadrature Mirror
Filter (QMF) samples in 48 kHz. However, in order to prevent the front-back confusion, the
delay added to the surround output channel may vary according to a sampling rate and a
reproduction environment.
[00279]     Here, when a configuration of an output channel has a deviation with respect to a
standard layout of the output channel, or when an elevation at which the virtual rendering is
to be performed is different from the basically-set elevation angle of the renderer, the
rendering parameter is updated. The updated rendering parameter may include a filter
coefficient updated by adding, to an initial value of the filter coefficient, a weight determined
based on an elevation angle deviation, or may include a panning coefficient updated by
increasing or decreasing an initial value of a panning coefficient according to a result of
comparing an elevation angle of an input channel with the basically-set elevation angle.
[00280]     If the frontal height input channel to be spatially elevation-rendered is present,
delayed QMF samples of the frontal input channel are added to an input QMF sample, and a
downmix matrix is extended to a changed coefficient.
                                                 35

[00281]     A method of adding a time delay to a frontal height input channel and changing a
rendering (downmix) matrix is described in detail below.
[00282]     When the number of input channels is Nin, with respect to an ith input channel
from among [1 Nin] channels, if the       ith input channel is one of height input channels
CH_U_L030, CH_U_L045, CH_U_R030, CH_U_R045, and CH_U_000, a QMF sample
delay of the input channel and a delayed QMF sample are determined according to Equation
21 and Equation 22.
[00283]     [Equation 21]
[00284]     delay = round(fs*0.003/64)
[00285]     [Equation 22]
     [0086]   n~k      nk    n-delay~k
[00286]     y      = [YA y             ]
[00287]     where, fs indicates a sampling frequency, and yr           indicates an nth QMF
sub-band sample of a kth band. The time delay applied to the surround output channel is
preferably about 2.7 ms and about 91.5 cm in distance, which corresponds to 128 samples,
i.e., two QMF samples in 48 kHz. However, in order to prevent the front-back confusion, the
delay added to the surround output channel may vary according to a sampling rate and a
reproduction environment.
[00288]     The changed rendering (downmix) matrix is determined according to Equations
23 through 25.
[00289]     [Equation 23]
[00290]     MDMX = [MDMX MDMX,1~NOutAi
[00291]     [Equation 24]
[00292]     MDMX2     = [MDMX2     [0 0 -- 0 T]
[00293]     [Equation 25]
[00294]     Nin = Nin + 1
where, MOM        indicates a downmix matrix for elevation rendering,        MDMX2    indicates a
downmix matrix for general rendering, and Nout indicates the number of output channels.
[00295]     In order to complete the downmix matrix for each of input channels, Nin is
increased by 1 and a procedure of Equation 3 and Equation 4 is repeated. In order to obtain a
                                                     36

downmix matrix with respect to one input channel, it is required to obtain downmix
parameters for output channels.
[00296]     The downmix parameter of a jth output channel with respect to an ith input channel
is determined as below.
[00297]     When the number of output channels is Nout, with respect to a jth output channel
from among [1 Nout] channels, if the jth output channel is one of surround channels
CH_M_Li 10 and CH_MR1 10, the downmix parameter to be applied to the output channel
is determined according to Equation 26.
[00298]     [Equation 26]
[00299]     MDMx, = 0
[00300]     When the number of output channels is Nout, with respect to the jth output channel
from among [1 Nout], if the jth output channel is not the surround channel CH_M_L 110 or
CH_M_R110, the downmix parameter to be applied to the output channel is determined
according to Equation 27.
[00301]     [Equation 27]
[00302]     MDMXNin     -  0
[00303]     Here, if a speaker layout of the output channel has a deviation with respect to the
standard layout, a process for compensating for an effect due to the difference may be added
but detailed descriptions thereof are omitted. The deviation of the output channel may include
deviation information according to a difference between elevation angles or azimuth angles.
[00304]     FIG. 17 illustrates horizontal channels and frontal height channels when a delay is
added to surround output channels, according to an embodiment.
[00305]     In the embodiment of FIG. 17, likewise to the embodiment of FIG. 14, it is
assumed that an output channel is 5.0 channels (a woofer channel is now shown) and frontal
height input channels are rendered to horizontal output channels. The 5.0 channels are present
on the horizontal plane 1410 and include a Front Center (FC) channel, a Front Left (FL)
channel, a Front Right (FR) channel, a Surround Left (SL) channel, and a Surround Right
(SR) channel.
[00306]     The frontal height channels are channels corresponding to the upper layer 1420 of
FIG. 14, and in the embodiment shown in FIG. 14, the frontal height channels include a Top
Front Center (TFC) channel, a Top Front Left (TFL) channel, and a Top Front Right (TFR)
channel.
                                                37

[00307]    In the embodiment of FIG. 17, likewise to the embodiment of FIG. 14, when it is
assumed that an input channel is 22.2 channels, input signals of 24 channels are rendered
(downmixed) to generate output signals of 5 channels. Here, components that respectively
correspond to the input signals of the 24 channels are distributed in the 5 channel output
signal according to a rendering rule. Therefore, the output channels, i.e., the FC channel, the
FL channel, the FR channel, the SL channel, and the SR channel respectively include
components corresponding to the input signals.
[00308]    In this regard, the number of the frontal height channels, the number of the
horizontal channels, azimuth angles, and elevation angles of height channels may be
variously determined according to a channel layout. When the input channel is the 22.2
channels or 22.0 channels, the frontal height channel may include at least one of CH_U_L030,
CH_U_R030, CH_U_L045, CH_U_R045, and CH_U_000. When the output channel is the
5.0 channels or 5.1 channels, the surround channel may include at least one of CH_M_Li 10
and CHMRi10.
[00309]    However, it is obvious to one of ordinary skill in the art that, even if input and
output multiple channels do not match the standard layout, a multichannel layout may be
variously configured according to an elevation angle and an azimuth angle of each channel.
[00310]    Here, in order to prevent a front-back confusion phenomenon occurring due to the
SL channel and the SR channel, a predetermined delay is added to the frontal height input
channel that is rendered via the surround output channel. An elevation-rendered surround
output channel that is delayed with respect to the frontal height input channel, based on a
changed elevation rendering parameter, may prevent the front-back confusion due to the
surround output channel.
[00311]    The methods of obtaining the elevation rendering parameter changed based on a
delay-added audio signal and an added delay are shown in Equations 1 through 7. As
described in detail in the embodiment of FIG. 16, detailed descriptions thereof are omitted in
the embodiment of FIG. 17.
[00312]    The time delay applied to the surround output channel is preferably about 2.7 ms
and about 91.5 cm in distance, which corresponds to 128 samples, i.e., two QMF samples in
48 kHz. However, in order to prevent the front-back confusion, the delay added to the
surround output channel may vary according to a sampling rate and a reproduction
environment.
[00313]    FIG. 18 illustrates a horizontal channel and a top front center (TFC) channel,
according to an embodiment.
                                               38

[00314]     According to the embodiment shown in FIG. 18, it is assumed that an output
channel is 5.0 channels (a woofer channel is now shown) and the top front center (TFC)
channel is rendered to a horizontal output channel. The 5.0 channels are present on the
horizontal plane 1810 and include a Front Center (FC) channel, a Front Left (FL) channel, a
Front Right (FR) channel, a Surround Left (SL) channel, and a Surround Right (SR) channel.
The TFC channel corresponds to an upper layer 1820 of FIG. 18, and it is assumed that the
TFC channel has 0 azimuth angle and is located with a predetermined elevation angle.
[00315]     As described above, it is very important to prevent a left-right reversal of a sound
image when the audio signal is rendered. In order to render a height input channel having an
elevation angle to a horizontal output channel, it is required to perform virtual rendering, and
multichannel input channel signals are panned to multichannel output signals via rendering.
[00316]     For the virtual rendering that provides an elevated feeling at a particular elevation,
a panning coefficient and a filter coefficient are determined, and in this regard, for a TFT
channel input signal, a sound image has to be located in front of a listener, i.e., at the center,
thus, panning coefficients of the FL channel and the FR channel are determined to make the
sound image of the TFC channel located at the center.
[00317]     In a case where a layout of output channels matches a standard layout, the panning
coefficients of the FL channel and the FR channel have to be identical, and panning
coefficients of the SL channel and the SR channel also have to be identical.
[00318]     As described above, since the panning coefficients of left and right channels for
rendering the TFC input channel have to be identical, it is impossible to adjust the panning
coefficients of the left and right channels so as to adjust an elevation of the TFC input
channel. Therefore, panning coefficients among front and rear channels are adjusted so as to
apply an elevated feeling by rendering the TFC input channel.
[00319]     When a reference elevation angle is 35 degrees, and an elevation angle of the TFC
input channel to be rendered is elv, the panning coefficients of the SL channel and the SR
channel for virtually rendering the TFC input channel to the elevation angle elv are
respectively determined according to Equation 28 and Equation 29.
[00320]     [Equation 28]
[00321]     GVHB'0i,) = 1 0 (O.asxmin (max(elv-s,O),as))/ZO  X GVOin)
[00322]     [Equation 29]
[00323]     GHG,(,)     =  10(o.2sXmin (max(elv-3so), 2))/20 x GvHO,6(4-i)
                                                 39

where, GvHO    ,Ain) is the panning coefficient of the SL channel for performing the virtual
rendering at the reference elevation angle is 35 degrees, and GvHO, 6,(,)   is the panning
coefficient of the SR channel for performing the virtual rendering at the reference elevation
angle is 35 degrees. ii. is an index with respect to a height input channel, and    Equation 28
and Equation 29 each indicate a relation between an initial value of the panning coefficient
and an updated panning coefficient when the height input channel is the TFC channel.
[00324]      Here, in order to constantly maintain an energy level of an output signal, the
panning coefficients obtained by using Equation 28 and Equation 29 are not changelessly
used but are power normalized by using Equation 30 and Equation 31 and then are used.
[00325]      [Equation 30]
[00326]      PGH      ) =         G       Qis)
[00327]      [Equation 31]
[00328]      GvH,1~6.in) =     1GH,1__0_)
                             PGvH
[00329]      In this manner, the power normalize process is performed so that a total sum of a
square of the panning coefficients of the input channel becomes 1, and by doing so, the
energy level of the output signal before the panning coefficients are updated and the energy
level of the output signal after the panning coefficients are updated may be equally
maintained.
[00330]      The embodiments according to the present invention can also be embodied as
programmed commands to be executed in various computer configuration elements, and then
can be recorded to a computer readable recording medium. The computer readable recording
medium may include one or more of the programmed commands, data files, data structures,
or the like. The programmed commands recorded to the computer readable recording medium
may be particularly designed or configured for the invention or may be well known to one of
ordinary skill in the art of computer software fields. Examples of the computer readable
recording medium include magnetic media including hard disks, magnetic tapes, and floppy
disks, optical media including CD-ROMs, and DVDs, magneto-optical media including
floptical disks, and a hardware apparatus designed to store and execute the programmed
commands in read-only memory (ROM), random-access memory (RAM), flash memories,
                                                40

and the like. Examples of the programmed commands include not only machine codes
generated by a compiler but also include great codes to be executed in a computer by using
an interpreter. The hardware apparatus can be configured to function as one or more software
modules so as to perform operations for the invention, or vice versa.
[00331]      While the detailed description has been particularly described with reference to
non-obvious features of the present invention, it will be understood by one of ordinary skill in
the art that various deletions, substitutions, and changes in form and details of the
aforementioned apparatus and method may be made therein without departing from the spirit
and scope of the following claims.
[00332]      Therefore, the scope of the present invention is defined not by the detailed
description but by the appended claims, and all differences within the scope will be construed
as being included in the present invention.
                                                 41

                                             CLAIMS
         1. A method of elevation rendering an audio signal, the method comprising:
         receiving multichannel signals including at least one height input channel signal;
         obtaining first elevation rendering parameters for the multichannel signals;
         obtaining a delayed height input channel signal by applying a predetermined delay to
a height input channel signal, wherein a label of the height input channel signal is one of
frontal height channel labels;
         obtaining second elevation rendering parameters based on the label of the height
input channel signal and labels of two output channel signals, wherein the labels of the two
output channel signals are surround channel labels; and
         elevation rendering the multichannel signals and the delayed height input channel
signal to output a plurality of output channel signals based on the first elevation rendering
parameters and the second elevation rendering parameters,
         wherein the first elevation rendering parameters and the second elevation rendering
parameters comprise at least one of a panning gain and an elevation filter coefficient.
         2.      The method of claim 1, wherein the plurality of output channel signals are
horizontal channel signals.
         3.      The method of claim 1, wherein the frontal height channel labels comprise at
least one of CH_U_L030, CH_U_R030, CH_U_L045, CH_U_R045, and CH_U_000.
         4.      The method of claim 1, wherein the surround channel label comprises at least
one of CH_M_L110 and CH_M_R110.
         5.      The method of claim 1, wherein the predetermined delay is determined based
on a sampling rate of the multichannel signal.
         6. The method of claim 5, the predetermined delay is determined based on an
equation of delay = round (& x 0.003/64), wherein the fs is the sampling rate of the
multichannel signal.
         7.      An apparatus for rendering an audio signal, the apparatus comprising:
                                                42

         a receiving unit configured to receive multichannel signals including at least one
height input channel signal;
         a rendering unit configured to:
         obtain first elevation rendering parameters for the multichannel signals,
         obtain a delayed height input channel signal by applying a predetermined delay to a
height input channel signal, wherein a label of the height input channel signal is one of
frontal height channel labels,
         obtain second elevation rendering parameters based on the label of the height input
channel signal and labels of two output channel signals, wherein the labels of the two output
channel signals are surround channel labels, and
         elevation render the multichannel signals and the delayed height input channel signal
to output a plurality of output channel signals based on the first elevation rendering
parameters and the second elevation rendering parameters,
         wherein the first elevation rendering parameters and the second elevation rendering
parameters comprise at least one of a panning gain and an elevation filter coefficient.
         8.      The apparatus of claim 7, wherein the plurality of output channel signals are
horizontal channel signals.
         9.      The apparatus of claim 7, wherein the frontal height channel labels comprise
at least one of CH_U_L030, CH_U_R030, CH_U_L045, CH_U_R045, and CH_U_000.
         10.     The apparatus of claim 7, wherein the surround channel label comprises at
least one of CH_M_L110 and CH_M_R110.
         11.     The apparatus of claim 7, wherein the predetermined delay is determined
based on a sampling rate of the multichannel signal.
         12.     The apparatus of claim 11, the predetermined delay is determined based on an
equation of delay = round (Q X 0.003/64), wherein the fs is the sampling rate of the
multichannel signal.
13.      A computer-readable recording medium having recorded thereon a computer program
for executing the method of claim 1.
                                                43

<removed-apn>   <removed-date>
                           1/18

<removed-apn>   <removed-date>
                           2/18

<removed-apn>   <removed-date>
                           3/18

<removed-apn>   <removed-date>
                           4/18

<removed-apn>   <removed-date>
                           5/18

<removed-apn>   <removed-date>
                           6/18

<removed-apn>   <removed-date>
                           7/18

<removed-apn>   <removed-date>
                           8/18

<removed-apn>   <removed-date>
                           9/18

<removed-apn>   <removed-date>
                           10/18

<removed-apn>   <removed-date>
                           11/18

<removed-apn>   <removed-date>
                           12/18

<removed-apn>   <removed-date>
                           13/18

<removed-apn>   <removed-date>
                           14/18

<removed-apn>   <removed-date>
                           15/18

<removed-apn>   <removed-date>
                           16/18

<removed-apn>   <removed-date>
                           17/18

<removed-apn>   <removed-date>
                           18/18

