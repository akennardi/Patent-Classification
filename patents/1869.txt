                                          ABSTRACT
        In cases of rendering a multichannel signal such as a 22.2 channel signal as a 5.1
channel signal, a three dimensional (3D) audio signal may be reproduced using a two
dimensional (2D) output channel, but rendered audio signals are sensitively affected by a
layout of speakers and may cause distortion of a sound image when the layout of arranged
speakers is different from a standard layout.
        The present invention may solve the aforementioned problem of the prior art. The
audio signal rendering method for reducing distortion of a sound image even when the layout
of the arranged speakers is different from the standard layout, according to one embodiment
of the present invention, includes: receiving a multi-channel signal including a plurality of
input channels that are to be converted to a plurality of output channels; obtaining deviation
information about at least one output channel, from a location of a speaker and a standard
location corresponding to each of the plurality of output channels; and modifying a panning
gain from a height channel included in the plurality of input channels to the output channel
having the deviation information, based on obtained deviation information.

       METHOD AND APPARATUS FOR RENDERING ACOUSTIC SIGNAL, AND
                     COMPUTER-READABLE RECORDING MEDIUM
                                    TECHNICAL FIELD
[0001]      The present application is a divisional application from Australian Patent
Application No. 2015234454, the entire disclosure of which is incorporated herein by
reference.
[0002]      The inventive concept relates to a method and apparatus for rendering audio signal,
and more particularly, to a rendering method and apparatus for reproducing location of a
sound image and tone color more accurately, by modifying a panning gain or a filter
coefficient when there is a misalignment between a standard layout and an arrangement
layout of output channels.
                                   BACKGROUND ART
[0003]      Stereophonic sound denotes a sound, to which spatial information is added,
capable of reproducing a direction or a distance of a sound, as well as pitch and tone color of
a sound, allowing a listener to have an immersive feeling, and making a listener, who does
not exist in a space where a sound source has occurred, experience directional, distance, and
spatial perceptions.
[0004]      When a channel signal such as a 22.2 channel is rendered as a 5.1 channel, a
three-dimensional (3D) stereophonic sound may be reproduced using a two-dimensional (2D)
output channel, but rendered audio signals are so sensitive to a layout of speakers that a
sound image distortion may occur if an arrangement layout of speakers is different from a
standard layout.
                DETAILED DESCRIPTION OF THE INVENTIVE CONCEPT
                                 TECHNICAL PROBLEM
[0005]      As described above, when a channel signal such as a 22.2 channel is rendered as a
5.1 channel, a three-dimensional (3D) stereophonic sound may be reproduced using a
two-dimensional (2D) output channel, but rendered audio signals are so sensitive to a layout
                                                1

of speakers that a sound image distortion may occur if an arrangement layout of speakers is
different from a standard layout.
[0006]      To address problems of the prior art, the inventive concept provides reduction in a
sound image distortion even when a layout of installed speakers is different from a standard
layout.
                                   TECHNICAL SOLUTION
[0007]      In order to achieve the objective, the present invention includes embodiments
below.
[0008]      An audio signal rendering method includes: receiving a multi-channel signal
comprising a plurality of input channels that are to be converted to a plurality of output
channels; obtaining deviation information about at least one output channel, from a location
of a speaker corresponding to each of the plurality of output channels and a standard location;
and modifying a panning gain from a height channel included in the plurality of input
channels to the output channel having the deviation information, based on obtained deviation
information.
                                ADVANTAGEOUS EFFECTS
[0009]      According to the inventive concept, an audio signal may be rendered so as to
reduce sound image distortion even if a layout of installed speakers is different from a
standard layout or a location of a sound image has changed.
                            DESCRIPTION OF THE DRAWINGS
[0010]      FIG. 1 is a block diagram illustrating an internal structure of a stereophonic sound
reproduction apparatus according to an embodiment;
[0011]      FIG. 2 is a block diagram of a renderer in the stereophonic sound reproduction
apparatus according to the embodiment;
[0012]      FIG. 3 is a diagram of a layout of channels in a case where a plurality of input
channels are down-mixed to a plurality of output channels, according to an embodiment;
                                                 2

[0013]       FIG. 4 is a diagram of a panning unit in a case where a positional deviation occurs
between a standard layout and an arrangement layout of output channels, according to an
embodiment;
[0014]       FIG. 5 is a diagram illustrating configuration of a panning unit in a case where
there is an elevation deviation between a standard layout and an arrangement layout of output
channels, according to an embodiment;
[0015]       FIG. 6 is diagrams showing locations of a sound image according to an
arrangement layout of output channels, when a center channel signal is rendered from a left
channel signal and a right channel signal;
[0016]       FIG. 7 is diagrams showing localization of a location of a sound image by
correcting an elevation effect according to an embodiment, if there is an elevation deviation
in output channels;
[0017]       FIG. 8 is a flowchart illustrating a method of rendering a stereophonic audio
signal, according to an embodiment;
[0018]       FIG. 9 is a diagram showing an elevation deviation versus a panning gain with
respect to each channel when a center channel signal is rendered from a left channel signal
and a right channel signal, according to an embodiment;
[0019]       FIG. 10 is a diagram showing spectrums of tones at locations, according to a
positional deviation between speakers;
[0020]       FIG. 11 is a flowchart illustrating a method of rendering a stereophonic audio
signal according to an embodiment;
[0021]       FIG. 12 is diagrams for illustrating methods of designing sound quality correction
filters, according to an embodiment;
[0022]       FIG. 13 is diagrams showing examples in which an elevation deviation exists
between output channels for 3D virtual rendering and a virtual sound source;
[0023]       FIG. 14 is a diagram for illustrating a method of virtual rendering a TFC channel
by using L/R/LS/RS channels according to an embodiment; and
[0024]       FIG. 15 is a block diagram of a renderer for processing a deviation in a virtual
rendering by using 5.1 output channels, according to an embodiment.
                                           BEST MODE
[0025]       In order to achieve the objective, the present invention includes embodiments
below.
                                                  3

[0026]       According to a first aspect of the present invention, there is provided a method of
rendering an audio signal, the method comprising: receiving multi-channel signals including
an input channel signal having a horizontal channel; obtaining deviation information from an
elevation angle of an output channel signal and a standard loudspeaker elevation angle;
obtaining filter coefficients for rendering the input channel signal into the output channel
signal; and when the elevation angle of the output channel signal is higher than the standard
loudspeaker elevation angle, modifying the filter coefficients, based on an inverse form of an
elevation filter using a Head-Related Transfer Function(HRTF) and the deviation
information.
[0027]       According to a second aspect of the present invention, there is provided an
apparatus for rendering an audio signal, the apparatus comprising: a receiver configured to
receive multi-channel signals including an input channel signal having a horizontal channel;
and an obtainer configured to: obtain deviation information from an elevation angle of an
output channel signal and a standard loudspeaker elevation angle, obtain filter coefficients for
rendering input channel signal into the output channel signal, and when the elevation angle of
the output channel signal is higher than the standard loudspeaker elevation angle, modify the
filter coefficients, based on an inverse form of an elevation filter using a Head-Related
Transfer Function(HRTF) and the deviation information.
[0028]       According to an embodiment, there may be provided a method of rendering an
audio signal, the method comprising: receiving multichannel signals including one or more
height input channels, to be converted from input channel configurations to output channel
configurations; obtaining a panning gain for a height input channel to be converted into an
output channel based on a standard loudspeaker position; obtaining deviation information
about the output channel, from an output loudspeaker position and the standard loudspeaker
position; and modifying the obtained panning gain based on the obtained deviation
information and the standard loudspeaker position.
[0029]       The plurality of output channels may be horizontal channels.
[0030]       The output channel having the deviation information may include at least one of a
left horizontal channel and a right horizontal channel.
[0031]       The deviation information may include at least one of an azimuth deviation and an
elevation deviation.
[0032]       The modifying of the panning gain may modify an effect caused by an elevation
deviation, when the obtained deviation information includes the elevation deviation.
                                                  4

[0033]      The modifying of the panning gain may correct the panning gain by a
two-dimensional (2D) panning method, when the obtained deviation information does not
include the elevation deviation.
[0034]      The correcting of the effect caused by the elevation deviation may include
correcting an inter-aural level difference (ILD) resulting from the elevation deviation.
[0035]      The correcting of the effect caused by the elevation deviation may include
modifying the panning gain of the output channel corresponding to obtained elevation
deviation, in proportional to the obtained elevation deviation.
[0036]      A sum of square values of panning gains with respect to the left horizontal
channel and the right horizontal channel may be 1.
[0037]      According to an embodiment, there may be provided an apparatus for rendering
an audio signal, the apparatus comprising: a receiver configured to receive multichannel
signals including one or more height input channels, to be converted from input channel
configurations to output channel configurations; a deviation obtaining unit configured to
obtain deviation information about an output channel, from an output loudspeaker position
and a standard loudspeaker position; and a panning gain obtaining unit configured to obtain a
panning gain for a height input channel to be converted into the output channel based on the
standard loudspeaker position and to modify the obtained panning gain based on the
deviation information and the standard loudspeaker position.
[0038]      The plurality of output channels may be horizontal channels.
[0039]      The output channel having the deviation information may include at least one of a
left horizontal channel and a right horizontal channel.
[0040]      The deviation information may include at least one of an azimuth deviation and an
elevation deviation.
[0041]      The panning gain modifier may correct an effect caused by an elevation deviation,
when the obtained deviation information includes the elevation deviation.
[0042]      The panning gain modifier may modify the panning gain by a two-dimensional
(2D) panning method, when the obtained deviation information does not include the elevation
deviation.
[0043]      The panning gain modifier may correct an inter-aural level difference caused by
the elevation deviation to correct an effect caused by the elevation deviation.
[0044]      The panning gain modifier may modify a panning gain of an output channel
corresponding to the elevation deviation, in proportional to obtained elevation deviation, so
as to correct an effect caused by the obtained elevation deviation.
                                                5

[0045]      A sum of square values of panning gains with respect to the left horizontal
channel and the right horizontal channel may be 1.
[0046]      According to an embodiment, there may be provided a computer-readable
recording medium having recorded thereon a computer program for executing the above
method.
[0047]      In addition, there may be provided another method, another system, and a
computer-readable recording medium having recorded thereon a computer program for
executing the method.
                           MODE OF THE INVENTIVE CONCEPT
[0048]      The detailed descriptions of the invention are referred to with the attached
drawings illustrating particular embodiments of the invention. These embodiments are
provided so that this disclosure will be thorough and complete, and will fully convey the
concept of the invention to one of ordinary skill in the art. It will be understood that various
embodiments of the invention are different from each other and are not exclusive with respect
to each other.
[0049]      For example, a particular shape, a particular structure, and a particular feature
described in the specification may be changed from an embodiment to another embodiment
without departing from the spirit and scope of the invention. Also, it will be understood that a
position or layout of each element in each embodiment may be changed without departing
from the spirit and scope of the invention. Therefore, the detailed descriptions should be
considered in a descriptive sense only and not for purposes of limitation and the scope of the
invention is defined not by the detailed description of the invention but by the appended
claims, and all differences within the scope will be construed as being included in the present
invention.
[0050]      Like reference numerals in the drawings denote like or similar elements
throughout the specification. In the following description and the attached drawings,
well-known functions or constructions are not described in detail since they would obscure
the present invention with unnecessary detail. Also, like reference numerals in the drawings
denote like or similar elements throughout the specification.
[0051]      Hereinafter, the present invention will be described in detail by explaining
exemplary embodiments of the invention with reference to the attached drawings. The
invention may, however, be embodied in many different forms, and should not be construed
                                                6

as being limited to the embodiments set forth herein; rather, these embodiments are provided
so that this disclosure will be thorough and complete, and will fully convey the concept of the
invention to those of ordinary skill in the art.
[0052]       Throughout the specification, when an element is referred to as being "connected
to" or "coupled with" another element, it can be "directly connected to or coupled with" the
other element, or it can be "electrically connected to or coupled with" the other element by
having an intervening element interposed therebetween. Also, when a part "includes" or
"comprises" an element, unless there is a particular description contrary thereto, the part can
further include other elements, not excluding the other elements.
[0053]       Hereinafter, the inventive concept will be described in detail below with reference
to accompanying drawings.
[0054]       FIG. 1 is a block diagram illustrating an internal structure of a stereophonic sound
reproducing apparatus according to an embodiment.
[0055]       The stereophonic sound reproducing apparatus 100 according to an embodiment
may output a multi-channel audio signal, in which a plurality of input channels are mixed to a
plurality of output channels to reproduce. Here, when the number of output channels is less
than the number of input channels, the input channels are down-mixed according to the
number of output channels.
[0056]       Stereophonic sound denotes sound, to which spatial information is added,
allowing a listener to have an immersive feeling by reproducing a direction or feeling of
distance of a sound, as well as an elevation and timbre of the sound, so that even a listener
who does not exist in a space where a sound source has occurred may experience directional,
distance, and spatial perceptions.
[0057]       In the descriptions below, an output channel of an audio signal may denote the
number of speakers that output sound. The more the output channels, the more the number of
speakers from which the sound is output. The stereophonic sound reproducing apparatus 100
according to the embodiment may render and mix a multi-channel audio input signal to
output channels that will reproduce the sound, so that the multi-channel audio signal from a
large number of input channels may be output and reproduced in an environment where a less
number of output channels are provided. Here, the multi-channel audio signal may include a
channel capable of outputting an elevated sound.
[0058]       The channel capable of outputting the elevated sound may denote a channel
capable of outputting an audio signal via a speaker located above a head of a listener so that
the listener may experience elevated feeling. A horizontal channel may denote a channel
                                                  7

capable of outputting an audio signal via a speaker located on a horizontal plane with respect
to the listener.
[0059]       The above-described environment in which less number of output channels are
provided may denote an environment in which the sound may be output via a speaker
provided on a horizontal plane, without using an output channel capable of outputting the
elevated sound.
[0060]       In addition, in the descriptions below, a horizontal channel may denote a channel
including an audio signal that may be output via a speaker provided on the horizontal plane.
An overhead channel may denote a channel including an audio signal that may be output via
a speaker that is provided on an elevated position, not on the horizontal plane, in order to
output the elevated sound.
[0061]       Referring to FIG. 1, the stereophonic sound reproducing apparatus 100 may
include an audio core 110, a renderer 120, a mixer 130, and a post-processor 140.
[0062]       The stereophonic sound reproducing apparatus 100 according to the embodiment
may render, mix, and output a multi-channel input audio signal to an output channel to
reproduce. For example, the multi-channel input audio signal may be a 22.2 channel signal,
and the output channel to reproduce may be 5.1 or 7.1 channels. The stereophonic sound
reproducing apparatus 100 performs a rendering by designating output channels to which
channels of the multi-channel input audio signal will correspond, and performs mixing of the
rendered audio signals by mixing signals of the channels respectively corresponding to the
channels to reproduce and outputs a final signal.
[0063]       An encoded audio signal is input to the audio core 110 in a format of a bistream,
and the audio core 110 decodes the input audio signal after selecting a decoder tool suitable
for the encoded format of the audio signal.
[0064]       The renderer 120 may render the multi-channel input audio signal to a
multi-channel output channels according to channels and frequencies. The renderer 120 may
perform three-dimensional (3D) rendering and two-dimensional (2D) rendering on the
multi-channel audio signal according to overhead channels and horizontal channels. A
configuration of the renderer and a detailed rendering method will be described in more detail
later with reference to FIG. 2.
[0065]       The mixer 130 may mix the signals of the channels corresponding to the
horizontal channels by the renderer 120, and output the final signal. The mixer 130 may mix
the signals of the respective channels according to each of predetermined sections. For
example, the mixer 130 may mix the signals of the respective channels by one frame unit.
                                                  8

[0066]      The mixer 130 according to the embodiment may perform the mixing based on
power values of the signals that are rendered to the respective channels to produce. That is,
the mixer 130 may determine amplitude of the final signal or a gain to be applied to the final
signal based on the power values of the signals rendered to the respective channels to
reproduce.
[0067]      The post-processor 140 performs a controlling of a dynamic range with respect to
a multi-band signal and binaurlaizing on an output signal of the mixer 130 to be suitable for
the respective reproducing apparatus (speaker, headphones, etc.). An output audio signal
output from the post-processor 140 is output via a device such as a speaker, and the output
audio signal may be reproduced in a 2D or 3D manner according to the process performed by
each element.
[0068]      The stereophonic sound reproducing apparatus 100 illustrated with reference to
FIG. 1 according to the embodiment is shown based on a configuration of an audio decoder,
and other additional configurations are omitted.
[0069]      FIG. 2 is a block diagram illustrating configuration of the renderer among the
configuration of the stereophonic sound reproducing apparatus according to an embodiment.
[0070]      The renderer 120 includes a filtering unit 121 and a panning unit 123.
[0071]      The filtering unit 121 compensates for a tone or the like of a decoded audio signal
according to a location, and may perform filtering of an input audio signal by using a
head-related transfer function (HRTF) filter.
[0072]      The filtering unit 121 may render an overhead channel that has passed through the
HRTF filter in different manners according to a frequency thereof, in order to perform 3D
rendering on the overhead channel.
[0073]      The HRTF filter may allow a stereophonic sound to be recognized according to a
phenomenon in which a characteristic of a complicated path such as diffraction on a surface
of a head, reflection by auricles, etc. is changed depending on a transfer direction of a sound,
as well as a simple difference between paths such as an inter-aural level difference (ILD) and
an inter-aural time difference (ITD) which occurs when a sound reaches two ears, etc. The
HRTF filter may process the audio signals included in the overhead channel, that is, by
changing sound quality of the audio signal so that the stereophonic sound may be recognized.
[0074]      The panning unit 123 calculates and applies a panning coefficient that is to be
applied to each frequency band and each channel, in order to pan the input audio signal with
respect to each output channel. Panning of the audio signal denotes controlling a magnitude
                                                 9

of a signal applied to each output channel, in order to render a sound source at a certain
location between two output channels.
[0075]      The panning unit 123 may render a low frequency signal among the overhead
channel signals according to add-to-the-closest channel method, and may render a high
frequency signal according to a multichannel panning method. According to the multichannel
panning method, a gain value that is set to differ in channels to be rendered to each of
channel signals is applied to signals of each of channels of a multichannel audio signal, so
that each of the signals may be rendered to at least one horizontal channel. The signals of
each channel to which the gain value is applied may be synthesized via mixing and may be
output as a final signal.
[0076]       Since the low frequency signal has a high diffractive property, even if each
channel in the multi-channel audio signal is rendered only to one channel, without being
rendered to various channels according to the multi-channel panning method, the listener may
feel the sound quality similarly to each other. Therefore, the stereophonic sound reproducing
apparatus 100 according to the embodiment may render the low frequency signal according
to the add-to-the-closest channel method, and thus, sound quality degradation that may occur
when various channels are mixed to one output channel may be prevented. That is, if various
channels are mixed to one output channel, sound quality may be amplified or decreased due
to interference between the channel signals and thus may degrade, and thus, the sound quality
degradation may be prevented by mixing one channel to one output channel.
[0077]      According to the add-to-the-closest channel method, each channel of the
multi-channel audio signal may be rendered to a closest channel from among the channels to
reproduce, instead of being rendered to various channels.
[0078]      Also, the stereophonic sound reproducing apparatus 100 performs the rendering
operation differently from the frequency, thereby increasing a sweet spot without degrading
the sound quality. That is, the low frequency signal having a high diffractive property is
rendered according to the add-to-the-closest channel method in order to prevent the sound
quality degradation that may occur when various channels are mixed to one output channel.
The sweet spot denotes a predetermined range in which the listener may optimally listen to
the stereophonic sound that has not been distorted.
[0079]      As the sweet spot is increased, the listener may optimally listen to the
stereophonic sound that has not been distorted within a large range. In addition, if the listener
does not exist within the sweet spot, the listener may listen to the sound, the sound quality or
the sound image of which has been distorted.
                                                10

[0080]       FIG. 3 is a diagram of a layout of channels in a case where a plurality of input
channels are down-mixed to a plurality of output channels, according to an embodiment.
[0081]       A technology for providing a stereophonic sound with a stereoscopic image has
been being developed in order to provide a user with realism and immersive feeling that are
equal to or more exaggerated than reality. A stereophonic sound denotes that an audio signal
itself has an elevation of sound and spatiality, and in order to reproduce the stereophonic
sound, at least two or more loud speakers, that is, output channels, are necessary. Also, a
large number of output channels are necessary in order to accurately reproduce feelings of
elevation, distance, and spatiality of the sound, except for a binaural stereophonic sound
using an HRTF.
[0082]       Therefore, various multi-channel systems such as a 5.1-channel system, the Auro
3D system, the Holman 10.2 channel system, the ETRI/Samsung 10.2 channel system, the
NHK 22.2 channel system, etc., in addition to a stereo system having two output channels,
have been suggested and developed.
[0083]       FIG. 3 is a diagram illustrating an example in which a stereophonic audio signal
of 22.2 channels is reproduced by a 5.1-channel output system.
[0084]       A 5.1-channel system is a generalized name of a 5-channel surround
multi-channel sound system, and has been widely distributed and used as home-theater in
households and a sound system for theatres. All kinds of 5.1 channels include a front left (FL)
channel, a center (C) channel, a front right (FR) channel, a surround left (SL) channel, and a
surround right (SR) channel. As denoted in FIG. 3, since the output channels of the
5.1-channel system are placed on a same horizontal plane, the 5.1-channel system physically
corresponds to 2D system. In order for the 5.1-channel system to reproduce stereophonic
audio signals, a rendering process for granting 3D effect to a signal to be reproduced has to
be performed.
[0085]       The 5.1-channel system is widely used in various fields such as digital versatile
disc (DVD) video, DVD sound, super audio compact disc (SACD), or digital broadcasting, as
well as in movies. However, although the 5.1-channel system provides an improved spatiality
when comparing with the stereo system, there are many restrictions in forming wider
listening space. In particular, the 5.1-channel system forms a narrow sweet spot and may not
provide a vertical sound image having an elevation angle, and thus, the 5.1-channel system
may not be suitable for a wide listening space, e.g., a theater.
[0086]       A 22.2-channel system suggested by NHK includes three-layers of output
channels. An upper layer includes a Voice of God (VOG), TO, T180, TL45, TL90, TL135,
                                                 11

TR45, TR90, and TR45 channels. Here, in the name of each channel, an index T denotes an
upper layer, indexes L and R respectively denote left and right, and a number at the rear
denotes an azimuth angle from a center channel.
[0087]      A middle layer is on a same plane as the 5.1 channels, and includes ML60, ML90,
ML135, MR60, MR90, and MR135 channels in addition to output channels of the 5.1
channels. Here, in the name of each channel, an index M at the front means a middle layer,
and a number at the rear denotes an azimuth angle from a center channel.
[0088]      A low layer includes LO, LL45, and LR45 channels. Here, an index L at the front
of the name of each channel denotes a low layer, and a number at the rear denotes an azimuth
angle from a center channel.
[0089]      In the 22.2 channels, the middle layer is referred to as a horizontal channel, and
the VOG, TO, T180, T180, M180, L, and C channels having azimuth angle of 0' or 1800 are
referred to as vertical channels.
[0090]      When a 22.2 channel input signal is reproduced via the 5.1 channel system, the
most general scheme is to distribute signals to channels by using a down-mix formula.
Otherwise, an audio signal having an elevation may be reproduced through the 5.1-channel
system by performing rendering to provide a virtual elevation.
[0091]      FIG. 4 illustrates a panning unit according to an embodiment in a case where a
positional deviation occurs between a standard layout and an arrangement layout of output
channels.
[0092]      When a multichannel input audio signal is reproduced by using a smaller number
of output channels than the number of channels of an input signal, an original sound field
may be distorted, and in order to compensate for the distortion, various techniques are being
researched.
[0093]      General rendering techniques are supposed to perform rendering based on a case
where speakers, that is, output channels, are arranged according to the standard layout.
However, when the output channels are not arranged to accurately match the standard layout,
distortion of a location of a sound image and distortion of a tone occur.
[0094]      The distortion of the sound image widely includes distortion of the elevation and
distortion of a phase angle that are not sensitively felt in a relatively low level. However, due
to a physical characteristic of a human body where both ears are located in left and right sides,
if sound images of left-center-right sides are changed, the distortion of the sound image may
be sensitively perceived. In particular, a sound image of a front side may be further
sensitively perceived.
                                                 12

[0095]      Therefore, as shown in FIG. 3, when the 22.2 channels are realized by using the
5.1 channels, it is particularly required not to change sound images of the VOG, TO, T180,
T180, M180, L, and C channels located at 0' or 1800, rather than left and right channels.
[0096]      When an audio input signal is panned, two processes are basically performed. The
first process corresponds to an initializing process in which a panning gain with respect to an
input multichannel signal is calculated according to a standard layout of output channels. In
the second process, a calculated panning gain is modified based on a layout with which the
output channels are actually arranged. After the panning gain modifying process is performed,
a sound image of an output signal may be present at a more accurate location.
[0097]      Therefore, in order for the panning unit 123 to perform processing, information
about the standard layout of the output channels and information about the arrangement
layout of the output channels are required, in addition to the audio input signal. In a case
where the C channel is rendered from the L channel and the R channel, the audio input signal
indicates an input signal to be reproduced via the C channel, and an audio output signal
indicates modified panning signals output from the L channel and the R channel according to
the arrangement layout.
[0098]      FIG. 5 is a diagram of a configuration of a panning unit according to an
embodiment in a case where there is an elevation deviation between a standard layout and an
arrangement layout of the output channels.
[0099]      The 2D panning method that only takes into account the azimuth deviation as
shown in FIG. 4 may not correct an effect caused by an elevation deviation if there is an
elevation deviation between the standard layout and the arrangement layout of the output
channels. Therefore, if there is an elevation deviation between the standard layout and the
arrangement layout of the output channels, an elevation rising effect due to the elevation
deviation has to be compensated for by an elevation effect compensator 124 as shown in FIG.
5.
[00100]     In FIG. 5, the elevation effect compensator 124 and the panning unit 123 are
shown as separate elements, but the elevation effect compensator 124 may be implemented as
an element included in the panning unit 123.
[00101]     Hereinafter, FIGS. 6 to 9 illustrate a method of determining a panning coefficient
according to a layout of speakers in detail.
[00102]     FIG. 6 is diagrams showing a location of a sound image according to an
arrangement layout of output channels, in a case where a center channel signal is rendered
from a left channel signal and a right channel signal.
                                                 13

[00103]      In FIG. 6, it is assumed that a C channel is rendered from the L channel and the R
channel.
[00104]      In FIG. 6A, the L channel and the R channel are located at a same plane while
having azimuth angles of 300 to left and right sides from the C channel according to the
standard layout. In this case, a C channel signal is rendered only by a gain obtained through
an initialization of the panning unit 123 and is located at a regular position, and thus, there is
no need to additionally modify the panning gain.
[00105]      In FIG. 6B, the L channel and the R channel are located on a same plane like in
FIG. 6A, and a location of the R channel matches the standard layout, whereas the L channel
has the azimuth angle of 45' that is greater than 300. That is, the L channel has an azimuth
deviation of 15' with respect to the standard layout.
[00106]      In the above case, the panning gain calculated through the initialization process is
the same with respect to the L channel and the R channel, and when the panning gain is
applied, a location of the sound image is determined to be C' that is biased toward the R
channel. The above phenomenon occurs because the ILD varies depending on a change in the
azimuth angle. When the azimuth angle is defined as 0' based on the location of the C
channel, a level difference ILD of the audio signals reaching two ears of a listener increases
as the azimuth angle increases.
[00107]      Therefore, the azimuth deviation has to be compensated for by modifying the
panning gain according to the 2D panning method. In a case shown in FIG. 5B, a signal of
the R channel is increased or a signal of the L channel is reduced so that the sound image
may be formed at the location of the C channel.
[00108]      FIG. 7 is diagrams showing localization of the sound image by compensating for
the elevation effect according to an embodiment, when there is an elevation deviation
between the output channels.
[00109]      FIG. 7A shows a case in which the R channel is arranged on a location of R'
having an elevation angle so as to have an azimuth angle of 30' that satisfies the standard
layout, whereas the R channel is not located on the same plane as the L channel and has an
elevation angle of 30' from the horizontal channel. In the above case, if the same panning gas
is applied to the R channel and the L channel, location of the sound image C' that has been
changed due to the change of the ILD according to the rising of the elevation of the R channel
is not located at the center between the L channel and the R channel, but is biased toward the
L channel.
                                                 14

[00110]      This is because the ILD is changed due to the elevation rising like in the case
where there is the azimuth deviation exists. If the elevation angle is defined to be 0' based on
the horizontal channel, the level difference ILD of the audio signals reaching two ears of the
listener is reduced as the elevation angle increases. Therefore, C' is biased toward the L
channel that is the horizontal channel (having no elevation angle).
[00111]      Therefore, the elevation effect compensator 124 compensates for the ILD of the
sound having the elevation angle in order to prevent bias of the sound image. In more detail,
the elevation effect compensator modifies the panning gain of the channel having the
elevation angle to be increased so as to prevent the bias of the sound image and to form the
sound image at the azimuth angle 00.
[00112]      FIG. 7B shows a location of the sound image that is localized through the
compensation of the elevation effect. The sound image before compensation of the elevation
effect is located at C', that is, a biased position toward the channel having no elevation angle
as shown in FIG. 7A. However, when the elevation effect is compensated for, the sound
image may be localized so as to be positioned at the center between the L channel and an R'
channel.
[00113]      FIG. 8 is a flowchart illustrating a method of rendering a stereophonic audio
signal, according to an embodiment.
[00114]      The method of rendering the stereophonic audio signal illustrated with reference
to FIGS. 6 and 7 is performed in following order.
[00115]      The renderer 120, in particular, the panning unit 123, receives a multi-channel
input signal having a plurality of channels (810). For panning the received multi-channel
input signal through multi-channel output, the panning unit 123 obtains deviation information
about each of output channels by comparing locations where the speakers corresponding to
the output channels are arranged with standard output locations (820).
[00116]      Here, if the output channel includes 5.1 channels, the output channels are
horizontal channels located on the same plane.
[00117]      Deviation information may include at least one of information about an azimuth
deviation and information about an elevation deviation. The information about the azimuth
deviation may include the azimuth angle formed by a center channel and output channels on
the horizontal plane where the horizontal channels exist, and information about the elevation
deviation may include an elevation angle formed by the horizontal plane on which the
horizontal channels exist and the output channel.
                                                   15

[00118]     The panning unit 123 obtains a panning gain that is to be applied to the input
multi-channel signal, based on the standard output location (830). Here, an order of the
obtaining of the deviation information (820) and the obtaining of the panning gain (830) may
be switched.
[00119]     In operation 820, as a result of obtaining the deviation information about each
output channel, if the deviation information exists in the output channel, the panning gain
obtained in operation 830 has to be modified. In operation 840, it is determined whether there
is an elevation deviation based on the deviation information obtained in operation 820.
[00120]     If the elevation deviation does not exist, the panning gain is modified only by
taking into account the azimuth deviation (850).
[00121]     There may be various methods of calculating and modifying the panning gain.
Representatively, a vector base amplitude panning (VBAP) method based on an amplitude
panning or a tangent law may be used. Otherwise, in order to address the problem that the
sweet spot has a narrow range, a method based on a wave field synthesis (WFS) that may
provide relatively wide sweet spot by matching time delays of multi-speakers used in a
reproduction environment in order to generate a waveform similar to a plane wave on a
horizontal plane may be used.
[00122]     Otherwise, when a transient signal such as raining sound, clapping sound, or the
like and signals from various channels are down-mixed to one channel, the number of
transient signals increases in one channel and a tone distortion such as whitening may occur.
To address the above problem, a hybrid virtual rendering method that performs the rendering
process after selecting a 2D (timbral)/3D (spatial) rendering modes according to an
importance of a spatial perception and sound quality in each scene may be applied.
[00123]     Otherwise, a rendering method that combines a virtual rendering for providing
spatial perception and a technique using an active down-mix that improves sound quality by
preventing comb-filtering during a down-mix process may be used.
[00124]     If there is the elevation variation, the panning gain is modified while taking into
account the elevation deviation (860).
[00125]     Here, the modifying of the panning gain taking into account the elevation
deviation includes a process of compensating for the rising effect according to the increase in
the elevation angle, that is, modifies the panning gain so as to compensate for the ILD that is
reduced according to the elevation increasing.
[00126]     After modifying the panning gain based on the deviation information about the
output channel, the panning process of the corresponding channel is finished. In addition,
                                                  16

processes from operation 820, that is, obtaining the deviation information about each output
channel, to operation 850 or 860, that is, modifying the panning gain that is to be applied to
the corresponding channel, may be repeatedly performed as many as the number of output
channels.
[00127]      FIG. 9 is a diagram showing an elevation deviation versus a panning gain with
respect to each channel, when a center channel signal is rendered from a left channel signal
and a right channel signal, according to an embodiment.
[00128]      FIG. 9 shows relation between the panning gains that are to be applied to a
channel having the elevation angle (elevated) and a channel on a horizontal plane (fixed) and
the elevation angle, as an embodiment of the elevation effect compensator 124.
[00129]      When the C channel is rendered from the L channel and the R channel on the
horizontal plane, panning gains EL and        9R  that will be applied to the L and R channels are
equal to each other since the L channel and the R channel arranged on the horizontal plane
                                                                                        1
                                                                             Et = ER= ,2
are symmetric with each other, and each has a value of 0.707, that is,
However, if one of the channels has the elevation angle as shown in the example of FIG. 7,
the panning gain has to be modified according to the elevation angle in order to compensate
for the effect caused by the elevation increase.
[00130]      In FIG. 9, the panning gain is modified to increase by a ratio of 8dB/90' according
to the change in the elevation angle. With respect to the examples shown in FIG. 7, a gain of
an elevated channel corresponding to the elevation angle 300 is applied to the R channel, and
then,  9R  is modified to 0.81, that is, increased from 0.707, and a gain of a fixed channel is
applied to the L channel, and then, 9L is modified to 0.58, decreased from 0.707.
[00131]      Here, the panning gains 9L and      9R  have to satisfy Equation 2 below for energy
normalization.gLgR
        g2+ g2=1                                                         (2)
[00132]      According to the embodiment illustrated with reference to FIG. 9, the panning
gain is modified to increase linearly by the ratio of 8dB/90* according to the change in the
                                                  17

elevation angle. However, the increasing ratio may vary depending on the example of the
elevation effect compensator, or the panning gain may increase non-linealry.
[00133]     FIG. 10 is a diagram showing spectrums of tone colors at different locations,
according to a positional deviation between the speakers.
[00134]     The panning unit 123 and the elevation effect compensator 124 process the audio
signals so that the sound image may not be biased according to locations of the speakers
corresponding to the output channels, but to be located at an original location. However, if
the locations of the speakers corresponding to the output channels actually change, the sound
image is not only changed, but the tone color is also changed.
[00135]     Here, a spectrum of the tone color that a human being perceives according to the
location of the sound image may be obtained based on an HRTF that is a function for
transferring the sound image at a certain spatial location to human ears. The HRTF may be
obtained by performing Fourier transformation on a head-related impulse response (HRIR)
obtained from a time domain.
[00136]     Since an audio signal from a spatial audio source propagates through the air and
passes through an auricle, an external auditory canal, and an eardrum, a magnitude or a phase
of the audio signal have changed. In addition, since a listener is also located in a sound field,
the audio signal that is transferred is also changed due to a head, a torso, or the like of the
listener. Therefore, the listener finally listens to a distorted audio signal. Here, a transfer
function of the audio signal that the listener listens to, in particular, between an acoustic
pressure and the audio signal, is referred to as HRTF.
[00137]     Since each person has a unique size and shape of head, auricle, and torso, the
HRTF is unique to each person. However, since it is impossible to measure the HRTF from
each person, the HRTF may be modelled by using a common HRTF, a customized HRTF,
etc.
[00138]     A diffraction effect of a head is shown from about 600 Hz and is rarely shown
after 4 kHz, and a torso effect that may be observed from 1 kHz to 2 kHz is increased as an
audio source is located at ipsilateral azimuth and an elevation angle of the audio source is low,
and is observed to 13 kHz at which the auricle dominantly affects sound image of the audio
signal. Around a frequency of 5 kHz, a peak is shown due to resonance of the auricle. In
addition, a first notch due to the auricle is shown within a range of 6 kHz to 10 kHz, a second
notch due to the auricle is shown within a range of 10 kHz to 15 kHz, and a third notch due to
the auricle is shown in a range of 15 kHz or greater.
                                                   18

[00139]      In order to perceive the azimuth angle and the elevation angle, an ITD and an ILD
of the audio source and peaks and notches shown in monaural spectral cues are used. The
peaks and notches are generated due to the diffraction and dispersion of the torso, head, and
auricle, and may be identified in the HRTF.
[00140]      As described above, the HRTF varies depending on the azimuth angle and the
elevation angle of the audio source. FIG. 10 shows a graph of the spectrum of tone color that
a human being perceives according to a frequency of the audio source, in a case where the
azimuth angle of the speaker is 300, 60', and 1100.
[00141]      When comparing the tone colors of the audio signals according to the azimuth
angles, the tone color of the azimuth angle of 30' has more intense component at 400 Hz or
less by about 3 dB to about 5 dB, than that of the tone color of the azimuth angle of 60'. In
addition, the tone color of the azimuth angle of 110' has less intense component within a
range of 2 kHz to 5 kHz by about 3 dB, than that of the tone color of the azimuth angle of
600.
[00142]      Therefore, when the tone color conversion filtering is performed by using the
characteristic of the tone color according to the azimuth angle, tone colors of a wideband
signal provided to a listener may be similar to each other, and thus, the rendering may be
performed more effectively.
[00143]      FIG. 11 is a flowchart illustrating a method of rendering a stereophonic audio
signal, according to an embodiment.
[00144]      FIG. 11 is a flowchart illustrating an embodiment of the method of rendering the
stereophonic audio signal, that is, a method of performing a tone color conversion filtering on
an input channel when the input channel is panned to at least two output channels.
[00145]      A multi-channel audio signal that is to be converted to a plurality of output
channels is input to the filtering unit 121 (1110). When a predetermined input channel from
the input multi-channel audio signal is panned to at least two output channels, the filtering
unit 121 obtains a mapping relation between the predetermined input channel and the output
channels to which the input channel is to be panned (1130).
[00146]      The filtering unit 121 obtains a tone color filter coefficient based on an HRTF
about a location of the input channel and locations of the output channels for panning based
on the mapping relation, and performs a tone color correction filtering by using the tone color
filter coefficient (1150).
[00147]      Here, the tone color correction filter may be designed by following processes.
                                                  19

[00148]      FIG. 12 is diagrams illustrating a method of designing a tone color correction
filter, according to an embodiment.
[00149]      It is assumed that the HRTF transferred to a listener when an azimuth angle of the
audio source is     0 (degree)  is defined as H, and an audio source having an azimuth angle of
0s is panned (localized) to speakers located at azimuth angles of       0         0
                                                                          D1 and    D1. In this case,
the HRTF with respect to the azimuth angles are respectively H             HOD, and
[00150]      Purpose of the tone color correction is to correct the sound reproduced from the
speakers located at the azimuth angles of OD1 and OD1 to have similar tone color to that of
the sound at the azimuth angle 0s, and thus, an output signal from the azimuth angle OD1
                                                              H as
                                                               8
                                                              H Di
passes through a filter having a transfer function such as         , and an output signal from the
                                                                                     H8 S
azimuth angle       D2 passes through a filter having a transfer function such as         .
[00151]      As a result of the above filtering, the sound reproduced from the speakers located
                           0
at the azimuth angles        Di  and OD2 may be corrected to have similar tone colors to that of
the sound from the azimuth angle of 0S.
[00152]      In the example of FIG. 10, when the tone colors of the audio signals from the
azimuth angles are compared with one another, the tone color at the azimuth angle of 300 has
more intense component at 400 Hz or less by about 3 dB to about 5 dB, than that of the
azimuth angle of 600, and the tone color at the azimuth angle of 1100 has a smaller
component within a range of 2kHz to 5 kHz by about 4 dB than that of the azimuth angle of
600.
[00153]      Since the purpose of the tone color correction is to correct the sound reproduced
from the speakers located at the angles of 300 and 1100 to have similar tone color to that of
the sound reproduced at the angle of 600, the component at 400 Hz or less in the sound
                                                  20

reproduced from the speaker at the angle of 300 is reduced by 4 dB in order to make the tone
color to be similar to that of the sound at the angle of 600, and the component within the
range of 2 kHz to 5 kHz in the sound reproduced from the speaker located at the angle of
1100 is increased by 4 dB in order to make the tone color to be similar to that of the sound at
the angle of 600.
[00154]       FIG. 12A shows a tone color correction filter that is to be applied to an audio
signal from the azimuth angle of 600 to be reproduced through the speaker at the azimuth
angle of 300, wherein the sound quality correction filter is applied to an entire frequency
                          Hen
section, that is, a ratio K between the spectrum (HRTF) of the tone color when the azimuth
angle is 600 and the spectrum (HRTF) of the tone color when the azimuth angle of 300 shown
in FIG. 10.
                             HSD
                             H&D
[00155]       In FIG. 12A,        becomes a filter that reduces a magnitude of a signal by 4 dB at
a frequency of 500 Hz or less, increases the magnitude of the signal by 5 dB at a frequency
between 500 Hz to 1.5 kHz, and by-passes the signal of the other frequency domain, similarly
to the above description.
[00156]       FIG. 12B shows a sound quality correction filter that is to be applied to an audio
signal from the azimuth angle 600 to be reproduced through the speaker at the azimuth angle
of 1100, wherein the sound quality correction filter is applied to the entire frequency section,
that is, a ratio H" between the spectrum (HRTF) of the tone color when the azimuth angle is
600 and the spectrum (HRTF) of the tone color when the azimuth angle is 1100 shown in FIG.
    HSD
    H1 1 D
10.
                             H6 D
                             HRD
[00157]       In FIG. 12B,        becomes a filter that increases the magnitude of the signal at the
frequency of 2 kHz to 7 kHz by 4 dB and by-passes the signal of the other frequency domain,
similarly to the above description.
[00158]       FIG. 13 is diagrams showing cases where there is an elevation deviation between
an output channel and a virtual audio source in a 3D virtual rendering.
                                                  21

[00159]      A virtual rendering is a technique for reproducing 3D sound from a 2D output
system such as the 5.1-channel system, that is, a rendering technique for forming an sound
image at a virtual location where there is no speaker, in particular, at a location having an
elevation angle.
[00160]      Virtual rendering techniques that provide an elevation perception by using 2D
output channels basically include two operations, that is, an HRTF correction filtering and a
multi-channel panning coefficient distribution. The HRTF correction filtering denotes a tone
color correction operation for providing a user with the elevation perception, that is, performs
similar functions as those of the tone color correction filtering described above with reference
to FIGS. 10 to 12.
[00161]      Here, as shown in FIG. 13A, it is assumed that the output channels are arranged
on a horizontal plane, and an elevation angle <p of a virtual audio source is 35*. In this case,
an elevation difference between an L channel, that is, a reproducing output channel, and the
virtual audio source is 35, and the HRTF with respect to the virtual audio source may be
defined as
[00162]      On the contrary, as shown in FIG. 13B, it is assumed that the output channel has a
greater elevation angle. In this case, although an elevation difference between the L channel,
that is, the reproducing output channel, and the virtual audio source is 35, the output channel
has a greater elevation angle, the HRTF with respect to the virtual audio source may be
defined as HE(_.sy
                                                             HE(-3s)
                                                                         HECBr)
[00163]      Here, a relationship expressed by an equation                      may be obtained.
In addition, if there is no elevation difference between the virtual audio source and the output
channel, the tone color correction by using the elevation correction filter   Hno    is not
performed. HE(c)
[00164]      The above rendering operation may be generalized as shown in Table 1 below.
          [Table 1]
                           Elevation angle of       Whether to use tone
Elevation angle of                                                           Filter type (filter
                           reproduction speaker     color conversion
virtual audio source                                                         cefcet
                           (output channel)         filter
                                                 22

00                        00                        Not used
                                                                              1
00                        (Po                       Used                    HEq
(Po                       00                        Used                    HEM
(PO                       (Po                       Not used
[00165]     Here, a case where the tone color conversion filter is not used is the same as a case
where a by-pass filtering is performed. Table 1 above may be applied to a case when the
elevation difference is within a predetermined range from p, as well as a case when the
elevation difference is accurately <p or -<p.
[00166]     FIG. 14 is a diagram illustrating a virtual rendering of a TFC channel by using
L/R/LS/RS channels, according to an embodiment.
[00167]     The TFC channel is located at an azimuth angle of 00 and an elevation angle of
350, and locations of horizontal channels L, R, LS, and RS for virtually rendering the TFC
channel are as shown in FIG. 14 and Table 2 below.
        [Table 2]
Speaker (output channel)           Azimuth angle (azimuth)         Elevation angle (elevation)
L                                  -450                            350
R                                  300                             00
LS                                 -1100                           00
RS                                 1350                            00
[00168]     As shown in FIG. 14 and Table 2 above, the R channel and the LS channel are
arranged according to the standard layout, the RS channel has an azimuth deviation of 250,
and the L channel has an elevation deviation of 350 and an azimuth deviation of 150.
[00169]     The method of applying the virtual rendering to the TFC channel by using the
L/R/LS/RS channels according to an embodiment is performed in following order.
[00170]     Firstly, a panning coefficient is calculated. The panning gain may be calculated by
loading initial values for virtual rendering of the TFC channel, wherein the initial values are
stored in a storage, or by using a 2D rendering, a VBAP, etc.
[00171]     Secondly, the panning coefficient is modified (corrected) according to the
arrangement of channels. When the layout of the output channels is as shown in FIG. 14, the
L channel has the elevation deviation, a panning gain that is modified by the elevation effect
compensator 124 is applied to the L channel and the R channel for performing a pair-wise
                                                 23

panning using the L-R channels. On the other hand, since the RS channel has the azimuth
deviation, a panning coefficient that is modified by a general method is applied to the LS
channel and the RS channel for performing the pair-wise panning using the LS-RS channels.
[00172]     Thirdly, the tone color is corrected by the tone color conversion filter. Since the R
channel and the LS channel are arranged according to the standard layout, a filter HE that is
the same as that of the original virtual rendering is applied thereto.HE
[00173]     Since the RS channel only has the azimuth deviation and no elevation deviation,
the filter HE  that is the same as that of the original virtual rendering operation is used, but a
filter HMlUo /HM13s for correcting HEthe component shifted from 1100 that is the azimuth
angle of the RS channel according to the standard layout to the azimuth angle 135'. Here,
Hm110 is an HRTF with respect to the audio source at the angle of 1100 and             HM13s is an
HRTF with respect to the audio source at the angle of 135 H            135. However, in this case,
since the azimuth angles 1100 and 1350 are relatively close to each other, the TFC channel
signal rendered to RS output channel may be by-passed.
[00174]     The L channel has both the azimuth deviation and the elevation deviation from the
standard layout, and thus, the filter     HE  that is to be applied originally for performing the
virtual rendering, a filter  HTOOO /HTo4s    for compensating for the tone color of the TFC channel
and the tone color at the location of the L channel is applied. Here, HTOOO is an HRTF with
respect to the standard layout of the TFC channel, and         HT045   is an HRTF with respect to the
location where the L channel is arranged. Otherwise, in the above case, since the location of
the TFC channel and the location of the L channel are relatively close to each other, it may be
determine to by-pass the TFC channel signal rendered to L output channel.
[00175]     The rendering unit generates an output signal by filtering the input signal and
multiplying the input signal by the panning gain, and the panning unit and the filtering unit
operate independently from each other. This will be cleared with reference to a block diagram
of FIG. 15.
                                                     24

[00176]     FIG. 15 is a block diagram of a renderer that processes a deviation in a virtual
rendering by using 5.1 output channels, according to an embodiment.
[00177]     The block diagram of the renderer shown in FIG. 15 illustrates an output and a
process of each block, when the L/R/LS/RS output channels that are arranged according to
the layout of FIG. 14 are used to perform the virtual rendering of the TFC channel by using
the L/S/LS/RS channels like in the embodiment illustrated with reference to FIG. 14.
[00178]     The panning unit firstly calculates a virtual rendering panning gain in the 5.1
channels. In the embodiment shown in FIG. 14, the panning gain may be determined by
loading initial values that are set to perform the virtual rendering of the TFC channel by using
the L/R/LS/RS channels. Here, the panning gains determined to be applied to the L/R/LS/RS
channels are   9L0, gRO     gLSO   and  9RSO,
[00179]     In a next block, the panning gains between the L-R channels and the LS-RS
channels are modified based on the deviation between the standard layout of the output
channels and the arrangement layout of the output channels.
[00180]     In a case of the LS-RS channels, since the LS channel only has the azimuth
deviation, the panning gains may be modified by a general method. Modified panning gains
are 9LS and    9RS.  In a case of the L-R channels, since the R channel has the elevation
deviation, the panning gains are modified by the elevation effect compensator 124 for
correcting the elevation effect. Modified panning gains are 9L and sR.
[00181]     The filtering unit 121 receives an input signal Mc, and performs the filtering
operation with respect to each channel. Since the R channel and the LS channel are arranged
according to the standard layout, the filter    HE  that is the same as that of the original virtual
rendering operation is applied thereto. Here,HE outputs from the filter are                addC,R
XrCp cLS
[00182]     Since the RS channel has no elevation deviation and only has the azimuth
deviation, the filter  HE  that is the same as that of the original virtual rendering is used, and a
correction filter  HM110 /HMlZS   is applied to a component that is shifted from the azimuth angle
                                                   25

1100 of the LS channel according to the standard layout to the angle 1350. Here, an output
signal from the filter is XTFCas
[00183]       The L channel has both the azimuth deviation and the elevation deviation with
respect to the standard layout, and thus, the filter   HE  that is originally applied for performing
the virtual rendering is not applied, but a filter  HTOOO /HT0     is applied for correcting a tone
color of the TFC channel and a tone color at the location of the L channel. Here, an output
signal from the filter is XTICL.
[00184]       The output signals from the filters applied respectively to the channels, that is,
    c,"        cR, XcLS,    and  XTGcRs   are multiplied by the panning gains      9L, 9R,  9Ls, and
9Rs    that are modified by the panning unit to output signals     YTFL      TFcR    TFCLs, and
  TE-Rs    from the renderer with respect to the channel signals.
[00185]       The embodiments according to the present invention can also be embodied as
programmed commands to be executed in various computer configuration elements, and then
can be recorded to a computer readable recording medium. The computer readable recording
medium may include one or more of the programmed commands, data files, data structures,
or the like. The programmed commands recorded to the computer readable recording medium
may be particularly designed or configured for the invention or may be well known to one of
ordinary skill in the art of computer software fields. Examples of the computer readable
recording medium include magnetic media including hard disks, magnetic tapes, and floppy
disks, optical media including CD-ROMs, and DVDs, magneto-optical media including
floptical disks, and a hardware apparatus designed to store and execute the programmed
commands in read-only memory (ROM), random-access memory (RAM), flash memories,
and the like. Examples of the programmed commands include not only machine codes
generated by a compiler but also include great codes to be executed in a computer by using
an interpreter. The hardware apparatus can be configured to function as one or more software
modules so as to perform operations for the invention, or vice versa.
[00186]       While the detailed description has been particularly described with reference to
non-obvious features of the present invention, it will be understood by one of ordinary skill in
                                                  26

the art that various deletions, substitutions, and changes in form and details of the
aforementioned apparatus and method may be made therein without departing from the spirit
and scope of the following claims.
[00187]      Therefore, the scope of the present invention is defined not by the detailed
description but by the appended claims, and all differences within the scope will be construed
as being included in the present invention.
                                                 27

                                              CLAIMS
         1.      A method of rendering an audio signal, the method comprising:
         receiving multi-channel signals including an input channel signal having a horizontal
channel;
         obtaining deviation information from an elevation angle of an output channel signal
and a standard loudspeaker elevation angle;
         obtaining filter coefficients for rendering the input channel signal into the output
channel signal; and
         when the elevation angle of the output channel signal is higher than the standard
loudspeaker elevation angle, modifying the filter coefficients, based on an inverse form of an
elevation filter using a Head-Related Transfer Function(HRTF) and the deviation
information.
         2.      The method of claim 1, wherein the standard loudspeaker has a horizontal
channel.
         3.      An apparatus for rendering an audio signal, the apparatus comprising:
         a receiver configured to receive multi-channel signals including an input channel
signal having a horizontal channel; and
         an obtainer configured to:
         obtain deviation information from an elevation angle of an output channel signal and
a standard loudspeaker elevation angle,
         obtain filter coefficients for rendering input channel signal into the output channel
signal, and
         when the elevation angle of the output channel signal is higher than the standard
loudspeaker elevation angle, modify the filter coefficients, based on an inverse form of an
elevation filter using a Head-Related Transfer Function(HRTF) and the deviation
information.
        4.       The apparatus of claim 3, wherein the standard loudspeaker has a horizontal
channel.
                                                  28

<removed-apn>   <removed-date>
                           1/19

<removed-apn>   <removed-date>
                           2/19

<removed-apn>   <removed-date>
                           3/19

<removed-apn>   <removed-date>
                           4/19

<removed-apn>   <removed-date>
                           5/19

<removed-apn>   <removed-date>
                           6/19

<removed-apn>   <removed-date>
                           7/19

<removed-apn>   <removed-date>
                           8/19

<removed-apn>   <removed-date>
                           9/19

<removed-apn>   <removed-date>
                           10/19

<removed-apn>   <removed-date>
                           11/19

<removed-apn>   <removed-date>
                           12/19

<removed-apn>   <removed-date>
                           13/19

<removed-apn>   <removed-date>
                           14/19

<removed-apn>   <removed-date>
                           15/19

<removed-apn>   <removed-date>
                           16/19

<removed-apn>   <removed-date>
                           17/19

<removed-apn>   <removed-date>
                           18/19

<removed-apn>   <removed-date>
                           19/19

