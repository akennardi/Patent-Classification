                                ABSTRACT
The Floor plan automatic recognition and 3D model transformation system
and method is for recognizing all the elements (walls, furniture, doors, basins
etc.) from an image of floor plan by utilizing deep learning methodology and
transforming the image to 3D model so that it enables users to see the 3D
model in the program or see the VR mode by using VR equipment. This
system comprises a program running on the mobile tablet, PC or laptop 110
and two programs running on the cloud 102. This system helps users to
intuitively explore more details about the floor plan and change the materials
in the 3D model with a maximum of freedom.

      System and method for the floor plan automatic
            recognition and 3D model transformation
Technical Field
[0001]         The present invention generally relates to architecture industry, which
relates to a method for creating 3D (three-dimensional) objects based on 2D (two
dimensional) floor plan images.
Background
[0002]         Traditionally, in order to create a 3D model of a property, the designers
need to first draw the 2D floor plan in a CAD (computer-aided design) software, then
the designers would export the floor plan image into a 3D CAD software (e.g.
SketchUp) and construct a 3D model based on the 2D image manually, which have
relatively high learning costs.
[0003]         Although it has recently become possible to integrate the process of
designing the floor plans in both 3D and 2D simultaneously. The process is in fact to
design the 3D model first, then easily convert the top view of 3D model to the 2D floor
plan, and usually not vice versa. The inverted way (from 2D to 3D) is generally much
more complicated to achieve a good result. And according to their customers'
feedbacks, the options of the 3D models are limited thus cannot satisfy the demands
from professionals.
Summary
[0004]         Our solution would be described by the following embodiments.
[0005]         The embodiments describe a technology including back-end and front-end
services that would allow transforming 2D floor plans to 3D models, this would be done
by recognizing the features that are of interest and generating models from the
corresponding features. The recognition process is divided into two parts, comprising
the detection of the infrastructure (e.g. walls, doors, windows, rooms and preferably
balconies) and the detection of the furniture (e.g. sofas, dining tables, beds, etc.), using
the techniques and algorithms in computer vision and machine learning. In the last

stage, the 3D model would be rendered by client and be shown on the screen to be
presented to the end users.
[0006]         In accordance with the present embodiments, there is provided a software
system in a client-server architecture, the client would allow the users to upload images
of the floor plans to the server, there would also be a collection of servers which are
responsible for executing the tasks of recognition and generating 3D models. The
process of recognition would be done separately in those servers.
[0007]         The servers would be configured to recognize the rooms, given the
information of the doors, windows and walls. And would output a 3D model in OBJ
format, with a JSON file which contains the parameters of each recognized furniture, for
instance, the location and the type of the furniture. The programming language used
would be including but not limited to: Python, Shell script, C#.
[0008]         Once the 3D models and other relevant information has been received,
the client would render the 3D model onto the screen thus be able to present to the
users.
[0009]         The software system would be configured to support multiple mainstream
platforms and different type of devices.
[0010]         In a further aspect, the system would allow customizations to the
generated model, e.g. changing the color and the textures of the generated 3D
furniture. And would be capable of storing the custom model into the cloud database.
[0011]         In a further aspect, the software system may be configured to provide an
immersive view in VR (virtual reality) once the 3D model has been successfully
generated.
[0012]         The present invention also provides a method to generate 3D model from
2D floor plan image. This method would also allow the user to view and to freely
explore the 3D model in different angles.
Advantageous Effects of Invention

[0013]        This system and method would be useful to help the users see the virtual
3D model and immerse in the virtual environment. Besides, it enables people to
substitute almost all the elements in the 3D model such as material, texture, color etc.
So that people can have intuitive feelings about the floor plan that is being inspected.
This system and method would be advantageous and could be utilized in many different
scenarios such as property inspections, property auction, "off-the-plan" sale, etc. and
would help enhance the competitiveness in the market substantially.
Brief Description of Drawings
[0014]        Preferred embodiments of the present invention are described hereinafter,
by way of non-limiting example only, with reference to the accompanying drawings, in
which:
[0015]        Figure 1 is a exemplary diagram of the overall framework of the system;
[0016]        Figure 2 is a flowchart of methods performed by the system;
[0017]        Figure 3 is the flowchart of the recognition processing method performed
by the system;
[0018]        Figure 4 is the breakdown of the room-detection method performed by the
system in Figure 3;
[0019]        Figure 5 is the detailed exemplary diagram showing how the data is
processed during the recognition processing method performed by the system;
[0020]        Figure 6A is an example of the floor plan image;
[0021]        Figure 6B is the 3D model of the walls detected from the floor plan and
generated by the wall-detection method performed by the system.
[0022]        Figure 7 is the example of final outputs from the system.

Detailed Description
[0023]         According to the present embodiments, there is provided a system and a
method that can enable a user to generate 3D models from a 2D floor plan image and
would allow the user to freely explore the 3D model. The system would preferably
support all mainstream platforms (Android, iOS, etc.).
[0024]         With reference to Figure 1, the system would be comprising:
               a cloud platform 102 which is comprising:
                  a back-end server 106 configured to:
                       receive request data and images from the clients; and
                      detect and extract the infrastructures from the 2D floor plan; and
                      transform the extracted infrastructure image to a 3D model; and
                      store the data of the infrastructures into files; and
                      send the data and 3D model file to the client, and
                  a GPU back-end server 108 configured to:
                       receive request data and images from the clients; and
                      detect and recognize the furniture from the 2D floor plan; and
                       record the coordinates for all elements; and
                      create a JSON file which stores the data of the furniture; and
                      send the JSON data to the client, and
                  a shared data storage 104; and
               front-end clients in different platforms 110 configured to:
                      allow the user to upload a photo of the floor plan to the server; and
                      allow the user to crop the image; and
                       receive the data and 3D model from server and render the 3D
               model to the user; and
                      allow the user to move the elements of 3D model and substitute
               features such as color, materials.
[0025]         As mentioned, the clients 110 would be used for uploading images of the
floor plans to the server, as well as rendering the 3D models on screen. Before
uploading an image, the client may ask the user to first perform some pre-processing
on the image, such as to identify which part of the image represents the floor plan.

Moreover, the client may compress the image when uploading it to the cloud platform
102.
[0026]          Once an image has been uploaded to the cloud platform 102, the cloud
platform 102 would dispatch the image to two servers and run the tasks of recognition
in parallel, the operations were shown in Figure 2. One server 106 is responsible for
executing the tasks of recognition and generating 3D models, the GPU server 108 is
used for detecting furniture via Faster R-CNN (Regional Convolutional Neural Network).
The servers may use the programming languages including but not limited to: Python
and Shell script.
[0027]          With reference to Figure 3, the raw data 314 is the uploaded image to the
cloud. When the server 106 received the raw data, it would execute the room detection
module 306 which takes the raw data 314 as the input and returns the room detection
data 312 as an output. In terms of the GPU server 108, it would execute the furniture
detection module 304 which would take the raw data 314 as the input and output a
JSON file 310, which contains the coordinates and the type of the furniture it has
recognized. These data would be sent back to the clients, when generating the models
of the furniture, the clients would choose the appropriate 3D model of the furniture from
its local storage, according to the information in the JSON file.
[0028]          To take a closer look at the room detection module 306, with reference to
Figure 4, there are several smaller modules that are encapsulated in the server 106,
which are used for detections and generations of 3D models. The submodules (402,
404, 406 and 408) in the room detection module 306 would make use of several
detection algorithms and image processing algorithms in OpenCV library. In terms of
generating the 3D models, the Potrace module 506 and Blender module 508 were
used, the Potrace module 506 is first used to convert the processed images to SVG
(Scalable Vector Graphics) format, then the SVG file would be used to extrude to a 3D
model by using Blender module 508.
Industrial Applicability

[0029]         The system and the method help property developers and agents to sell
the property in a more attractive way by showing the 3D model and the 'real' residential
environment. It helps people to create and demonstrate a 3D model within a few
seconds. Architects and interior designers are more confident with their work since they
are able to utilize this system to help them simulate the real model. It promotes the
furniture suppliers as well since this system comprises many materials from different
suppliers. The system will greatly lead the real estate market prosperous. This system
and method can also be used by the professionals to save their time on creating the 3D
models from the CAD drawings manually.
[0030]         This system and method can also be used by the professionals to save
their time on creating the 3D models from the CAD drawings manually, which could
greatly improve their efficiency.

                                     CLAIMS
        A system including:
        a computer system configured to:
            allow the user to upload a photo of the floor plan to the server;
            allow the user to crop the image;
            receive the data and 3D model from server and render the 3D model to
   the user;
            allow the user to move the elements of 3D model and substitute features
   such as color, materials ;and
        at least one server configured to:
            receive request data and images from the queries sent by the clients;
            detect and extract the infrastructures from the 2D floor plan;
            detect and recognize the furniture from the 2D floor plan and record the
   coordinates for all elements;
            create a JSON file which stores the data of the furniture and the
   infrastructures;
            store the data in a shared data storage;
            transform the extracted infrastructure image to a 3D model;
            send the data and 3D model file to the client.
2.      The system of claim 1, wherein the recognition of all elements from the
   images or the 3D models, comprising walls, doors, windows and furniture, is
   achieved by tools in the aspect of machine learning, comprising but not limited to
   Faster-RCNN or SSD (Single Shot MultiBox Detection).
3.      The system of claim 1 or 2, wherein the back-end server transforms an
   image of the infrastructures with coordinates data to a 3D model, which the
   server firstly converts a 2D image to a SVG image then extrude the SVG to a 3D
   model, the modules of Potrace* and Blender* were used during the process.
4.      The system of claim 1, wherein the system would provide an interactive way
   to inspect the rendered 3D model by allowing users to freely change the view, in

   a further aspect, the system could be extended to support VR, which allows the
   user to view rendered 3D models and move around immersively in a VR headset.
5.     The method including:
       detecting and recognizing the furniture from the 2D floor plan and record the
   coordinates for all elements;
       detecting and extracting the infrastructures from the 2D floor plan;
       transforming an image of a floor plan to a 3D model;

           <removed-apn>   <removed-date>
                                           1/8
Figure 1
                                Drawings

           <removed-apn>   <removed-date>
                                      2/8
Figure 2

           <removed-apn>   <removed-date>
                                      3/8
Figure 3

           <removed-apn>   <removed-date>
                                      4/8
Figure 4

           <removed-apn>   <removed-date>
                                      5/8
Figure 5

            <removed-apn>   <removed-date>
                                       6/8
Figure 6A

            <removed-apn>   <removed-date>
                                       7/8
Figure 6B

           <removed-apn>   <removed-date>
                                      8/8
Figure 7

