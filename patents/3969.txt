Abstract
A method for decoding an ambisonics audio soundfield representation for playback over
a plurality of loudspeakers comprises: receiving a first matrix that includes gain vectors
that are based on a panning based on positions of the loudspeakers and a plurality of
source directions, wherein the source directions are distributed evenly over a unit sphere,
a number of the source directions is S, the order of the ambisonics audio soundfield
representation is N, and S > (N+1)2; receiving a mode matrix determined based on the
source directions and an order of the ambisonics audio soundfield representation;
receiving a base matrix determined based on the mode matrix and the first matrix; and
decoding the ambisonics audio soundfield representation with a decoding matrix, wherein
the decoding matrix is based on the first matrix and the base matrix.
Fig.1

                            1/4
                  W
102
        L   110
103    /S
            120     *130           135
      N
      105
        get
      order
SF,                                      140 AUdec
Fig.1
                         *9
                              k' .
                                   vB
                                   11
                &                      s  x
Fig.2

                                                   1
   Method and device for decoding an audio soundfield representation for audio playback
   Field of the disclosure
 5 This disclosure relates to a method and a device for decoding an audio soundfield
   representation, and in particular an Ambisonics formatted audio representation, for audio
   playback.
   Background
10
   This section is intended to introduce the reader to various aspects of art, which may be
   related to various aspects of the present disclosure that are described and/or claimed
   below. This discussion is believed to be helpful in providing the reader with background
   information to facilitate a better understanding of the various aspects of the present
15 disclosure. Accordingly, it should be understood that these statements are to be read in
   this light, and not as admissions of prior art, unless a source is expressly mentioned.
   Accurate localisation is a key goal for any spatial audio reproduction system. Such
   reproduction systems are highly applicable for conference systems, games, or other
20 virtual environments that benefit from 3D sound. Sound scenes in 3D can be synthesised
   or captured as a natural sound field. Soundfield signals such as e.g. Ambisonics carry a
   representation of a desired sound field. The Ambisonics format is based on spherical
   harmonic decomposition of the soundfield. While the basic Ambisonics format or B-format
   uses spherical harmonics of order zero and one, the so-called Higher Order Ambisonics
25 (HOA) uses also further spherical harmonics of at least    2 nd order. A decoding process is
   required to obtain the individual loudspeaker signals. To synthesise audio scenes,
   panning functions that refer to the spatial loudspeaker arrangement, are required to
   obtain a spatial localisation of the given sound source. If a natural sound field should be
   recorded, microphone arrays are required to capture the spatial information. The known
30 Ambisonics approach is a very suitable tool to accomplish it. Ambisonics formatted
   signals carry a representation of the desired sound field. A decoding process is required
   to obtain the individual loudspeaker signals from such Ambisonics formatted signals.
   Since also in this case panning functions can be derived from the decoding functions, the
   panning functions are the key issue to describe the task of spatial localisation. The spatial
35 arrangement of loudspeakers is referred to as loudspeaker setup herein.

                                                  2
   Commonly used loudspeaker setups are the stereo setup, which employs two
   loudspeakers, the standard surround setup using five loudspeakers, and extensions of
   the surround setup using more than five loudspeakers. These setups are well known.
 5 However, they are restricted to two dimensions (2D), e.g. no height information is
   reproduced.
   Loudspeaker setups for three dimensional (3D) playback are described for example in
   "Wide listening area with exceptional spatial sound quality of a 22.2 multichannel sound
10 system",K. Hamasaki, T. Nishiguchi, R. Okumaura, and Y. Nakayama in Audio
   Engineering Society Preprints, Vienna, Austria, May 2007, which is a proposal for the
   NHK ultra high definition TV with 22.2 format, or the 2+2+2 arrangement of Dabringhaus
   (mdg-musikproduktion dabringhaus und grimm, www.mdq.de) and a 10.2 setup in "Sound
   for Film and Television", T. Holman in 2nd ed. Boston: Focal Press, 2002. One of the few
15 known systems referring to spatial playback and panning strategies is the vector base
   amplitude panning (VBAP) approach in "Virtual sound source positioning using vector
   base amplitude panning," Journal of Audio Engineering Society, vol. 45, no. 6, pp. 456
   466, June 1997, herein Pulkki. VBAP (Vector Base Amplitude Panning) has been used by
   Pulkki to play back virtual acoustic sources with an arbitrary loudspeaker setup. To place
20 a virtual source in a 2D plane, a pair of loudspeakers is required, while in a 3D case
   loudspeaker triplets are required. For each virtual source, a monophonic signal with
   different gains (dependent on the position of the virtual source) is fed to the selected
   loudspeakers from the full setup. The loudspeaker signals for all virtual sources are then
   summed up. VBAP applies a geometric approach to calculate the gains of the
25 loudspeaker signals for the panning between the loudspeakers.
   An exemplary 3D loudspeaker setup example considered and newly proposed herein has
   16 loudspeakers, which are positioned as shown in Fig.2. The positioning was chosen
   due to practical considerations, having four columns with three loudspeakers each and
30 additional loudspeakers between these columns. In more detail, eight of the loudspeakers
   are equally distributed on a circle around the listener's head, enclosing angles of 45
   degrees. Additional four speakers are located at the top and the bottom, enclosing
   azimuth angles of 90 degrees. With regard to Ambisonics, this setup is irregular and
   leads to problems in decoder design, as mentioned in "An ambisonics format for flexible

                                                   3
   playback layouts," by H. Pomberger and F. Zotter in Proceedings of the 1s Ambisonics
   Symposium, Graz, Austria, July 2009.
   Conventional Ambisonics decoding, as described in "Three-dimensional surround sound
 5 systems based on spherical harmonics" by M. Poletti in J. Audio Eng. Soc., vol. 53, no.
   11, pp. 1004-1025, Nov. 2005, employs the commonly known mode matching process.
   The modes are described by mode vectors that contain values of the spherical harmonics
   for a distinct direction of incidence. The combination of all directions given by the
   individual loudspeakers leads to the mode matrix of the loudspeaker setup, so that the
10 mode matrix represents the loudspeaker positions. To reproduce the mode of a distinct
   source signal, the loudspeakers' modes are weighted in that way that the superimposed
   modes of the individual loudspeakers sum up to the desired mode. To obtain the
   necessary weights, an inverse matrix representation of the loudspeaker mode matrix
   needs to be calculated. In terms of signal decoding, the weights form the driving signal of
15 the loudspeakers, and the inverse loudspeaker mode matrix is referred to as "decoding
   matrix", which is applied for decoding an Ambisonics formatted signal representation. In
   particular, for many loudspeaker setups, e.g. the setup shown in Fig.2, it is difficult to
   obtain the inverse of the mode matrix.
20 As mentioned above, commonly used loudspeaker setups are restricted to 2D, i.e. no
   height information is reproduced. Decoding a soundfield representation to a loudspeaker
   setup with mathematically non-regular spatial distribution leads to localization and
   coloration problems with the commonly known techniques. For decoding an Ambisonics
   signal, a decoding matrix (i.e. a matrix of decoding coefficients) is used. In conventional
25 decoding of Ambisonics signals, and particularly HOA signals, at least two problems
   occur. First, for correct decoding it is necessary to know signal source directions for
   obtaining the decoding matrix. Second, the mapping to an existing loudspeaker setup is
   systematically wrong due to the following mathematical problem: a mathematically correct
   decoding will result in not only positive, but also some negative loudspeaker amplitudes.
30 However, these are wrongly reproduced as positive signals, thus leading to the above
   mentioned problems.
   Throughout this specification the word "comprise", or variations such as "comprises" or
   "comprising", will be understood to imply the inclusion of a stated element, integer or

                                                   4
   step, or group of elements, integers or steps, but not the exclusion of any other element,
   integer or step, or group of elements, integers or steps.
   Any discussion of documents, acts, materials, devices, articles or the like which has been
 5 included in the present specification is not to be taken as an admission that any or all of
   these matters form part of the prior art base or were common general knowledge in the
   field relevant to the present disclosure as it existed before the priority date of each claim
   of this application.
10 Summary of the disclosure
   The present disclosure describes a method for decoding a soundfield representation for
   non-regular spatial distributions with highly improved localization and coloration
   properties. It represents another way to obtain the decoding matrix for soundfield data,
15 e.g. in Ambisonics format, and it employs a process in a system estimation manner.
   Considering a set of possible directions of incidence, the panning functions related to the
   desired loudspeakers are calculated. The panning functions are taken as output of an
   Ambisonics decoding process. The required input signal is the mode matrix of all
   considered directions. Therefore, as shown below, the decoding matrix is obtained by
20 right multiplying the weighting matrix by an inverse version of the mode matrix of input
   signals.
   Concerning the second problem mentioned above, it has been found that it is also
   possible to obtain the decoding matrix from the inverse of the so-called mode matrix,
25 which represents the loudspeaker positions, and position-dependent weighting functions
   ("panning functions") W. One aspect of the disclosure is that these panning functions W
   can be derived using a different method than commonly used. Advantageously, a simple
   geometrical method is used. Such method requires no knowledge of any signal source
   direction, thus solving the first problem mentioned above. One such method is known as
30 "Vector-Based Amplitude Panning" (VBAP). According to the disclosure, VBAP is used to
   calculate the required panning functions, which are then used to calculate the Ambisonics
   decoding matrix. Another problem occurs in that the inverse of the mode matrix (that
   represents the loudspeaker setup) is required. However, the exact inverse is difficult to
   obtain, which also leads to wrong audio reproduction. Thus, an additional aspect is that

                                                 5
   for obtaining the decoding matrix a pseudo-inverse mode matrix is calculated, which is
   much easier to obtain.
   The disclosure uses a two step approach. The first step is a derivation of panning
 5 functions that are dependent on the loudspeaker setup used for playback. In the second
   step, an Ambisonics decoding matrix is computed from these panning functions for all
   loudspeakers.
   An advantage of the disclosure is that no parametric description of the sound sources is
10 required; instead, a soundfield description such as Ambisonics can be used.
   A method for decoding an audio soundfield representation for audio playback, wherein
   the audio soundfield representation is an Ambisonics format of an order N, with N       2,
   comprising steps of calculating, for each of a plurality of loudspeakers, a panning function
15 using a geometrical method based on the positions of the loudspeakers and a plurality of
   source directions, calculating a mode matrix from the source directions, calculating a
   pseudo-inverse mode matrix of the mode matrix, and decoding the audio soundfield
   representation, wherein the decoding is based on a decode matrix that is obtained from
   at least the panning function and the pseudo-inverse mode matrix wherein the plurality of
20 source directions comprises S source directions, with S       (N+1).
   A device for decoding an audio soundfield representation for audio playback, wherein the
   audio soundfield representation is Ambisonics format of an order N, with N        2,
   comprising first calculating means for calculating, for each of a plurality of loudspeakers,
25 a panning function using a geometrical method based on the positions of the
   loudspeakers and a plurality of source directions, second calculating means for
   calculating a mode matrix from the source directions, third calculating means for
   calculating a pseudo-inverse mode matrix of the mode matrix, and decoder means for
   decoding the soundfield representation, wherein the decoding is based on a decode
30 matrix and the decoder means uses at least the panning function and the pseudo-inverse
   mode matrix to obtain the decode matrix wherein the plurality of source directions
   comprises S source directions, with S 2 (N+1). The first, second and third calculating
   means can be a single processor or two or more separate processors.

                                                     6
   A computer readable medium having stored on it executable instructions to cause a
   computer to perform a method for decoding an audio soundfield representation for audio
   playback, wherein the audio soundfield representation is an Ambisonics format of an
   order N, with N      2, the method comprising steps of calculating, for each of a plurality of
 5 loudspeakers, a panning function using a geometrical method based on the positions of
   the loudspeakers and a plurality of source directions, calculating a mode matrix from the
   source directions, calculating pseudo-inverse mode matrix of the mode matrix, and
   decoding the audio soundfield representation, wherein the decoding is based on a
   decode matrix that is obtained from at least the panning function and the pseudo-inverse
10 mode matrix wherein the plurality of source directions comprises S source directions, with
   S   (N+1).
   One embodiment provides a method for decoding an ambisonics audio soundfield
   representation for playback over a plurality of loudspeakers, the method comprising:
15           obtaining, for each of a plurality of loudspeakers, a panning function using a
   geometrical method based on positions of the loudspeakers and a plurality of source
   directions;
             obtaining a mode matrix from the source directions and an order of the
   ambisonics audio soundfield representation;
20           obtaining a base matrix from the mode matrix; and
             decoding the ambisonics audio soundfield representation with a decoding matrix,
   wherein the decoding matrix is based on the panning function and the base matrix, the
   source directions are distributed evenly over a unit sphere, and a number of the source
   directions is S, the order of the ambisonics audio soundfield representation is N, and S >
25 (N+1) 2 .
   One embodiment provides a device for decoding an ambisonics audio soundfield
   representation for playback over a plurality of loudspeakers, the device comprising:
             a means for obtaining, for each of a plurality of loudspeakers, a panning function
30 using a geometrical method based on positions of the loudspeakers and a plurality of
   source directions;
             a means for obtaining a mode matrix from the source directions and an order of
   the ambisonics audio soundfield representation;
             a means for obtaining a base matrix from the mode matrix; and

                                                     7
             a means for decoding the ambisonics audio soundfield representation with a
   decoding matrix, wherein the decoding matrix is based on the panning function and the
   base matrix, the source directions are distributed evenly over a unit sphere, and a
   number of the source directions is S, the order of the ambisonics audio soundfield
 5 representation is N, and S > (N+1.)2
   One embodiment provides a computer readable medium having stored on it executable
   instructions to cause a computer to perform a method for decoding an ambisonics audio
   soundfield representation for audio playback, the method comprising steps of:
10           obtaining, for each of a plurality of loudspeakers, a panning function using a
   geometrical method based on positions of the loudspeakers and a plurality of source
   directions;
             obtaining a mode matrix from the source directions and an order of the
   ambisonics audio soundfield representation;
15           obtaining a base matrix from the mode matrix; and
             decoding the ambisonics audio soundfield representation with a decoding matrix,
   wherein the decoding matrix is based on the panning function and the base matrix, the
   source directions are distributed evenly over a unit sphere, and a number of the source
   directions is S, the order of the ambisonics audio soundfield representation is N, and S >
20 (N+1) 2 .
   One embodiment provides a method for decoding an ambisonics audio soundfield
   representation for playback over a plurality of loudspeakers, the method comprising:
             receiving a first matrix that includes gain vectors that are based on a panning
25 based on positions of the loudspeakers and a plurality of source directions, wherein the
   source directions are distributed evenly over a unit sphere, a number of the source
   directions is S, the order of the ambisonics audio soundfield representation is N, and S >
   (N+1  )2;
             receiving a mode matrix determined based on the source directions and an order
30 of the ambisonics audio soundfield representation; receiving a base matrix determined
   based on the mode matrix and the first matrix; and
             decoding the ambisonics audio soundfield representation with a decoding matrix,
   wherein the decoding matrix is based on the first matrix and the base matrix.

                                                   8
   One embodiment provides a device for decoding an ambisonics audio soundfield
   representation for playback over a plurality of loudspeakers, the device comprising:
           a means for receiving a first matrix that includes gain vectors that are based on a
   panning based on positions of the loudspeakers and a plurality of source directions,
 5 wherein the source directions are distributed evenly over a unit sphere, a number of the
   source directions is S, the order of the ambisonics audio soundfield representation is N,
   and S > (N+1) 2 ;
           a means for receiving a mode matrix determined based on the source directions
   and an order of the ambisonics audio soundfield representation;
10         a means for receiving a base matrix determined based on the mode matrix; and
           a means for decoding the ambisonics audio soundfield representation with a
   decoding matrix, wherein the decoding matrix is based on the first matrix and the base
   matrix.
15 One embodiment provides a non-transitory computer readable medium having stored on
   it executable instructions to cause a computer to perform a method for decoding an
   ambisonics audio soundfield representation for audio playback, the method comprising
   steps of:
           receiving a first matrix that includes gain vectors that are a panning based on
20 positions of the loudspeakers and a plurality of source directions, wherein the source
   directions are distributed evenly over a unit sphere, a number of the source directions is
   S, the order of the ambisonics audio soundfield representation is N, and S > (N+1    )2;
           receiving a mode matrix determined based on the source directions and an order
   of the ambisonics audio soundfield representation;
25         receiving a base matrix determined based on the mode matrix and the first matrix;
   and
           decoding the ambisonics audio soundfield representation with a decoding matrix
   wherein the decoding matrix is based on the first matrix and the base matrix, wherein the
   decoding matrix is based on the first matrix and the base matrix.
30
   Brief description of the drawings
   Exemplary embodiments of the disclosure are described with reference to the
   accompanying drawings, which show in

                                                9
   Fig.1 a flow-chart of the method;
   Fig.2 an exemplary 3D setup with 16 loudspeakers;
   Fig.3 a beam pattern resulting from decoding using non-regularized mode matching;
 5 Fig.4 a beam pattern resulting from decoding using a regularized mode matrix;
   Fig.5 a beam pattern resulting from decoding using a decoding matrix derived from
   VBAP;
   Fig.6 results of a listening test; and
   Fig.7 and a block diagram of a device.
10
   Detailed description of the disclosure
   As shown in Fig.1, a method for decoding an audio soundfield representation SFc for
   audio playback comprises steps of calculating 110, for each of a plurality of
15 loudspeakers, a panning function W using a geometrical method based on the positions
   102 of the loudspeakers (L is the number of loudspeakers) and a plurality of source
   directions 103 (S is the number of source directions), calculating 120 a mode matrix E
   from the source directions and a given order N of the soundfield representation,
   calculating 130 a pseudo-inverse mode matrix E of the mode matrix E, and decoding
20 135,140 the audio soundfield representation SFc. wherein decoded sound data       AUdec  are
   obtained. The decoding is based on a decode matrix D that is obtained 135 from at least
   the panning function W and the pseudo-inverse mode matrix E*. In one embodiment, the
   pseudo-inverse mode matrix is obtained according to E* = EH [       H 1 . The order N of the
   soundfield representation may be pre-defined, or it may be extracted 105 from the input
25 signal SFc.
   As shown in Fig.7, a device for decoding an audio soundfield representation for audio
   playback comprises first calculating means 210 for calculating, for each of a plurality of
   loudspeakers, a panning function W using a geometrical method based on the positions
30 102 of the loudspeakers and a plurality of source directions 103, second calculating
   means 220 for calculating a mode matrix E from the source directions, third calculating
   means 230 for calculating a pseudo-inverse mode matrix E* of the mode matrix E , and
   decoder means 240 for decoding the soundfield representation. The decoding is based
   on a decode matrix D, which is obtained from at least the panning function W and the
35 pseudo-inverse mode matrix E* by a decode matrix calculating means 235 (e.g. a

                                                    10
   multiplier). The decoder means 240 uses the decode matrix D to obtain a decoded audio
   signal  AUdec.   The first, second and third calculating means 220,230,240 can be a single
   processor, or two or more separate processors. The order N of the soundfield
   representation may be pre-defined, or it may be obtained by a means 205 for extracting
 5 the order from the input signal SFc.
   A particularly useful 3D loudspeaker setup has 16 loudspeakers. As shown in Fig.2, there
   are four columns with three loudspeakers each, and additional loudspeakers between
   these columns. Eight of the loudspeakers are equally distributed on a circle around the
10 listener's head, enclosing angles of 45 degrees. Additional four speakers are located at
   the top and the bottom, enclosing azimuth angles of 90 degrees. With regard to
   Ambisonics, this setup is irregular and usually leads to problems in decoder design.
   In the following, Vector Base Amplitude Panning (VBAP) is described in detail. In one
15 embodiment, VBAP is used herein to place virtual acoustic sources with an arbitrary
   loudspeaker setup where the same distance of the loudspeakers from the listening
   position is assumed. VBAP uses three loudspeakers to place a virtual source in the 3D
   space. For each virtual source, a monophonic signal with different gains is fed to the
   loudspeakers to be used. The gains for the different loudspeakers are dependent on the
20 position of the virtual source. VBAP is a geometric approach to calculate the gains of the
   loudspeaker signals for the panning between the loudspeakers. In the 3D case, three
   loudspeakers arranged in a triangle build a vector base. Each vector base is identified by
   the loudspeaker numbers k,m,n and the loudspeaker position vectors        Ik,In, 1,given in
   Cartesian coordinates normalised to unity length. The vector base for loudspeakers k,m,n
25 is defined by
            Lkm, =flk, Im,I,}                                            (1
   The desired direction Q = (0,$) of the virtual source has to be given as azimuth angle      +
   and inclination angle 0. The unity length position vector p(Q) of the virtual source in
   Cartesian coordinates is therefore defined by
30          p(Q)   ={cos# sin 0, sin# sin 0, cosO}T                               (2)
   A virtual source position can be represented with the vector base and the gain factors
   g(Q) =(gk,     gm, gn)Tby
            p(   )= Lkn g(f2) =~gk Ik+~gm Im+ gn In                      (3)
   By inverting the vector base matrix the required gain factors can be computed by
35          g(Q) =    L-'kmn P(Q)                                                 (4)

                                                    11
   The vector base to be used is determined according to Pulkki's document: First the gains
   are calculated according to Pulkki for all vector bases. Then for each vector base the
   minimum over the gain factors is evaluated by ~gmin = min{~gk, ~gm, ~gn}. Finally the vector
   base where ~gmin has the highest value is used. The resulting gain factors must not be
 5 negative. Depending on the listening room acoustics the gain factors may be normalised
   for energy preservation.
    In the following, the Ambisonics format is described, which is an exemplary soundfield
   format. The Ambisonics representation is a sound field description method employing a
10 mathematical approximation of the sound field in one location. Using the spherical
   coordinate system, the pressure at point r = (r,0,$) in space is described by means of the
   spherical Fourier transform
                   p~~r~kAA"k ) j, (kr) Y"(0,0p)
                          n=Or=-n
                                                                                   (5)
   where k is the wave number. Normally n runs to a finite order M. The coefficients Amn(k)
15 of the series describe the sound field (assuming sources outside the region of validity),
   jn(kr) is the spherical Bessel function of first kind and Ymn (6,4) denote the spherical
   harmonics. Coefficients A"' (k) are regarded as Ambisonics coefficients in this context.
   The spherical harmonics Ym n (0,$) only depend on the inclination and azimuth angles and
   describe a function on the unity sphere.
20 For reasons of simplicity often plain waves are assumed for sound field reproduction. The
   Ambisonics coefficients describing a plane wave as an acoustic source from direction 0,
   are
               Amnplane (fOs    --      in Y
                                        E            sm
                                                                                   (6)
   Their dependency on wave number k decreases to a pure directional dependency in this
25 special case. For a limited order M the coefficients form a vector A that may be arranged
   as
                     Af(s2)=     AO A-'      AO     At   ... Am ]T
                                                                                   (7)
   holding 0 = (M + 1)2 elements. The same arrangement is used for the spherical
   harmonics coefficients yielding a vector Y(Os)       = .(   Y0Y-      Yo   Y1        A1M ]H

                                                12
   Superscript H denotes the complex conjugate transpose.
   To calculate loudspeaker signals from an Ambisonics representation of a sound field,
   mode matching is a commonly used approach. The basic idea is to express a given
 5 Ambisonics sound field description A(Q,) by a weighted sum of the loudspeakers' sound
   field descriptions A(QI)
                        L
            A (f2,)=       w 1A(.0)
                      1=1
                                                                                 (8)
   where Q denote the loudspeakers' directions, w, are weights, and L is the number of
   loudspeakers. To derive panning functions from eq.(8), we assume a known direction of
10 incidence Q,. If source and speaker sound fields are both plane waves, the factor 47[i"
   (see eq.(6)) can be dropped and eq.(8) only depends on the complex conjugates of
   spherical harmonic vectors, also referred to as "modes". Using matrix notation, this is
   written as
            Y(Qs)* =T w(Os)                                                      (9)
15 where T is the mode matrix of the loudspeaker setup
               '   [Y(A 1 )*,y(f  2 )* .  Y(fL)*]
                                                                                 (10)
   with 0 x L elements. To obtain the desired weighting vector w, various strategies to
   accomplish this are known. If M = 3 is chosen, T is square and may be invertible. Due to
   the irregular loudspeaker setup the matrix is badly scaled, though. In such a case, often
20 the pseudo inverse matrix is chosen and
            D = [THT]-1 T H
   yields a L x 0 decoding matrix D. Finally we can write
            w(Q,) = DY(Qs)*                                                      (12)
   where the weights w(Qs) are the minimum energy solution for eq.(9). The consequences
25 from using the pseudo inverse are described below.
   The following describes the link between panning functions and the Ambisonics decoding
   matrix. Starting with Ambisonics, the panning functions for the individual loudspeakers
   can be calculated using eq.(12). Let
30          E = [Y(Q,)*,Y(Q2)*, .,Y(Qs)*]                               (13)
   be the mode matrix of S input signal directions (Q.), e. g. a spherical grid with an
   inclination angle running in steps of one degree from 1 ...180* and an azimuth angle from

                                                   13
   1.. .3600 respectively. This mode matrix has 0 x S elements. Using eq.(12), the resulting
   matrix W has L x S elements, row I holds the S panning weights for the respective
   loudspeaker:
            W = DE                                                               (14)
 5
   As a representative example, the panning function of a single loudspeaker 2 is shown as
   beam pattern in Fig.3. The decode matrix D of the order M = 3 in this example. As can be
   seen, the panning function values do not refer to the physical positioning of the loud
   speaker at all. This is due to the mathematical irregular positioning of the loudspeakers,
10 which is not sufficient as a spatial sampling scheme for the chosen order. The decode
   matrix is therefore referred to as a non-regularized mode matrix. This problem can be
   overcome by regularisation of the loudspeaker mode matrix T in eq.(1 1). This solution
   works at the expense of spatial resolution of the decoding matrix, which in turn may be
   expressed as a lower Ambisonics order. Fig.4 shows an exemplary beam pattern
15 resulting from decoding using a regularized mode matrix, and particularly using the mean
   of eigenvalues of the mode matrix for regularisation. Compared with Fig.3, the direction of
   the addressed loudspeaker is now clearly recognised.
   As outlined in the introduction, another way to obtain a decoding matrix D for playback of
20 Ambisonics signals is possible when the panning functions are already known. The
   panning functions W are viewed as desired signal defined on a set of virtual source
   directions Q, and the mode matrix E of these directions serves as input signal. Then the
   decoding matrix can be calculated using
            D =W EH [      H -1= W E+                                            (15)
25
   where EH           or simply-1-+ is the pseudo inverse of the mode matrix E. In the new
   approach, we take the panning functions in W from VBAP and calculate an Ambisonics
   decoding matrix from this.
30 The panning functions for W are taken as gain values g(Q) calculated using eq.(4), where
   Q is chosen according to eq.(13). The resulting decode matrix using eq.(15) is an
   Ambisonics decoding matrix facilitating the VBAP panning functions. An example is
   depicted in Fig.5, which shows a beam pattern resulting from decoding using a decoding
   matrix derived from VBAP. Advantageously, the side lobes SL are significantly smaller
35 than the side lobes SLeg of the regularised mode matching result of Fig.4. Moreover, the

                                                    14
   VBAP derived beam pattern for the individual loudspeakers follow the geometry of the
   loudspeaker setup as the VBAP panning functions depend on the vector base of the
   addressed direction. As a consequence, the new approach according to the disclosure
   produces better results over all directions of the loudspeaker setup.
 5
   The source directions 103 can be rather freely defined. A condition for the number of
   source directions S is that it must be at least (N+1)2. Thus, having a given order N of the
   soundfield signal SFc it is possible to define S according to S > (N+1)2, and distribute the
   S source directions evenly over a unity sphere. As mentioned above, the result can be a
10 spherical grid with an inclination angle 0 running in constant steps of x (e.g. x = 1...5 or
   x=10,20 etc.) degrees from 1... 1800 and an azimuth angle     4from  1...360' respectively,
   wherein each source direction Q = (O,$) can be given by azimuth angle $ and inclination
   angle 0.
15 The advantageous effect has been confirmed in a listening test. For the evaluation of the
   localisation of a single source, a virtual source is compared against a real source as a
   reference. For the real source, a loudspeaker at the desired position is used. The
   playback methods used are VBAP, Ambisonics mode matching decoding, and the newly
   proposed Ambisonics decoding using VBAP panning functions according to the present
20 disclosure. For the latter two methods, for each tested position and each tested input
   signal, an Ambisonics signal of third order is generated. This synthetic Ambisonics signal
   is then decoded using the corresponding decoding matrices. The test signals used are
   broadband pink noise and a male speech signal. The tested positions are placed in the
   frontal region with the directions
25          Q1 = (76.10, -23.2*), Q2 = (63.3*, -4.3*)                             (16)
   The listening test was conducted in an acoustic room with a mean reverberation time of
   approximately 0.2 s. Nine people participated in the listening test. The test subjects were
   asked to grade the spatial playback performance of all playback methods compared to
   the reference. A single grade value had to be found to represent the localisation of the
30 virtual source and timbre alterations. Fig.5 shows the listening test results.
   As the results show, the unregularised Ambisonics mode matching decoding is graded
   perceptually worse than the other methods under test. This result corresponds to Fig.3.
   The Ambisonics mode matching method serves as anchor in this listening test. Another
35 advantage is that the confidence intervals for the noise signal are greater for VBAP than

                                                 15
   for the other methods. The mean values show the highest values for the Ambisonics
   decoding using VBAP panning functions. Thus, although the spatial resolution is reduced
   - due to the Ambisonics order used - this method shows advantages over the parametric
   VBAP approach. Compared to VBAP, both Ambisonics decoding with robust and VBAP
 5 panning functions have the advantage that not only three loudspeakers are used to
   render the virtual source. In VBAP single loudspeakers may be dominant if the virtual
   source position is close to one of the physical positions of the loudspeakers. Most
   subjects reported less timbre alterations for the Ambisonics driven VBAP than for directly
   applied VBAP. The problem of timbre alterations for VBAP is already known from Pulkki.
10 In opposite to VBAP, the newly proposed method uses more than three loudspeakers for
   playback of a virtual source, but surprisingly produces less coloration.
   As a conclusion, a new way of obtaining an Ambisonics decoding matrix from the VBAP
   panning functions is disclosed. For different loudspeaker setups, this approach is
15 advantageous as compared to matrices of the mode matching approach. Properties and
   consequences of these decoding matrices are discussed above. In summary, the newly
   proposed Ambisonics decoding with VBAP panning functions avoids typical problems of
   the well known mode matching approach. A listening test has shown that VBAP-derived
   Ambisonics decoding can produce a spatial playback quality better than the direct use of
20 VBAP can produce. The proposed method requires only a sound field description while
   VBAP requires a parametric description of the virtual sources to be rendered.
   While there has been shown, described, and pointed out fundamental novel features of
   the present disclosure as applied to preferred embodiments thereof, it will be understood
25 that various omissions and substitutions and changes in the apparatus and method
   described, in the form and details of the devices disclosed, and in their operation, may be
   made by those skilled in the art without departing from the spirit of the present disclosure.
   It is expressly intended that all combinations of those elements that perform substantially
   the same function in substantially the same way to achieve the same results are within
30 the scope of the disclosure. Substitutions of elements from one described embodiment to
   another are also fully intended and contemplated. It will be understood that modifications
   of detail can be made without departing from the scope of the disclosure. Each feature
   disclosed in the description and (where appropriate) the claims and drawings may be
   provided independently or in any appropriate combination. Features may, where
35 appropriate be implemented in hardware, software, or a combination of the two.

                                              16
Any reference numerals appearing in the claims are by way of illustration only and shall
have no limiting effect on the scope of the claims.

                                                    17
   Claims
             1.      A method for decoding an ambisonics audio soundfield representation for
   playback over a plurality of loudspeakers, the method comprising:
             receiving a first matrix that includes gain vectors that are based on a panning
 5 based on positions of the loudspeakers and a plurality of source directions, wherein the
   source directions are distributed evenly over a unit sphere, a number of the source
   directions is S, the order of the ambisonics audio soundfield representation is N, and S >
   (N+1  )2;
             receiving a mode matrix determined based on the source directions and an order
10 of the ambisonics audio soundfield representation; receiving a base matrix determined
   based on the mode matrix and the first matrix; and
             decoding the ambisonics audio soundfield representation with a decoding matrix,
   wherein the decoding matrix is based on the first matrix and the base matrix.
             2.      The method of claim 1, wherein the obtaining of the panning is based on a
15 Vector Base Amplitude Panning (VBAP).
             3.      The method of claim 1, wherein the ambisonics soundfield representation
   is of at least a 2nd order.
             4.      A device for decoding an ambisonics audio soundfield representation for
   playback over a plurality of loudspeakers, the device comprising:
20           a means for receiving a first matrix that includes gain vectors that are based on a
   panning based on positions of the loudspeakers and a plurality of source directions,
   wherein the source directions are distributed evenly over a unit sphere, a number of the
   source directions is S, the order of the ambisonics audio soundfield representation is N,
   and S > (N+1) 2;
25           a means for receiving a mode matrix determined based on the source directions
   and an order of the ambisonics audio soundfield representation;
             a means for receiving a base matrix determined based on the mode matrix; and
             a means for decoding the ambisonics audio soundfield representation with a
   decoding matrix, wherein the decoding matrix is based on the first matrix and the base
30 matrix.
             5.      The device of claim 4, wherein the panning is obtained based on a Vector
   Base Amplitude Panning (VBAP).

                                                  18
           6.      The device of claim 4, wherein the ambisonics soundfield representation is
   of at least a 2nd order.
           7.      A non-transitory computer readable medium having stored on it executable
   instructions to cause a computer to perform a method for decoding an ambisonics audio
 5 soundfield representation for audio playback, the method comprising steps of:
           receiving a first matrix that includes gain vectors that are a panning based on
   positions of the loudspeakers and a plurality of source directions, wherein the source
   directions are distributed evenly over a unit sphere, a number of the source directions is
   S, the order of the ambisonics audio soundfield representation is N, and S > (N+1    )2;
10         receiving a mode matrix determined based on the source directions and an order
   of the ambisonics audio soundfield representation;
           receiving a base matrix determined based on the mode matrix and the first matrix;
   and
           decoding the ambisonics audio soundfield representation with a decoding matrix
15 wherein the decoding matrix is based on the first matrix and the base matrix, wherein the
   decoding matrix is based on the first matrix and the base matrix.

 16 Nov
 21     2018
    Feb 2014
 <removed-apn>
 2014265108
This data, for application number 2014265108, is current as of 2016-06-21 21:00 AEST

 16 Nov
 21     2018
    Feb 2014
 <removed-apn>
 2014265108
This data, for application number 2014265108, is current as of 2016-06-21 21:00 AEST

 16 Nov
 21     2018
    Feb 2014
 <removed-apn>
 2014265108
This data, for application number 2014265108, is current as of 2016-06-21 21:00 AEST

 16 Nov
 21     2018
    Feb 2014
 <removed-apn>
 2014265108
This data, for application number 2014265108, is current as of 2016-06-21 21:00 AEST

