 ABSTRACT
 A method and a system for improving a user's experience with a graphical user
interface corresponding to a gaming or simulation environment, executes a
software product corresponding to the game or simulation, on the computing
hardware of an electronic device. The interface renders multiple graphical objects
and user selectable options corresponding to the graphical object. The user
selects one or more selectable option, and eventually, performs a touching or a
swiping operation through multiple points on the display screen of the graphical
object. The touching or swiping operation leads to deploying of multiple resources
corresponding to the selected option, at different locations on the interface. For
controlling the different deployed resources, the user can swipe through different
regions of the display screen, based on his/her desire. The number of resources
deployed at the different locations on the screen depends on certain parameters,
including the pressure applied by the user on the screen, during performing the
touching or swiping operations. Results of the simulation can be employed to
control real technical systems, for example for food production.

SYSTEM AND METHOD FOR CONTROLLING TECHNICAL PROCESSES
The present application is a divisional application of Australian Application No.
<removed-apn>, which in turn is a divisional application of Australian Application No.
2013246615, which is the Australian national phase application of
PCT/11B2013/001126 and is incorporated in its entirety herein by reference.
This application claims the benefit of GB1222096.8 filed 7 December 2012,
US13/479,637 filed 24 May 2012 and US13/445,783 filed 12 April 2012, which are
hereby incorporated by reference in its entirety
Field of the invention
The present invention relates to systems for controlling technical processes, for
example to systems for controlling technical processes relating to at least one of
technical process simulation and technical process control. Moreover, the present
invention concerns methods of controlling technical processes, for example to
methods of controlling technical processes relating to at least one of technical
process simulation and technical process control. Furthermore, the present
invention relates to software products recorded on machine-readable data storage
media, wherein the software products are executable upon computing hardware for
implementing aforesaid methods.
Background of the invention
Graphical user interfaces (GUI) for controlling complex processes are known, for
example in control rooms associated with nuclear power plant, in military defence
systems and in aviation management. Such graphical user interfaces can be
employed both to control real technical facilities as well as simulations of such
facilities. The simulations provide an opportunity to investigate a potential behaviour
of the facilities, prior to applying actual control signals and commands to the
facilities, thereby providing better control of the facilities an anticipating behaviour
of the facilities.
Computing devices include tablet computers such as iPads, and smart phones,
including Apple's iPhone@, Google's Android@ phone, and Symbian @ phones.
These computing devices have extremely user-friendly graphical interfaces, for
                                            1

enabling easy and quick interaction to users thereof. Most of these devices
incorporate touch-sensitive screens that obtain user's inputs and facilitate smooth
user interaction. Simulation software, for example conveniently implemented in a
form of gaming software, is employed in many of these devices for leisure purpose
as well as technical control purposes as aforementioned. An important aspect of a
gaming or simulation system is the ease with which a given user can enter desired
inputs and interact with the user interface of the device on which he/she plays a
game and/or executes a simulation. For devices that lack a touch-screen facility
incorporated therein, the only possible ways of interaction of the given user while
playing a game or executing a simulation on such devices, is by clicking an
associated mouse, using associated keyboard functions/keys to operate, or using
associated joysticks. Experiences with the 'point and click' or 'joystick' incorporated
in many lower-grade electronic devices is incompatible and often time consuming,
while playing a game or executing a technical simulation. Specifically, there are
specific games or technical simulations where a given user/player needs to use
clicking, pointing, tapping and dragging operations many times, and often at
different device display locations, which is hard to operate through a contemporary
mouse or a contemporary joystick. In a typical gaming environment, where a given
user needs to perform similar operations by clicking or touching on multiple points
on the interface, this becomes cumbersome. Even the touch-sensitive screens,
provided in many conventional electronic devices, are capable of sensing the
touching operation only at one point at a time. Multi-touch screens are still not
popular, and they can be of great benefit in a gaming environment or a simulation
environment. Some of the conventional gaming console applications can be
controlled through multi-touch sensitive operations, however, in strategic gaming
environments, for performing certain desired operations, they still have some
drawbacks.
Therefore, considering the aforementioned problems, there exists a need for a
better and highly congenial graphical user interface (GUI) for a gaming or technical
simulation-and-control system, while playing a game or executing a simulation on a
computing device.
                                           9

Summary of the invention
The present invention seeks to provide an improved user graphical interface which
is more convenient to employ when undertaking gaming activities and/or executing
simulations of real technical systems before proceeding to control operation of such
technical systems.
The present invention also seeks to provide an improved method of employing a
user graphical interface which is more convenient when undertaking gaming
activities and/or executing simulations of real technical systems before proceeding
to control operation of such systems.
According to a first aspect of the present invention, there is provided an electronic
device as claimed in claim 1: there is provided an electronic device comprising: a
touch-sensitive display screen, configured to simultaneously sense touching
operations performed at multiple points of the screen;
a computing hardware operable to execute a software product, wherein executing
the software product results in generating and rendering a graphical user interface
on the display screen, the graphical user interface being configured to facilitate
user interaction; the graphical user interface, when rendered, presenting: one or
more graphical objects; and
one or more user selectable options, each option representing one or more
resources for performing an operation on one or more of the one or more graphical
objects; wherein
               based on a user's selection of one or more of the user selectable
options, the software product is configured to render the one or more resources
corresponding to the selected user selectable option, at multiple locations of the

interface.
The invention is of advantage in that the graphical user interface is more convenient
to employ, for example when submitting complex instructions requiring concurrent
deployment activities.
Optionally, in the electronic device, the software product is configured to execute
actions through the one or more resources, on one or more graphical objects, based
on receiving a user's execution input, after rendering the one or more resources at
multiple locations.
Optionally, in the electronic device, the software product is configured to render the
one or more resources at multiple locations, based on a user's touching operation
at multiple points of the display screen, or a user's swiping operation through the
multiple points, the multiple points corresponding to the multiple locations on the
display screen. More optionally, in the electronic device, the software is configured
to render the one or more resources at multiple locations when the user's touching
operation at the multiple points is performed for a pre-determined time. Yet more
optionally, in the electronic device, the pre-determined time is user-adjustable. More
optionally, in the electronic device, the rapidity of rendering the one or more
resources at multiple locations is based at least on the speed of the user's touching
operation or the swiping operation on the display screen.
More optionally, in the electronic device, the number of resources rendered at
multiple locations depends at least on the pressure applied by the user over the
display screen, during performing the touching or swiping operation. Pressure
applied by a given user to a touch-screen is beneficially determined by one or more
pressure-sensitive transducers integrated into the touch-screen. However, certain
contemporary touch-screens operate only on a binary basis, namely either there is
contact or no contact with a given area of the touch-screen. In such touch-screens,
pressure applied by the given user can be determined by an area of neighbouring
spatially   contiguous     sensing   points   on   the  screen    which   substantially
simultaneously experience a contact being made by the given user. Thus,
progressively more spatially contiguous sensing points are substantially
simultaneously in contact state as progressively more pressure is applied due to
                                            4

elastic deformation of biological tissue of the given user's finger tips. A similar
pressure sensing functionality can be achieved when the given user employs a
pointing device having an elastically deformable end to contact onto the touch
screen to control a game or a simulation, or to enter commands for controlling a real
technical facility. Optionally, the game or simulation includes a calibration routine for
a given user to perform to calibrate pressure sensitivity of the touch-screen.
Optionally, in the electronic device, the software product and the graphical user
interface corresponds to a gaming environment. More optionally, in the electronic
device, the gaming system corresponds to a war-based game, the graphical user
interface corresponding to a battlefield, and the one or more resources
corresponding to weapons of use within the battlefield. For example, the gaming
environment can be a simulation, prior to implementing a military operation in
practice using real technical hardware.
Optionally, in the electronic device, there is including a database for continuously
recording and updating the change in status of the one or more graphical objects,
the software product being coupled to the database and being configured to resume
the status of the one or more graphical objects to their last updated status in the
database, in case of interruptions in the operable state of the graphical user
interface.
Optionally, a plurality of electronic devices are connected to a server through a
network, the graphical user interface being generated temporally concurrently on
each of the electronic devices, to facilitate a plurality of users' interaction with the
graphical user interface, wherein the graphical user interfaces generated on the
plurality of electronic devices are coordinated and synchronized through the server,
and updated concurrently on the plurality of electronic devices with time.
Optionally, the electronic device is implemented as a desktop computer, a laptop
computer, an iPad, or a smart phone, including an iPhone@, an Android@ phone or
a Symbian@ phone; "@"denotes registered trademarks.
According to a second aspect of the invention, there is provided a method of
facilitating user interactions with a graphical user interface, the graphical interface
                                            5;

being generated and rendered on the display of an electronic device, by executing
a software product on a computing hardware of the electronic device, the method
comprising:
(a)     rendering one or more graphical objects, and one or more user-selectable
        options corresponding to the one or more graphical objects on the graphical
        user interface, each user-selectable options corresponding to one or more
        resources to be deployed on the interface;
(b)     selecting one or more of the user-selectable options, and performing one of
        a touching operation at different points on the display, and a swiping
        operation through the different points of the display; and
(c)     deploying the one or more resource corresponding to the selected user
        selectable option at multiple locations on the interface simultaneously, the
        multiple locations corresponding to the different points where the touching
        operation, or through which the swiping operation, is being performed.
        Optionally, the method further comprises:
(d)     deploying the one or more resources at multiple locations based at least on
        detecting that the touching operation at the multiple points on the display
        screen is performed fora pre-determined time.
Optionally, in the method, the rapidity of deployment of the one or more resources
at multiple locations depends on the speed of the swiping operation or the touching
operation.
Optionally, in the method, the number of resources deployed at the different
locations on the interface depends on the pressure applied on the display screen
during performing the touching operation or the swiping operation.
Optionally, in the method, the software product and the graphical user interface
corresponds to a gaming system. More optionally, in the method, the gaming system
corresponds to a war-based game, the graphical user interface corresponds to a
battlefield, and the one or more resources correspond to weapons of use within the
battlefield.

Optionally, the method further comprises continuously recording and updating the
change in status of the one or more graphical objects, coupling the software product
to the database, and resuming the status of one or more graphical objects to their
last updated status in the database, in case of interruptions in the operations of the
graphical user interface.
Optionally, the method further comprises:
(e)    connecting a plurality of the electronic devices to a server through a network;
(f)    generating the graphical user interface temporally concurrently on the
       displays of the different electronic devices; and
(g)    coordinating the plurality of graphical user interfaces through the server, and
       updating them concurrently with time, to facilitate multiple users' interaction
       and coordination with the graphical user interfaces.
More optionally, in the method, the graphical user intefaces correspond to a gaming
system, and the method is configured to facilitate an online multiplayer gaming
system.
According to a third aspect of the present invention, there is provided a software
product recorded on a machine readable data storage medium, wherein the
software product is executable on the computing hardware of a computing device
for implementing a method according to the second aspect of the invention.
According to a fourth aspect of the present invention, there is provided an
electronic device comprising: a display screen;
a computing hardware capable of executing a software product, wherein executing
the software product leads to generating and rendering a graphical user interface
on the display screen, the graphical user interface being configured to facilitate
easy user interaction; the graphical user interface, when rendered, presenting: one
or more graphical objects;
a pointer object configured to be movable over one or more graphical objects, and
configured to invoke a menu list containing one or more user selectable options as
                                            7

the pointer object is clicked or tapped over one or more of the graphical objects,
wherein:
               on selecting a user selectable option from the menu list, and
performing one of a dragging of the pointer object and swiping a touch sensitive
object over the graphical user interface, through one or more graphical objects, or
through a portion of a specific graphical object, the software product is configured
keep an effect corresponding to the selected option to be continuously applied to
the one or more graphical objects, or to the portion of the specific graphical object,
respectively, thereby enabling a change in status of the one or more graphical
objects, or the portion of the specific graphical object, respectively.
Optionally, the electronic device further comprises a user input interface rendered
over the graphical user interface, the user input interface being configured to obtain
and interpret a user's input corresponding to moving the pointer object, clicking or
tapping the pointer object, or swiping the touch sensitive object over the graphical
user interface.
Optionally, in the electronic device, the graphical user interface is configured to
apply continuously the user selectable option to the portion of the specific graphical
object, or to one or one graphical objects, in response to a user's swiping the touch
sensitive object over the portion of the specific graphical object, or to the one or one
graphical objects, respectively.
Optionally, in the electronic device, the graphical user interface is configured to
facilitate termination of the effect corresponding to the selected option, and facilitate
disappearing of the selected option, on termination of the dragging of the pointer
object or the swiping of the touch sensitive object.
Optionally, in the electronic device, the rapidity of application of the effect
corresponding to the selected option, over the portion of the graphical object, or over
the one or graphical objects, is dependent at least partially on the speed of
performing the dragging operation of the pointer, or the swiping operation of the
display sensitive object. More optionally, in the electronic device, the graphical user
interface is a touch-sensitive screen, and the user interface is implemented as a
tactile surface of the touch-sensitive screen.
                                            A

Optionally, in the electronic device, the graphical user interface is configured to
disable the application of the effect corresponding to the selected option, to the
portion of the specific graphical object, or to the one or more graphical objects, in
response to termination of the dragging of the pointer object, or the swiping of the
display sensitive object.
Optionally, in the electronic device, the graphical user interface and the software
product correspond to a gaming system or a simulation system. More optionally, in
the electronic device, the gaming system or simulation system corresponds to a
farming game, the graphical objects of the graphical user interface correspond to
different spatial regions of a farming environment in which one or more crops are
desired to be grown, and wherein the user selectable options in the menu list
correspond to different farming tools.
Optionally in the electronic device, there is included a database for continuously
recording and updating the change in status of the one or more graphical objects,
the software product being coupled to the database and being configured to resume
the status of the one or more graphical objects to their last updated status in the
database, in case of interruptions in the operable state of the graphical user
interface.
Optionally, a plurality of electronic devices are connected to a server through a
network, the graphical user interface being generated temporally concurrently on
each of the electronic devices, to facilitate a plurality of users' interaction with the
graphical user interface, wherein the graphical user interfaces generated on the
plurality of electronic devices are coordinated through the server and updated
concurrently on the plurality of electronic devices with time.
Optionally, the electronic device is implemented using a desktop computer, a laptop
computer, an iPad, or a smart phone, including an iPhone@, an Android@ phone or
a Symbian@ phone; "@"denotes registered trademarks.
According to a fifth aspect of the present invention, there is provided a method of
facilitating easy user interactions with a graphical user interface, the graphical
interface being generated and rendered on the display of an electronic device, by
executing a software product on a computing hardware of the electronic device, the
                                            q

method comprising:
  (a)   rendering one or graphical objects within the graphical user interface;
  (b)   clicking or tapping one or more graphical objects through a pointer object, to
  invoke a menu list containing a set of user-selectable options, the user-selectable
  options corresponding to an effect to be applied to a portion of a specific graphical
  object, or to one or more graphical objects; and
  (c)   selecting a specific user-selectable option, and applying the effect
  corresponding to the selected option, to a portion of a specific graphical object, or
  to one or more graphical object, by performing one of a dragging operation of the
  pointer object and a swiping operation of a display sensitive item, over the specific
  portion of the graphical object, or over the one or more graphical objects,
  respectively.
Optionally, in the method, the graphical user interface is configured to keep the
effect corresponding to the selected user-selectable option active, until the time the
dragging operation or the swiping operation is performed, and is configured to
enable disappearing of the selected option when the dragging or the swiping
operation is terminated.
Optionally, in the method, the software product corresponds to a gaming system or
a simulation system. More optionally, in the method, the gaming or simulation
system corresponds to a farming game or farming simulation, the graphical objects
correspond the spatial regions of a farming environment, and the user selectable
options correspond to different farming tools.
Optionally, the method further comprises continuously recording and updating the
change in status of the one or more graphical objects, coupling the software product
to the database, and resuming the status of one or more graphical objects to their
last updated status in the database, in case of interruptions in the operations of the
graphical user interface.
Optionally, the method further comprises:
(d)     connecting a plurality of the electronic devices to a server through a network;
                                            in

(e)     generating the graphical user interface temporally concurrently on the
displays of the different electronic devices; and
(f)     coordinating the plurality of graphical user interfaces through the server,
and updating them concurrently with time, to facilitate multiple users' interaction
and coordination with the graphical user interfaces.
Optionally, in the method, the graphical user intefaces correspond to a gaming
system, and the method being configured to facilitate online multiplayer gaming
system.
According to a sixth aspect of the present invention, there is provided a software
product recorded on a machine readable data storage medium, the software product
being executable on the computing hardware of a computing device, for
implementing a method pursuant to the fifth aspect of the invention.
It will be appreciated that features of the invention are susceptible to being
combined in various combinations without departing from the scope of the invention
as defined by the appended claims.
Description of the diagrams
Embodiments of the present invention will now be described, by way of example
only, with reference to the following diagrams wherein:
FIG. 1 is an overview schematic illustration of a system pursuant to the present
invention, providing a graphical user interface (GUI) for interfacing one or more
users to a facility, wherein the facility includes elements of gaming, simulation and/or
real technical system control;
FIG. 2 is an illustration of an embodiment of the graphical user interface of FIG. 1;
FIG. 3 is an illustration of an example environment which is controllable using the
graphical user interface of FIG. 2;
FIG. 4 and FIG. 5 are illustrations of user interactions with the environment of FIG.
3;
                                              11

FIG. 6 is an illustration of a network of servers and devices required for
implementing the system of FIG. 1;
FIG. 7 is a flow diagram of steps implemented within the system of FIG. 1;
FIG. 8, FIG. 9 and FIG. 10 are illustrations of an environment which the system of
FIG. 1 is operable to simulate or provide a playing environment;
FIG. 11 is an illustration of a graphical user interface (GUI) implemented pursuant
to the present invention;
FIG. 12 to FIG. 15 are illustrations of farming environments which are generated
by the system of FIG. 1; and FIG. 16 is an alternative network of data servers and
devices for implementing the system as illustrated in FIG. 1.
In the accompanying diagrams, an underlined number is employed to represent an
item over which the underlined number is positioned or an item to which the
underlined number is adjacent. A non-underlined number relates to an item
identified by a line linking the non-underlined number to the item. When a number
is non- underlined and accompanied by an associated arrow, the non-underlined
number is used to identify a general item at which the arrow is pointing.
Description of embodiments of the invention
In overview, the present invention is concerned with an apparatus for controlling
technical processes, wherein the technical processes include elements of
simulation and control of facilities. In FIG. 1, there is shown an apparatus 10 for
providing a graphical user interface (GUI) between a given user 20, for example one
or more persons, and a technical facility 30, wherein the apparatus 10 is
conveniently implemented using a device including computing hardware which is
operable to execute one or more software products recorded on machine-readable
data storage media. Moreover, the apparatus 10 is conveniently implemented using
contemporary computing platforms, for example computing platforms which are
wireless-enabled for supporting communication           via wireless communication
networks. The technical facility 30 optionally includes elements of simulation,
gaming and real system control.
                                           19

An embodiment of the present invention pertains to a graphical user interface for a
gaming and/or simulation system, for facilitating easy and quick interaction of a
given user while playing a game or controlling a simulation, and for avoiding
contemporary problems        experienced while performing touching or swiping
operations on the touch- sensitive screens of electronic devices on which the games
are being played and/or simulations are being executed.
Gaming systems are incorporated for leisure in many electronic computing devices,
including computers, iPads, mobile phones, tablet computers and smart phones.
Many such conventional electronic devices incorporate touch-sensitive screens for
obtaining user inputs and for making congenial user experience with the interface.
For playing games on electronic devices, or controlling technical simulations,
without a touch-sensitive screen, including many desktop and laptop computers, the
user generally interacts with and provides inputs to a gaming or simulation system's
interface through coupled input devices, such as mice, certain keys on the keypads,
and joysticks. Using multiple clicking operations through a mouse is time consuming
and unfavourable, for example, in cases where a same operation needs to be
performed at multiple points on the gaming or simulation interface. Even with the
devices have touch-sensitive displays, when similar operations corresponding to the
game being played, or the simulation being executed, need to be performed
simultaneously through multiple regions of the interface, this becomes difficult to
achieve as the conventional touch-sensitive screens are capable of sensing
touching operations one at a time, at a specific point. Even though multi-touch
sensitive screens are currently available, and are incorporated in electronic devices,
operations corresponding to certain games, when played, similarly corresponding
to certain technical simulations, require simultaneous sensing and detecting of
touching or swiping operations performed through multiple regions of the screen.
Thus, the present disclosure provides an enhanced graphical user interface for a
gaming and/or simulation system, which improves a given user's experience while
playing a game, or executing a technical simulation, on an electronic device. The
system and method facilitate performing of touching and swiping operations through
a multi-touch sensitive screen of the electronic device, and allows the given user to
perform similar operations pertaining to the game or simulation, simultaneously,
                                          13

through different regions of the interface.
In FIG. 2, there is shown a graphical user interface corresponding to a game being
played, or a simulation being executed, on an electronic device, illustrating a manner
in which a user playing a strategic game or executing a simulation performs touching
or swiping operations through multiple points of the interface, simultaneously, for
executing similar operations through multiple locations on the interface. As shown,
a graphical user interface 100, corresponding to the game being played or a
simulation being executed, is rendered on a display screen on the electronic device.
Specifically, the interface 100 is rendered and presented on the display screen,
when a software product corresponding to the game or simulation, is executed on
computing hardware of the electronic device. The display screen is a multi-touch
sensitive screen, capable of sensing touching or swiping operations performed at
multiple points on the screen simultaneously. A user 108 uses two of his/her fingers
and performs touching operations at two different locations 102 and 104, on the
interface 100. The interface 100 senses this operation, and the software product
corresponding to the game or simulation, executes actions pertaining to the
performed touching operation on different graphical objects of the interface 100.
This is explained in more detail hereinafter with respect to an example of a specific
gaming environment or simulation environment, in conjunction with the drawings
that follow.
In FIG. 3, there is shows a snapshot of the display screen of an electronic device,
when a user plays a game, or executes a simulation, on the device, and uses the
method of the present disclosure for controlling the gaming- or simulation-interface.
As shown, an electronic device 200 includes a display screen 202, wherein different
resources, for performing actions corresponding to the game or simulation, are
rendered on a graphical element 206 of the display screen 202. For the purpose of
explaining the disclosure, the depicted gaming-          or simulation-environment
corresponds to a war-based game or simulation, and the gaming environment
rendered on the display screen 200 corresponds to a battlefield 204. The device
200 can be any suitable electronic device that incorporates a multi-touch sensitive
screen, including an iPad, a smartphone, for example, Apple's iPhone@, an Android
phone@, or a Symbian phone@, a tablet computer, a desktop computer or a laptop
                                          14

computer, and so forth. The battlefield 204 has different graphical objects, for
example, a target 208, which can represent a castle, or a camp. An objective of the
game or simulation may be to win the castle, by attacking it through different
resources A, B and C, and so forth, shown within the graphical element 206. The
resources A, B and C within the element 206 can represent weapons, including
guns, cannons, arrows, bows, and so forth (namely technical hardware), or
represent different troops, armed soldiers, walking soldiers or horse riding soldiers,
and so forth. Though only three such resources have been shown, there can be
multiple other resources for playing the game or executing the simulation. In the
strategic game or simulation, the user selects one or more of these resources, and
deploys the selected resources at multiple locations within the battlefield 204. The
selected resources are then used to perform operations for conquering the target
208. For example, the deployed resources can be operated to attack the target 208
through the different weapons they possess. The user can use multiple touching
operations simultaneously, at different points on the display 202, to deploy the
resources A, B, C, and so forth at multiple locations within the battlefield 204.
Moreover, the user can also perform the swiping operation, to deploy a specific
resource all through a set of points along a specific path, by swiping fingers across
that path. The movement of the different deployed resource, either away from, or
towards the target 208, can be controlled by pointing towards a specific deployed
resource, and swiping the finger in the desired direction. When the user touches the
display screen 202 to deploy a selected resource, the screen 202 detects the
pressure applied by the user at different points. The number of resources deployed
at different locations optionally depends on the amount of pressure applied.
Specifically, a higher pressure applied at a specific point results in deploying
increased numbers of resources at that point, and vice versa. Moreover, the rapidity
of deploying the resources at different locations on the battlefield 204 depends upon
the speed with which the user performs the touching or the swiping operation
through different points. For example, if the user wishes to deploy a selected
resource along different points in a specific path, and performs a swiping operation
through the path, the resources are deployed as quickly as the swiping operation
through the path is performed. A rapid swiping operation results in a quicker
deployment of resources, compared to a slow swiping operation.
                                           15

Moreover, in FIG. 3, there is shown the display screen of the device, when the user
has selected one of the selectable options A, B and C, for deploying resources within
the battlefield of the war-based game or simulation. Shown as an example, the user
has selected the option B corresponding to a specific category or type of resources
to be deployed in the battlefield, to operate on the target 208 thereafter. As
aforementioned, the selected resources may be troops, armed soldiers possessing
specific kinds of weapons, horse riding soldiers, and so forth. Further, though only
one option has been shown being selected, the user can also select multiple options
to deploy different kinds of resources in the battlefield. Eventually, after selecting
the option B, the user uses two of his/her fingers to control the interface and deploy
the troops at two desired points 302 and 304, as shown. Specifically, the user
performs a touching operation at the points 302 and 304, either simultaneously, or
in temporal sequence, namely one-by-one. Alternatively, a swiping operation may
also be performed by initiating from either of the selected points 302 and 304,
through a specific desired path, to deploy the resources all through the desired path.
In an embodiment, the resources are deployed at the selected points, at a specific
predetermined time after the touching operation is performed. For example, in one
embodiment, the resources may be deployed at a specific point only if the user
keeps his finger in touch with the point for a pre-determined time, which may be
about 0.5 to 1 seconds. This feature is adjustable, and the minimum time for which
the user needs to keep his fingers in contact with the screen, for deploying the
resources, can be customized based on the user's desire, before playing the game
or executing the simulation. Further, this avoids the cases where the resources may
be deployed unintentionally or undesirably.
A specific deployed resource is released for action, for example, to attack the target
208, based on detection of certain conditions. This may include, for example, the
user still keeping his/her finger at a desired point, for about 1 to 2 seconds after the
resource has been already deployed at that point. In another case, an execution
option may be separately rendered on the display screen, and the user needs to
provide an execution command through the option, after the resources are
deployed. Moreover, the multi-touch operations performed through the different
fingers act independently, and the display screen is configured to sense and
interpret the swiping or touching operations performed through these fingers
                                            1

independently. Specifically, as an example, when one finger is touched or swiped
through specific points on the screen, one set of resources may be deployed over
one set of locations corresponding to those points, and subsequently, when another
finger is touched or swiped through a different set of points, a second set of
resources may be subsequently deployed over those points too. The two sets of
resources may be same or different, depending on the game settings, which are
user adjustable, and can be customized before playing the game or executing the
simulation Furthermore, as aforementioned, the display screen is also capable of
sensing touching or swiping operations performed at different points simultaneously,
and deploy the resources at different points together. In an embodiment, the number
of resources deployed at different points, may be one each corresponding to
detecting of a touching operation performed at that point. Alternatively, a constant
number of resources per unit time may be deployed at a specific point, or over a set
of points, as long as a touching or a swiping operation is performed over those
points. In another embodiment, as aforementioned, the number of resources
deployed is a function of the pressure applied by the user while performing the
touching or swiping operation. Specifically, a higher pressure applied at a specific
point optionally results in deploying more number of resources at that point, and vice
versa.
Referring next to FIG. 4, there is illustrated the display screen of the electronic
device, where the resources corresponding to the selected option B, are shown
deployed at multiple locations on the display screen. As shown, a set of resources
410 are deployed at one set of locations on the screen 202, and these correspond
to multiple touching operations performed earlier around a point 302, shown in FIG.
4. To deploy the resources 410, the user optionally performs a swiping operation
through a path covering these points. Moreover, another set of resources 420 are
shown deployed on the other side of the target 208. These resources are rendered
when the touching operations initiating with a point 304, see FIG. 4, is performed by
the user, through another finger. Similarly, a touching or swiping operation is
optionally performed at many other points on the display screen 202, to deploy the
resources at other desirable points.
In FIG. 6, there is shown an illustration of an exemplary environment for
                                          17

implementing the method and apparatus in accordance with the present disclosure.
A plurality of electronic devices 502, 504, 506 and 508 are shown, through which a
user can connect to one of different data servers 510 and 540, for example game
servers and/or simulation servers, through one of a multiple networks represented
by 550, 560 and 570. The electronic devices 502, 504, 506 or 508, can be any
suitable electronic devices having a computing hardware capable of supporting and
executing a software product corresponding to a gaming and/or a simulation
system. Typical examples of the illustrated electronic devices may include a desktop
computer, a laptop computer, a tablet computer, a smart phone including the
popularly known iPhones@, Android phone@, an iPad, and so forth. Furthermore,
all these electronic devices have one or more multi-touch sensitive screens for
sensing and obtaining a user's input through touching or swiping operations
performed at multiple points of the one or more display screens. Moreover, the
different electronic devices 502, 504, 506 and 508, are mutually connected to each
other through either of the servers 510 and 540, through suitable communication
networks. The networks 550, 560 and 570, and so forth, may be Wireless networks,
such as a Wireless Local area network (WLAN), Local area networks (LAN), cellular
networks, for example, 2G network, 3G network, and so forth. Moreover, any of the
electronic devices 504, 506 and 508 may also use its own Bluetooth network and
may be capable of connecting to a Bluetooth server, to synchronize with the other
electronic devices; "Bluetooth" is a registered trademark. The shown exemplary
environment supports multiplayer gaming too, by facilitating multiple users to be
online through different devices, connecting through a suitable network, and
synchronizing with each other. Moreover, multiple databases, as shown by modules
520, 530, and so forth, are coupled to different servers, and information related to
the gaming environment is continuously stored in these databases, when the
different users are online for multiplayer gaming.
For facilitating single-player gaming or single-user simulation, a user logs on
through any of the electronic devices 502, 504, 506 or 508, and connects to one of
the gaming or simulation servers 510 or 540, through a suitable network, for
example via the Internet and/or a wireless communication network. As the user logs
on, and executes the gaming or simulation software on the computing hardware of
the specific device that he/she utilizes, for example, the device 502, a graphical user
                                            1I

interface corresponding to the game is generated, and is rendered on the display
screen of the device 502. The graphical user interface presents different graphical
objects pertaining to the game or simulation, on the display screen of the device
502. The graphical objects may be represented by different blocks/segments of the
graphical user interface, on which different operations corresponding to the game
being played or simulation being executed, can be performed. For example, in a
case where the game is a war-based game or the simulation relates to technical
military hardware such as guns, bombs and such like, such blocks/segments may
represent one or more targets that need to be conquered, such as the target 208
shown earlier in FIG. 3. Moreover, one or more graphical elements, representing a
set of user selectable options for performing actions on the graphical objects, are
also rendered on the interface of the device 502. Such elements have been
explained in detail earlier, in conjunction with the previous drawings of the
disclosure, which pertain to a war-based game or simulation. Moreover, a point
object (cursor) movable over the different graphical objects appears on the graphical
user interface, for controlling the gaming or simulation operations. The pointer object
is controllable by performing touching, swiping or tapping operations on the display
screen of the device 502. Moreover, other input devices, including a mouse, a
joystick or a set of keyboard buttons, may be coupled to the device 502 (though not
shown), for facilitating provision of user inputs. The touching operation on the
display screen can be performed through use of a suitable touch-sensitive object,
including fingers, a pen, a pencil, a pointing organ, and so forth.
Another database 580, coupled to the gaming or simulation server 510, serves as a
back-end database for the gaming or simulation server 510. As the user of the
device 502 starts playing the game, or executing a simulation, typical actions and
gestures performed by the user, are recorded in the back-end server 580.
Specifically, such actions are interpreted through the gaming or simulation server
510, and are sent as messages to the back-end server 580, which eventually
maintains a log of, and a backup for the played game or executed simulation. Such
messages can be in the form of data packages sent over an Internet connection
through which the device 502 is connected to the server 510, or sent over any other
wireless or wired network connecting the device 502 to the server 510, as
aforementioned. Typical elements of such messages for maintaining a backup for
                                           19

the game or simulation may include a header, a payload and a checksum. The
checksum can be a function of the payload, or it may be a unique user identifier,
such as a username or similar. An advantage arising from including the checksum
in the back-end maintaining messages, is a possibility of avoiding potential frauds
while playing the game, or avoiding third-party corruption of a simulation which could
adversely influence results generated by the simulation. Those in the art will
understand that an appropriate checksum function or a checksum algorithm may be
applied to the collected digital data, while the game is being played, or simulation
being executed, to obtain the checksum. Further, the checksum corresponding to a
specific data can be recomputed at any point of time, and compared to the stored
checksum, to avoid possible frauds. The back-end messages received by the server
510 are also sent to the other databases 520 and 530 of the server 510. In these
databases 520, 530, these back-end messages are used to maintain a continuous
logic that represents the status of the game or simulation, for example, the exact
score of the player updated with time, and a stage of the game that the player has
already reached, or results of the simulation such as yield, integrity of a structure
and similar. With a continuous receipt of the back-end messages by the databases
520 and 530, a regular updating of the game status is undertaken within these
server databases 520 and 530, eventually, with time. This ensures facilitating the
resumption of the game or simulation to its last status, in cases where the device
510 unexpectedly shuts down, the device 510 is unexpectedly hindered in its
communication or the user changes the gaming or simulation terminal, or he/she
intentionally quits playing or executing the simulation for a certain period, and logs
in at some other time, such a possibility of resumption assists to enhance user
satisfaction with the graphical user interface.
Though only two servers 510 and 540 have been shown, there can be multiple
gaming or simulation servers coordinating with, and connected to each other, for
implementing the gaming and/or simulation environment in accordance with the
present disclosure. Moreover, the environment as shown in Fig. 6 is capable of
implementing a thin client game or simulation, namely written in a computer program
that is partially independent in its computational roles, wherein a part of the gaming
or simulation-logic may be stored in any of the servers 510 and 540, and a part of it
may be stored in the gaming or simulation terminal. The depicted environment also
                                           2n

supports a thick client game or simulation, namely written in a solely independent
computer, wherein the entire gaming or simulation logic may be stored in the gaming
terminal. Furthermore, the game or simulation is optionally completely web-based
too, wherein most of the gaming or simulation logic may be stored in any of the
servers 510 or 540. The gaming or simulation software corresponding to the game
or simulation being played or executed respectively, can be optionally written in any
programming language.
Although, the gaming or simulation system implementable through the illustrated
gaming or simulation environment, has been described for the case when a single
user logs on to any of the electronic devices 502, 504, 506 or 508, the same gaming
or simulation environment is capable of supporting multi-participant gaming or
simulation, wherein different users may log on through different electronic devices,
and synchronize with each other by connecting concurrently through any of the
common gaming or simulation servers 510 and 540, through suitable networks as
aforementioned, and share a common graphical user interface representing the
ongoing game or simulation. In such embodiments, the graphical user interface
rendered on the display screens of the different electronic devices, is regularly
updated, concurrently, through the logic data stored in the databases 520 and 530
of the gaming or simulation servers, at the back-end.
In FIG. 7, there is shown a method of facilitating user interactions with a graphical
user interface (GUI), while playing a game or executing a simulation. The method is
elucidated in conjunction with a typical example of a war-based game or simulation,
described earlier through the previous figures of the disclosure. However, the
method can be generalized and implemented on other gaming or simulation
environments also, and is not intended to limiting the scope of the present
disclosure. At a step 604, the method includes a step of executing a software
product on computing hardware of an electronic device. The electronic device can
be any appropriate device incorporating a multi-touch sensitive screen, examples of
which have been set forth earlier. The software product corresponds to a gaming or
simulation system, for facilitating playing of a game or executing a technical
simulation on the electronic device. At a step 608, as the software product is
executed, the method includes generating and rendering on a graphical user
                                          21

interface a representation of the gaming or simulation environment on the display
screen of the electronic device. At a step 612, the method includes presenting via
the graphical user interface different graphical objects, a set of user selectable
options for controlling the gaming or simulation environment, and a pointer for
performing touching or swiping operations through different points on the interface.
For example, as aforementioned, in a war-based game or simulation, the graphical
objects may correspond to a castle to be conquered, a camp to be destroyed, and
so forth, and the gaming or simulation environment may represent a battlefield. The
user selectable options may correspond to different resources that can be deployed
over different portions of the interface, to perform operations on the graphical
objects, for example for scoring points or otherwise determining their technical
characteristics.
Specifically, the resources may be different kinds of troops, horse riding soldiers,
armed soldiers possessing versatility of weapons, including guns, bombs, cannons,
bows, arrows, and so forth. At a step 616, the method includes the user selecting
one or more selectable options corresponding to the different kinds of resources
that he/she wants to deploy within the gaming or simulation environment.
Proceeding further, after selecting and enabling one of the selectable options, at a
step 620, the method includes deploying the corresponding resources, the user
performs touching or swiping operations on multiple points of the interface,
depending on the locations where he/she wishes to deploy them. At step a 624, the
resources are deployed and appear on the gaming or simulation interface. In an
embodiment, the nature of deployment of the different resources may depend on
different parameters. For example, the number of resources deployed at a specific
point, depends on the pressure applied by the user on the display screen, while
performing the touching operation at that point. Moreover, if the user wishes to
deploy resources along multiple points constituting a specific path, and performs a
swiping operation along that path, the rapidity with which the resources are deployed
depends on the speed with which the user performs the swiping operation along the
path. In another embodiment, a constant number of resources per unit time can be
deployed at each point where a touching operation is being performed. The nature
of deployment of resources is user adjustable, and can be customized, based on
the user's priority, before playing the game.
                                          99

At a step 628, the method includes checking whether or not other resources are
desired to be deployed, before executing actions through the resources. If "yes", the
method includes returning to the step 616, selecting the selectable options
corresponding to the resource, and performing the touching or swiping operations
through the desired points again. Alternatively, going further, at a step 632, the
method includes releasing the deployed resources for action, within the gaming or
simulation environment. For example, in a war-based game or simulation, the
deployed troops/armed soldiers are released for operating on a specific target, to
attack it from different points where they are deployed. In an embodiment, the
releasing of the deployed resources is automated, and occurs when the user keeps
his/her fingers on a specific resource for a pre-determined time after deploying it.
For example, this time may be about 1 to 2 seconds of touching operation after the
resource is already deployed. The display screen is configured to sense this
predetermined time, and the software product executes action pertaining to the
deployed resource, when this occurs. In another embodiment, releasing the different
resources may require a manual user input. Specifically, for example, a triggering
option (like a "go" or "fire" option) may be rendered after deploying the resources,
and the resources may not be released until the user manually initiates the option.
At a step 636, after the actions have been performed by the deployed resources,
the graphical user interface is updated and a reformed interface representing the
latest status of the gaming- or simulation-environment, renders on the display
screen.
The method and system of the present disclosure, for improving interaction of a user
with a graphical user interface corresponding to a game and/or simulation, provides
substantial benefits as the user performs different operations in a gaming or
simulation environment. Similar operations, when desired to be performed by a
user, through different locations on the gaming or simulation interface, can be easily
executed by touching or swiping through multiple points of the display screen
simultaneously. Hence, the user's experience with the gaming or simulation
interface is much more comfortable.
Although the present disclosure has been described comprehensively, through an
exemplary embodiment where it is applicable in a gaming and/or simulation
                                           921

environment, and specifically through the example of a war-based game or
simulation, the disclosure also finds it applications in other gaming, control and
simulation environments, and, generally, may be applicable to other graphical user
interfaces, not pertaining to a gaming or simulation system also. In certain
applications, the user interface of the disclosed embodiment can be used for a
virtual control of any type of game, technical system or simulation. Certain aspects
of the disclosed embodiments are also applicable to perform other operations,
including building arcades and solving puzzle games. Further, the congenial user
interface may also be implemented within other types of games, for example,
adventurous, role playing and shooting games, construction and management
simulation games, and so forth. For example, the congenial user interface can be
used in computer terminals employed at financial exchanges, for example in Wall
Street in New York and the Stock Exchange in London, where traders need to
control multiple transactions simultaneously when executing a financial transaction,
for example a synthetic credit default swap or a trading in derivative financial
products.
Further embodiments of the present invention will now be described below. The
present disclosure pertains to a graphical user interface (GUI) for a gaming or
simulation system, as aforementioned, for facilitating easy and quick interaction of
a user while playing the game or executing the simulation, and for avoiding the
cumbersome operations normally experienced while using a mouse or a joystick
when a game or simulation is played or executed respectively on an electronic
device.
Gaming and simulation systems are incorporated for leisure in many electronic
devices, including computers, iPads, mobile phones, tablet computers and smart
phones. While playing a game, or executing a simulation, on the computing devices
without a touch-screen facility, including many conventionally available desktop and
laptop computers, the major mode of interaction of a user with the gaming or
simulation system interface is through devices like mouse, certain keys on the
keypad, and the joysticks coupled to the computing device. In many games or
technical simulations, the user often desires to obtain quick application of certain
operations, for which he/she needs to use the clicking or tapping operation multiple
                                           94

times, and at different spots of the interface, which often takes time. Most of the
smart phones and tablet computers have now incorporated touch screen displays,
and playing games on these devices is comparatively easier. However, while
interacting with the touch-sensitive screen acting as tactile surface for the graphical
user interface corresponding to a game, multiple clicking or tapping operations at a
single or different places may deteriorate the screen. Moreover, the screen often
gets degenerated in long run, producing scratches and dirt spots on it, as a device
is used too often for playing games, which is often undesirable. Furthermore, certain
operations require consistent clicking and tapping at different locations on the
graphical user interface, which takes time to enable the operations.
In FIG. 8, there is depicted the graphical user interface corresponding to a farming
game or farming simulation, illustrating how the different relevant operations are
conventionally performed, and the problems faced by a user/player, while
performing these operations. The simulation is beneficially employed in respect of
Africa as a technical assistance for farmers coping with agriculture in harsh
environmental conditions, for example exacerbated by anthropogenically-forced
climate change believed to be caused by anthropogenic Carbon Dioxide emissions
into the Earth's atmosphere, causing an increase of atmospheric Carbon Dioxide
concentration of circa 3 p.p.m./year, in respect of a contemporary Carbon Dioxide
concentration in atmosphere of around 400 p.p.m. Increased Carbon Dioxide
concentrations are believed to be causing acidification of World oceans, namely
adversely influencing major sources for aquatic foods, already stressed by
radioactive leaks from Fukushima, Japan, namely the worst industrial accident in
human history.
In FIG. 8, there is a farming field 1100, and multiple characters 1106 which control
the operations on the field 1100. The characters 1106 are controlled by the
user/player, and are moved and allowed to perform different operations within the
field 1100. A score card is shown in the top left corner of the graphical interface, and
different houses 1102 are shown, where the characters 1106 can hide. The game
or simulation is about growing different crops/fruits in different suitable parts of the
field 1100, for example as a function of future weather predictions pertaining to
Africa, for example as determined from analyzing data from meteorological

satellites. An example situation is now to be described: the character 1106 desires
to grow something in a specific region of the field 1100. Referring next to FIG. 9, the
user selects a graphical object 1200 corresponding to the location where he/she
wishes to grow a specific crop. The selection is made by tapping the object 1200
through the mouse, or by touching the interface, if the interface is touch-sensitive.
As the user touches the object 1200, a menu list appears, containing different
selectable options corresponding to different crops that can be grown in that area,
for example, raspberries 1206, blueberries 1204, strawberries 1208, and so forth,
as shown. Suppose the user has decided to grow blueberries 1204 in one portion,
and raspberries 1206 in another region of the field. For this the user selects the
relevant options and selects the corresponding regions where he/she wishes to
grow them. Continuing further, the updated field 1100 of FIG. 8 is shown now in Fig.
10, where blueberries have been shown grown in a region 1300, and the raspberries
have been shown grown along the region 1302. A major problem here arises when
the farming field is substantially large, and different crops are required to be grown
in different regions of the farming field. Moreover, a specific crop may be desired to
be grown in different regions of the field, lying proximal to each other, or in abutment.
For enabling this, the user needs to select each of those regions individually,
through multiple clicking/tapping operations through the mouse, or by pointing the
finger or a touch sensitive object like fingers, on different regions, in case where the
screen is a touch-sensitive screen. In both the cases, the operation consumes a lot
of time, and specifically, when the operation is performed on a touch-screen through
fingers, it may deteriorate the screen eventually.
The present disclosure provides an efficient and user friendly graphical user
interface (GUI) for a gaming- or simulation-system like that shown in FIG. 8 to FIG.
10, an interface that facilitates easy and quick operations by dragging a pointer
object or by performing a swiping action over different graphical objects of the
interface.
Specifically, the present disclosure is related to performing a swiping operation on
the graphical user interface of a gaming- and/or simulation-system, while controlling
or facilitating operations on the interface. In FIG. 11, there is illustrated the swiping
operation that can be performed on the graphical user interface of a gaming or

simulation system, for controlling operations during playing a game or executing a
simulation. As shown, for performing the swiping operation of the present
disclosure, a finger 1408 of the user is initially placed at a desired point 1402, and
moved along a desired path 1406, until a desired destination point 1404 in reached,
in the normal fashion as it is done to operate menus and handle other applications
in electronic devices incorporating touch-sensitive screens 1400.
Moreover, instead of using fingers, the swiping operation can also be performed
through a mouse, by pointing and tapping the mouse initially at the point 1402,
dragging the pointer on the screen along the desired path 1406, through the mouse,
and finally releasing the mouse at the final position 1404. Further, any other display
sensitive device or an organ, for example, a pen or a pointed device, can be used
on the screen for performing the swiping operation. Connecting this operation and
its advantages applicable on the typical farming environment depicted in FIG. 8 to
FIG. 10, suppose a user wishes to grow raspberries all along a wide region
represented by the path 1406 in FIG. 11, on different blocks on the farming field.
Then, the user just needs to select the raspberry option that pops up, by pointing on
any point along the path 1406, and swipe his/her fingers all along the path 1406.
This operation will lead to easy and quickergrowing of the raspberries along the
entire path 1406.
In FIG. 12 to FIG. 15, there is shown the view of the farming field shown earlier in
FIG. 8, and the figures illustrate the advantages of the swiping feature supported by
the graphical user interface of the present disclosure. As shown in Fig. 12, a view
of a farm field 1500 is illustrated, and the object of the game or simulation is to score
points or acquire credits by producing different products along different regions of
the field 1500. Growing different crops/products, or performing different operations
like harvesting or watering of different sections of the field 1500, carry different
points or credits to be scored by the user. The field 1500 has different
segments/blocks that can be modified by the user to score points or credits. These
segments/blocks are represented by the different graphical objects of a graphical
user interface which presents the gaming environment or the farm field 1500 on the
display screen of an electronic device on which the game is being played, or the
simulation is being executed. Referring next to FIG. 13, for growing a specific
                                             97

product/crop, the user has to click or tap through the mouse, or touch with his finger,
or through a display sensitive object (in case where the screen of the electronic
device is touch-sensitive), at a specific desired position, for example, the one
represented by the block 1602, as shown. As the user touches the block 1602, an
item specific menu (ISM) corresponding to the block 1602 appears on the graphical
user interface.     Different blocks may have different item           specific menus,
corresponding to the possible crops/products that can be grown over them.
As shown, the ISM menu corresponding to block 1602 shows different user
selectable options like A, B, C, D and E, which correspond to different crops that
can be grown in the field. Each selectable option corresponds to a specific tool for
growing a different kind of crop/product, for example, maize, corn, carrots, wheat
and rice. The embodiment shown in the figures and described herein, is a mere
example, and other embodiments incorporating obvious variations may also be
possible, thus, not limiting the scope of the present disclosure. For example, there
may be other different kind of tools present in the ISM menu, depending on the
block/segment of the field clicked, tapped or selected. Specifically, if the selected
block 1602 is already cultivated, then some of the selectable options appearing in
the ISM menu may correspond to pesticide spray, harvesting, pouring water, and
so forth. Referring next to FIG. 14, if the user decides to cultivate rice, for example,
then he/she selects a suitable corresponding option from the ISM menu, and swipes
his/her fingers all over the different blocks/segments of the field, wherever he/she
desires to grow the rice. Eventually, as shown, the cultivated rice appears all over
the region 1700 of the farm field, where the user has swiped his fingers, or dragged
the mouse. As a further example to illustrate the application of swiping motion to
other operations, if the user now wishes to harvest the grown rice in certain areas
of the region 1700, then he/she taps, clicks or touches the region 1700, and one of
the tools appears in another popping ISM menu, for sickle operation, as shown by
the tool 1702. Continuing further in conjunction with FIG. 15, the user points his/her
finger over the sickle tool, and swipes the finger over regions of the field where
he/she wants to harvest the grown rice. Eventually, as shown, the user gets
successful in harvesting and collecting rice from areas 1802, and has intentionally
left the other areas free from being harvested.
                                            2

Emphasizing on the advantages of the application of the swiping feature in the
graphical user interface of a gaming system, as compared to the solutions as
illustrated before through FIG. 8 to FIG. 10, all such operations like harvesting or
cultivating in a farm field, for example, are easily done through the extremely quick
and easily operable swiping action, which just takes a fraction of a second and
avoids multiple clicking or tapping at different points on the interface, as was done
in prior-art gaming or simulation systems. This eliminates any effects like
deterioration of the display screen if the screen is touch sensitive, or avoids any
complexities in performing different operations, irrespective of how big the farm field
may be.
In FIG. 16, there is shown an exemplary environment for implementing the method
and system in accordance with an aspect of the present disclosure. As shown,
different electronic devices 1902, 1904, 1906 and 1908 are depicted, through which
a user can connect to one of the different gaming or simulation servers 1910 and
1940, through one of the multiple networks represented by 1950, 1960 and 1970.
The electronic devices 1902, 1904, 1906 or 1908, can be any suitable electronic
devices having a computing hardware capable of supporting and executing a
software product corresponding to a gaming and/or simulation system. Typical
examples of the illustrated electronic devices may include a desktop computer, a
laptop computer, a tablet computer, a smart phone including the predominantly
known iPhones@, Android phone@ and so forth, an iPad, and so forth. Moreover,
any of the electronic devices can have the touch-sensitive screen for obtaining user
inputs through a touching operation, and some of them may also be coupled to, and
operable through conventional devices like a mouse, a joystick, a keyboard, and so
forth. Further, the different electronic devices 1902, 1904, 1906 and 1908, are
commonly connected to each other through the servers 1910 and 1940, through
suitable networks. The networks 1950, 1960 and 1970, and so forth, may be
Wireless networks, for example a Wireless Local area network (WLAN), Local area
networks, cellular networks, for example, 2G network, 3G network, and so forth.
Furthermore, any of the electronic devices may also use its own Bluetooth network
and Bluetooth server, to connect and synchronize with the other electronic devices;
"Bluetooth" is a registered trademark. The exemplary environment facilitates
multiple users to be online at the same time, and synchronize with each other, to
                                            9q

enable    multiplayer gaming.     Additionally, multiple    databases    1920,  1930,
corresponding to the different servers, as illustrated, allow the different servers to
store information relevant to the gaming or simulation environment, when the
different users are online for multiuser gaming and/or simulation.
For a user player gaming or executing simulations, the user logs on through any of
the electronic devices 1902, 1904, 1906 or 1908, and connects to one of the gaming
or simulation servers 1910 or 1940, through a suitable network. As the user logs on
and executes the gaming or simulation software on the computing hardware of a
specific device, for example, the device 1902, a graphical user interface
corresponding to the game or simulation is generated and rendered on the display
screen of the device 1902. The graphical user interface presents different graphical
objects on the display screen of the device 1902. The graphical objects may be the
different blocks/segments of the graphical user interface, on which different
operations corresponding to the game being played, or the simulation being
executed, can be performed. Moreover, a point object (cursor) movable over the
different graphical objects appears on the graphical user interface, for controlling
the gaming or simulation operations. If the device 1902 does not have a touch
sensitive screen, the pointer object may be controllable through a mouse, a joystick
or a set of keyboard buttons, coupled to the device 1902. Furthermore, if the device
1902 has a touch-screen functionality incorporated therein, the same controlling
operations can also be performed by swiping or tapping/clicking through fingers or
any display sensitive item, like any other organ/pen/pencil.
Another database 1980 serves as a back-end database for the gaming or simulation
server 1910. As the user of the device 1902 starts playing the game, or executing
the simulation, typical actions and gestures performed by the user, are recorded in
the back-end server 1980. Specifically, such actions are interpreted through the
gaming or simulation server 1910, and are sent as messages to the back-end sever
1980, which eventually maintains a backup for the played game or executed
simulation. Such messages can be in the form of data packages sent over an
Internet connection through which the device 1902 is connected to the server 1910,
or any other wireless or wired connection connecting the device 1902 to the server
1910. Typical elements of such messages for maintaining a back end for the game
                                           mn

or simulation, may include a header, a payload and a checksum. The checksum can
be a function of the payload, or it may be a unique user identifier, like the username,
and so forth. The advantage of including the checksum in back-end maintaining
message, is the possibility of avoiding prospective frauds while playing the game,
or corruption in a simulation which could adversely influence results generated by
the simulation. The back-end messages received by the server 1910 are also sent
to the other databases 1920 and 1930 of the server 1910. In these databases, these
backend messages are used to maintain a continuous logic representing the status
of the game or simulation, for example, the exact score of the player with time, and
the stage of the game that the player has already reached. With a continuous receipt
of the back-end messages by the databases 1920 and 1930, a regular updating of
the game or simulation status is implemented within the server databases 1910 and
1920, eventually, with time. This ensures facilitating the resumption of the last status
of the game or simulation, in a case of the device 1910 unexpectedly shutting down,
the user changes the gaming or simulation terminal or intentionally quits playing or
executing the simulation for a certain period, and logs in at some other time.
Although only two servers 1910 and 1940 have been shown, there can be multiple
gaming or simulation servers coordinating with, and, connected to each other, for
implementing the gaming or simulation environment in accordance with the present
disclosure. Moreover, the environment, as illustrated in Fig. 16, is capable of being
implemented as a thin client game or simulation, wherein a part of the gaming logic,
or the simulation logic, may be stored in any of the servers 1910 and 1940, and a
part of it may be stored in the gaming or simulation terminal. The depicted
environment also supports a thick client game or simulation, wherein the entire
gaming logic, or simulation logic, may be stored in the gaming or simulation terminal.
Furthermore, the game can be completely web-based too, wherein most of the
gaming logic or simulation logic may be stored in any of the servers 1910 or 1940.
The    present   invention   is  optionally   implemented     via a     cloud-computing
infrastructure.
Although, the gaming or simulation system implementable through the illustrated
gaming or simulation environment, has been explained in the case when a single
user logs on to any of the electronic devices 1902, 1904, 1906 or 1908, the same
                                           31

environment is capable of supporting multiuser gaming or simulation, wherein
different users may log on through different electronic devices, and synchronize with
each other by connecting to the common servers 1910 and 1940 through suitable
networks, and share a common graphical user interface representing the ongoing
game or simulation, for example a United Nations famine relief programme. In such
embodiments, the graphical user interface rendered on the display screens of the
different electronic devices, is regularly updated, concurrently, through the logic
data stored in the databases 1920 and 1930 of the gaming or simulation servers, at
the back-end.
In the foregoing, pressure applied by a given user to a touch-screen is beneficially
determined by one or more pressure-sensitive transducers integrated into the
touchscreen. However, certain contemporary touch-screens operate only on a
binary basis, namely either there is contact or no contact with a given area of the
touchscreen. In such touch-screens, pressure applied by the given user can be
determined by an area of neighbouring spatially contiguous sensing points on the
screen which substantially simultaneously experience a contact being made by the
given user. Thus, progressively more spatially contiguous sensing points are
substantially simultaneously in contact state as progressively more pressure is
applied due to elastic deformation of biological tissue of the given user's finger tips.
A similar pressure sensing functionality can be achieved when the given user
employs a pointing device having an elastically deformable end to contact onto the
touch-screen to control a game or a simulation, or to enter commands for controlling
a real technical facility.
Beneficially, when a game or simulation is implemented as described in the
foregoing and the given user exits from the game or simulation, for example for
resumption at a later time, parameters describing a state of the game or simulation
at an instant of exiting from the game are beneficially stored in data memory, so that
the state of the game or simulation can be restored again at resumption of the game
or simulation.
Modifications to embodiments of the invention described in the foregoing are
possible without departing from the scope of the invention as defined by the

accompanying       claims.   Expressions      such    as   "including",  "comprising",
"incorporating", "consisting of', "have", "is" used to describe and claim the present
invention are intended to be construed in a non-exclusive manner, namely allowing
for items, components or elements not explicitly described also to be present.
Reference to the singular is also to be construed to relate to the plural. Numerals
included within parentheses in the accompanying claims are intended to assist
understanding of the claims and should not be construed in any way to limit subject
matter claimed by these claims.

CLAIMS
1.      An electronic device comprising:
        a display screen; and
        a computing hardware configured to execute a software product, wherein
executing the software product generates and renders a graphical user interface on
the display screen, the graphical user interface being configured to facilitate user
interaction, the computing hardware, graphical user interface and the software
product being implemented on a gaming system, the computer hardware being
configured to:
        present one or more selectable graphical objects on the graphical user
interface; enable a selection of one or more of the selectable graphical objects;
        generate a menu list on the graphical user interface upon selection of one of
the selectable graphical objects, the menu list comprising one or more selectable
options;
        detect a selection of one of the selectable options from the menu list;
        detect a substantially continuous selection of areas along a path on the
graphical user interface, wherein the substantially continuous selection comprises
detecting a swipe motion over the graphical user interface; and
        execute an action corresponding to the selected option in each area along the
path on the graphical user interface, wherein the gaming system comprises a
farming game, the selectable graphical objects of the graphical user interface
comprise different spatial regions of a farming environment in which one or more
crops are grown, and wherein the selectable options in the menu list are different
farming tools.
2.      The electronic device of claim 1, wherein detecting the substantially
continuous selection comprises detecting a track of a cursor over the graphical user
interface.
                                            34

3.     The electronic device of claim 1, further comprising a user input interface
rendered over the graphical user interface, the user input interface being configured
to detect an input corresponding to moving a pointer object, clicking or tapping the
pointer object, or swiping a touch sensitive object over the graphical user interface.
4.     The electronic device of claim 1, the computing hardware being configured to
continuously apply the selected option to a portion of a graphical object in each area
along the path in response to detecting a swipe action of a touch sensitive object
over the portion of the graphical object.
5.     The electronic device of claim 1, wherein the computing hardware is
configured to detect an end of the substantially continuous selection, terminate the
action, and remove a visual indicator of the selected option from the graphical user
interface.
6.     The electronic device of claim 1, wherein the computing hardware is
configured to detect a speed of the substantially continuous selection of the one or
more areas along the path; and
        execute the action corresponding to the selected option at a rapidity that is
dependent at least partially on the speed of the substantially continuous selection of
the one or more areas along the path.
7.     The electronic device of claim 1, wherein the graphical user interface is a
touch- sensitive screen, and a user interface is implemented on the touch-sensitive
screen as a tactile surface of the touch-sensitive screen.
8.     The electronic device of claim 1, wherein the computing hardware is
configured to disable the execution of the action corresponding to the selected
option, in response to detecting a termination of the substantially continuous
selection of one or more areas along a path on the graphical user interface.
9.     The electronic device of claim 1, comprising a database for continuously
recording and updating the change in status of the one or more graphical objects,
the software product being coupled to the database and being configured to resume
the status of the one or more graphical objects to their last updated status in the
                                           35

database, in case of interruptions in the operable state of the graphical user
interface.
10.    The electronic device of claim 1, wherein the electronic device is connected to
a server through a network, the graphical user interface being generated temporally
concurrently on a plurality of electronic devices to facilitate a plurality of users'
interaction with the graphical user interface, wherein each of the graphical user
interfaces generated on the plurality of electronic devices are coordinated through
the server and updated concurrently on the plurality of electronic devices with time.
11.    The electronic device of claim 1, wherein the electronic device comprises a
desktop computer, a laptop computer, an iPad, or a smart phone, including an
iPhone@, an Android@ phone or a Symbian@ phone.
12.    A method of facilitating user interactions with a graphical user interface, the
graphical interface being generated and rendered on the display of an electronic
device, by executing a software product on a computing hardware of the electronic
device, the computing hardware, graphical user interface and the software product
being implemented on a gaming system, the method comprising:
        rendering one or graphical objects within the graphical user interface;
        detecting a selection of one or more of the one or more graphical object;
        rendering a menu list containing a set of selectable options, each selectable
option corresponding to an effect to be applied to a portion of a specific graphical
object, or to one or more of the one or more graphical objects;
        detecting a selection of one of the selectable options;
        detecting a substantially continuous selection of areas of the graphical user
interface along a path by detecting a swipe motion over the graphical user interface;
and
        applying the effect corresponding to the selected option to a portion of a
specific graphical object, or to one or more graphical objects corresponding to the
path, wherein the gaming system comprises a farming game, the selectable
                                            36

graphical objects of the graphical user interface comprise different spatial regions of
a farming environment in which one or more crops are grown, and wherein the
selectable options in the menu list are different farming tools.
13.    The method of claim 12, comprising configuring the graphical user interface to
continue to apply the effect corresponding to the selected option during a time of
detection of the substantially continuous selection of areas of the graphical user
interface along the path to remove the selected option when the substantial
continuous selection is terminated.
14.    The method of claim 12, comprising continuously recording and updating a
change in status of the one or more graphical objects, coupling the software product
to a database, and resuming the status of one or more graphical objects to their last
updated status in the database, in case of interruptions in the operations of the
graphical user interface.
15.    The method of claim 12, comprising:
        connecting a plurality of electronic devices to a server through a network;
generating the graphical user interface temporally concurrently on the displays of
each of the electronic devices;
        coordinating a plurality of graphical user interfaces through the server, and
updating them concurrently with time, to facilitate multiple users' interaction and
coordination with the graphical user interfaces.
16.    The method of claim 15, wherein the graphical user interfaces comprises a
gaming system, the method being implemented to facilitate an online multiplayer
gaming system.
17.    A software product recorded on a machine readable data storage medium,
the software product being executable on the computing hardware of a computing
device, for implementing a method according to claim 12.
                                             37

<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
