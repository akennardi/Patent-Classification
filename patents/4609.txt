1002019920
                                            ABSTRACT
         User interface navigation on a personal electronics device based on movements of a
crown is disclosed. The device can select an appropriate level of information arranged along a z
axis for display based on crown movement. The navigation can be based on an angular velocity
of the crown.

   1002019920
            USER INTERFACE FOR MANIPULATING USER INTERFACE OBJECTS
                      CROSS-REFERENCE TO RELATED APPLICATIONS
   [0001]      This application claims priority to U.S. Provisional Patent Application Serial No.
 5 61/873,356, filed September 3, 2013, entitled "CROWN INPUT FOR A WEARABLE
   ELECTRONIC DEVICE"; U.S. Provisional Patent Application Serial No. 61/873,359, filed
   September 3, 2013, entitled "USER INTERFACE OBJECT MANIPULATIONS IN A USER
   INTERFACE"; U.S. Provisional Patent Application Serial No. 61/959,85 1, filed September 3,
   2013, entitled "USER INTERFACE FOR MANIPULATING USER INTERFACE OBJECTS";
 0 U.S. Provisional Patent Application Serial No. 61/873,360, filed September 3, 2013, entitled
   "USER INTERFACE FOR MANIPULATING USER INTERFACE OBJECTS WITH
   MAGNETIC PROPERTIES"; and U.S. Non-provisional Patent Application Serial No.
   14/476,657, filed September 3, 2014, entitled "USER INTERFACE FOR MANIPULATING
   USER INTERFACE OBJECTS WITH MAGNETIC PROPERTIES". The content of these
 5 applications is hereby incorporated by reference in its entirety for all purposes.
   [0002]      This application is related to co-pending applications U.S. Non-provisional Patent
   Application filed September 3, 2014, concurrently herewith, entitled "CROWN INPUT FOR A
   WEARABLE ELECTRONIC DEVICE," naming Nicholas Zambetti et al. as inventors; U.S.
   Non-provisional Patent Application filed September 3, 2014, concurrently herewith, entitled
 0 "USER INTERFACE OBJECT MANIPULATIONS IN A USER INTERFACE", naming
   Nicholas Zambetti et al. as inventors; and U.S. Provisional Patent Application Serial No.
   61/747,278, filed December 29, 2012, entitled "Device, Method, and Graphical User Interface
   for Manipulating User Interface Objects with Visual and/or Haptic Feedback". The content of
   these applications is hereby incorporated by reference in its entirety for all purposes.
25 [0002a]     Also incorporated herein by reference, in its entirety, is PCT/US2014/053957
   (published as WO 2015/034965), filed on 3 September 2014.
                                                  FIELD
   [0003]      The disclosed embodiments relate generally to user interfaces of electronic devices,
   including but not limited to user interfaces for electronic watches.
                                                      1

1002019920
                                        BACKGROUND
[0004]     Advanced personal electronic devices can have small form factors. Exemplary
personal electronic devices include but are not limited to tablets and smart phones. Uses of such
personal electronic devices involve manipulation of user interface objects on display screens
                                                 la

       WO 2015/034965                                                           PCT/US2014/053957
   which also have small form factors that complement the design of the personal electronic
   devices.
   [0005]      Exemplary manipulations that users can perform on personal electronic devices
   include navigating a hierarchy, selecting a user interface object, adjusting the position, size, and
 5 zoom of user interface objects, or otherwise manipulating user interfaces. Exemplary user
   interface objects include digital images, video, text, icons, control elements such as buttons, and
   other graphics.
   [0006]      Existing methods for manipulating user interface objects on reduced-size personal
   electronic devices can be inefficient. Further, existing methods generally provide less precision
 0 than is preferable.
                                               SUMMARY
   [0007]      In some embodiments, techniques for navigating a user interface on a personal
   electronics device based on movements of a crown are disclosed. Systems and computer
   readable storage media for performing the processes described above are also disclosed.
 5                           BRIEF DESCRIPTION OF THE DRAWINGS
   [0008]      FIG. 1 illustrates an exemplary personal electronic device.
   [0009]      FIG. 2 illustrates an exemplary user interface.
   [0010]      FIG. 3 illustrates an exemplary user interface.
   [0011]      FIG. 4 illustrates an exemplary user interface.
20 [0012]      FIG. 5 illustrates an exemplary user interface.
   [0013]      FIG. 6 illustrates an exemplary user interface.
   [0014]      FIG. 7 illustrates an exemplary user interface.
   [0015]      FIG. 8 illustrates an exemplary user interface.
   [0016]      FIG. 9 illustrates an exemplary logical structure of a user interface.
25 [0017]      FIG. 10 illustrates an exemplary user interface.
                                                     2

      WO 2015/034965                                                         PCT/US2014/053957
   [0018]    FIG. 11 illustrates an exemplary user interface.
   [0019]    FIG. 12 illustrates an exemplary user interface.
   [0020]    FIG. 13 illustrates an exemplary user interface transition.
   [0021]    FIG. 14 illustrates an exemplary user interface.
 5 [0022]    FIG. 15 illustrates an exemplary user interface.
   [0023]    FIG. 16 illustrates an exemplary user interface transition.
   [0024]    FIG. 17 illustrates an exemplary user interface.
   [0025]    FIG. 18 illustrates an exemplary user interface.
   [0026]    FIG. 19 illustrates an exemplary user interface transition.
 0 [0027]    FIG. 20 illustrates an exemplary user interface.
   [0028]    FIG. 21 illustrates an exemplary user interface.
   [0029]    FIG. 22 illustrates an exemplary user interface and transition.
   [0030]    FIG. 23 illustrates an exemplary user interface.
   [0031]    FIG. 24 illustrates an exemplary user interface and transition.
15 [0032]    FIG. 25A and FIG. 25B illustrate an exemplary user interface.
   [0033]    FIG. 26 illustrates an exemplary user interface.
   [0034]    FIG. 27 illustrates an exemplary user interface and transition.
   [0035]    FIG. 28 illustrates an exemplary user interface.
   [0036]    FIG. 29 illustrates an exemplary user interface.
20 [0037]    FIG. 30 illustrates an exemplary user interface and transition.
   [0038]    FIG. 31 illustrates an exemplary user interface.
   [0039]    FIG. 32 illustrates an exemplary user interface.
                                                  3

      WO 2015/034965                                                           PCT/US2014/053957
   [0040]     FIG. 33 illustrates an exemplary user interface.
   [0041]     FIG. 34 illustrates an exemplary user interface.
   [0042]     FIG. 35 illustrates an exemplary process.
   [0043]     FIG. 36 illustrates an exemplary computing system.
 5 [0044]     FIG. 37 illustrates an exemplary personal electronic device.
   [0045]     FIG. 38 illustrates an exemplary personal electronic device.
   [0046]     FIG. 39 illustrates an exemplary personal electronic device.
   [0047]     FIG. 40 illustrates an exemplary user interface.
   [0048]     FIG. 41 illustrates an exemplary logical structure of a user interface.
 0 [0049]     FIG. 42 illustrates an exemplary user interface.
                                      DETAILED DESCRIPTION
   [0050]     In the following description of the disclosure and examples, reference is made to the
   accompanying drawings in which it is shown by way of illustration specific examples that can be
   practiced. It is to be understood that other examples can be practiced and structural changes can
 5 be made without departing from the scope of the disclosure.
   [0051]     FIG. 1 illustrates exemplary personal electronic device 100. In the illustrated
   example, device 100 is a watch that generally includes body 102 and strap 104 for affixing
   device 100 to the body of a user. That is, device 100 is wearable. Body 102 can designed to
   couple with straps 104. Device 100 can have touch-sensitive display screen (hereafter
20 touchscreen) 106 and crown 108. In some embodiments, device 100 can have one or more
   buttons 110, 112, and 114. In some embodiments, device 100 does not have buttons 110, 112,
   nor 114.
   [0052]     Conventionally, the term "crown," in the context of a watch, refers to the cap atop a
   stem for winding the watch. In the context of a personal electronic device, the crown can be a
25 physical component of the electronic device, rather than a virtual crown on a touch sensitive
   display. Crown 108 can be mechanical meaning that it can be connected to a sensor for
   converting physical movement of the crown into electrical signals. Crown 108 can rotate in two
                                                    4

       WO 2015/034965                                                          PCT/US2014/053957
   directions of rotation (e.g., forward and backward). Crown 108 can also be pushed in towards
   the body of device 100 and/or be pulled away from device 100. Crown 108 can be touch
   sensitive, for example, using capacitive touch technologies that can detect whether a user is
   touching the crown. Moreover, crown 108 can further be rocked in one or more directions or
 5 translated along a track along an edge or at least partially around a perimeter of body 102. In
   some examples, more than one crown 108 can be used. The visual appearance of crown 108 can,
   but need not, resemble crowns of conventional watches. There examples described herein refer
   to crown rotations, pushes, pulls, and/or touches, each of which constitutes a physical state of the
   crown.
 0 [0053]      Buttons 110, 112, and 114, if included, can each be a physical or a touch-sensitive
   button. That is, the buttons may be, for example, physical buttons or capacitive buttons.
   Further, body 102, which can include a bezel, may have predetermined regions on the bezel that
   act as buttons.
   [0054]      Touchscreen 106 can include a display device, such as a liquid crystal display (LCD),
 5 light-emitting diode (LED) display, organic light-emitting diode (OLED) display, or the like,
   positioned partially or fully behind or in front of a touch sensor panel implemented using any
   desired touch sensing technology, such as mutual-capacitance touch sensing, self-capacitance
   touch sensing, resistive touch sensing, projection scan touch sensing, or the like. Touchscreen
   106 can allow a user to perform various functions by touching over hovering near the touch
 0 sensor panel using one or more fingers or other object.
   [0055]      In some examples, device 100 can further include one or more pressure sensors (not
   shown) for detecting a force or pressure applied to the display. The force or pressure applied to
   touchscreen 106 can be used as an input to device 100 to perform any desired operation, such as
   making a selection, entering or exiting a menu, causing the display of additional options/actions,
25 or the like. In some examples, different operations can be performed based on the amount of
   force or pressure being applied to touchscreen106. The one or more pressure sensors can further
   be used to determine a position that the force is being applied to touchscreen 106.
   1.       Crown-based user interface control
   [0056]      FIGs. 2-7 illustrate exemplary user interfaces that respond to movements of crown
30 108 (FIG. 1). FIG. 2 shows exemplary screen 200 that can be displayed by device 100. Screen
   200 can be, for example, a home screen that appears upon power-on of device 100 or that
   appears initially when the touchscreen display of device 100 powers-on (including wake up from
                                                      5

       WO 2015/034965                                                          PCT/US2014/053957
   a sleep state). Icons 204, 206, and 208 can be displayed in screen 200. In some embodiments,
   the icons can correspond to applications operable on device 100, meaning that the applications
   can be installed onto and/or can execute as a service on device 100. A touch (e.g., a finger tap)
   on an icon causes the corresponding application to launch, meaning that the application runs in
 5 the foreground of device 100 and appears on touchscreen 106. In some embodiments, the icons
   can correspond to text documents, media items, web pages, e-mail messages, or the like.
    [0057]     Device 100 can select icons 204, 206, and 208 out of larger set of available icons for
   display on screen 200 because these icons have information relevant to the user at the current
   time. For example, icon 204 can correspond to a messaging application in which the user has
 0 just received an incoming message, and icon 206 can correspond to a calendar application where
   the user has an upcoming calendar appointment entry.
    [0058]     FIG. 3 shows exemplary screen 300, which can be displayed by device 100 in
   response to a rotation of crown 108 in direction 302 while screen 200 (FIG. 2) is displayed.
   Screen 300 can show, for example, a user's favorite icons, selected previously by the user from a
 5 larger set of available icons. Also, screen 300 can include icons, selected from the larger set of
   available icons, by device 100 based on a user's frequency of access of the icons. Exemplary
   icons 304, 306, 308, 310, and 312 displayed in screen 300 can each correspond to an application
   operable on device 100. A touch (e.g., a finger tap) on an icon causes the corresponding
   application to launch.
 0  [0059]     FIG. 4 shows exemplary screen 400, which can be displayed by device 100 in
   response to a rotation of crown 108 in direction 402 while screen 300 (FIG. 3) is displayed.
   Screen 400 can show, for example, icons corresponding to all of the applications operable on
   device 100. Because a large number of applications can be operable on device 100, screen 400
   can include a large number of icons. When many icons are displayed, the icons can be sized
25 accordingly so that they can fit within touchscreen 106, or sized so that at least a representative
   number or predetermined percentage of icons can fit visibly within touchscreen 106.
    [0060]     FIG. 5 shows exemplary screen 500, which can be displayed by device 100 in
   response to a rotation of crown 108 in direction 502 while screen 400 (FIG. 4) is displayed.
   Screen 500 can show, for example, icons corresponding to a subset of the applications operable
30 on device 100. Because fewer icons are displayed on screen 500 as compared with screen 400,
   the icons that are displayed on screen 500, e.g., icon 504, can become larger and can have
   additional fidelity as compared with the display of icons on screen 400. For example, icons on
                                                      6

       WO 2015/034965                                                          PCT/US2014/053957
   screen 500 can have indicia, in the form of text and/or imagery, identifying its corresponding
   application. As shown, icon 504 uses the letter "c" to suggest the name of the corresponding
   application begins with a "c", as in clock. In some embodiments, a touch (e.g., a finger tap) on
   an icon causes the corresponding application to launch.
 5 [0061]      FIG. 6 shows exemplary screen 600, which can be displayed by device 100 in
   response to a rotation of crown 108 in direction 602. Screen 600 can show, for example, a
   further winnowed subset of icons, as compared with screen 500, that correspond to applications
   operable on device 100. Because even fewer icons are displayed on screen 600 as compared
   with screen 500 (FIG. 5), the icons that are displayed (e.g., icon 604) can enlarge further and can
 0 have additional fidelity as compared with the display of icons on screens 200, 300, 400, and 500.
   For example, icon 604 can have the image of a clock that displays the current time. In some
   embodiments, a touch (e.g., a finger tap) on an icon causes the corresponding application to
   launch.
   [0062]      FIGs. 7 and 8 show exemplary screens 700 and 800, respectively, that can be
 5 displayed by device 100 in response to a rotation of crown 108 in direction 702 while screen 600
   (FIG. 6) is displayed.
   [0063]      With reference to FIG. 7, in some embodiments, screen 700 can be displayed in
   response to crown rotation in direction 702 when screen 600 (FIG. 6) is displayed. Because a
   single icon 704 is displayed on screen 700, icon 704 can have additional fidelity as compared
 0 with the previous screens. For example, icon 704 can have the image of a clock that displays
   day-date information along with the current time. A touch (e.g., a finger tap) on icon 704 causes
   the corresponding application to launch.
   [0064]      Turning to FIG. 8, in some embodiments, screen 800 can be displayed in response to
   crown rotation in direction 802 when screen 600 (FIG. 6) is displayed. Screen 800 shows
25 application 804, which corresponds to icon 704 (FIG. 7), operating in the foreground of device
   100. That is, application 804 launched in response to crown rotation in direction 802.
   Exemplary application 804 can be a clock application that provides alarm features. Also, in
   some embodiments, screen 800 becomes displayed in response to crown rotation in direction 802
   when screen 700 FIG. 7) is displayed.
30 [0065]      Screens 200-700 (FIGs. 2-7) described above can be logically organized as planes of
   information along an axis. Under this organization, a given screen of icons can be thought of as
   a plane, defined by two axes (e.g., x- and y-axes), having icons spatially positioned thereon.
                                                     7

       WO 2015/034965                                                           PCT/US2014/053957
   Multiple planes can be organized along a third axis orthogonal to at least one of the x- or y-axes,
   called the z-axis. (The z-axis can be perpendicular to the plane formed by the x- and y-axes.)
   [0066]      This logical organization is illustrated by FIG. 9, in which x-axis 902 and y-axis 904
   form a plane co-planar with the touchscreen screen surface of device 100 (FIG. 1) and z-axis 906
 5 is perpendicular to the x/y-plane formed by axes 902 and 904. Plane 908 can correspond to
   screen 200 (FIG. 2). Plane 910 can correspond to screen 300 (FIG. 3). Plane 912 can represent
   the collection of icons that represent the operable applications of a personal electronic device.
   Thus, different viewpoints of plane 912 can correspond to screens 400-700 (FIGs. 4-7). Planes
   908 and 910 can be related to plane 912 in that planes 908 and 910 can each include a subset of
 0 the icons available on plane 912. The particular plane of information (i.e., screen of icons) that
   is to be displayed on a personal electronic device can be selected via crown movement, such as
   crown rotation. That is, crown movement can be used to traverse the planes of information
   intersecting z-axis 906, or to provide alternative views of a given plane (e.g., plane 912).
   [0067]      In some embodiments, when an end of the z-axis (e.g., the top or bottom-most plane)
 5 is reached via crown movement, the displayed information (e.g., screen of icons) produces a
   rubberband effect to indicate that the end has been reached. Consider the situation in which a
   user has, through crown input, reached the bottom most plane of information. As the user
   provides additional crown input in the same direction, the displayed collection of icons shrink (to
   the extent possible) in accordance with the crown movement until the movement stops. When
 0 the crown movement stops, the displayed icons return from their shrunken size back to their
   normal size via on-screen animation, thereby producing the visual effect of rubberbanding.
   [0068]      One notable benefit of this logical organization is that different planes of information
   need not be (but can be) zoomed subsets of one another. That is, for example, planes 908 and
   910 can contain entire different icons out of those icons available on a personal electronic
25 device, but yet the different planes of information can be accessed efficiently by a user.
   [0069]      Alternatively, screens 200-700 (FIG. 2-7) can be logically organized as subsets of
   information belonging to different modal states of a personal electronic device. Under this
   organization, screens 200 and 300 can correspond to first and a second modal state of the device,
   and screens 400-700 can correspond to a third modal state, for example. The personal electronic
30 device can cycle through modal states in response to crown pushes, and can display screens 200
   or 300 in the first and second modal states, respectively. In alternative embodiments, modal
   states may be cycled using buttons 110, 112, or 114. When multiple screens are available within
                                                      8

       WO 2015/034965                                                            PCT/US2014/053957
   a particular modal state (e.g., the third modal state), the device can switch from the display of
   one screen (e.g., 300) to another screen (e.g., 400) based on crown rotation. On-screen user
   interface elements, such as paging dots, can be used to indicate the availability of additional
   screens for display within a particular modal state.
 5 [0070]       This logical arrangement is illustrated by FIG. 41. As shown, planes 4102 and 4104
   can correspond to screens 200 (FIG. 2) and 300 (FIG. 3) respectively. Plane 4106 can represent
   the collection of icons that represent the operable applications of a personal electronic device.
   Thus, different viewpoints of plane 4106 can correspond to screens 400-700 (FIGs. 4-7). The
   particular plane of information (i.e., screen of icons) that is to be displayed on a personal
 0 electronic device can be selected via crown movement, such as crown pushes.
   2.       Velocity-based crown control
   [0071]       Device 100 (FIG. 1) can consider the angular velocity of rotation of crown 108 (FIG.
   1) in determining whether one screen of icons should be replaced with another screen of icons.
   Specifically, device 100 can require crown 108 to rotate above a predetermined angular velocity
 5 before changing the display of one screen of icons to another. In this way, while slow rotations
   of crown 108 that are unintended by a user can still cause device 100 to receive crown input
   indicating angular displacement, the displacement need not be interpreted as having sufficient
   velocity to cause user interface updates that are unintended. The selection of predetermined
   angular velocities for this purpose can depend on a number of factors, such as the density of
 0 icons currently displayed, the visual arrangement of icons currently displayed, and so forth.
   [0072]     In some embodiments, the minimum angular velocity of crown rotation that is
   necessary to switch between screens of icons corresponds directly to the instantaneous angular
   velocity of crown 108 (FIG. 1), meaning that the user interface of device 100, in essence,
   responds when crown 108 reaches a sufficient angular velocity. In some embodiments, the
25 minimum angular velocity of crown rotation necessary for switching between screens of icons is
   a calculated velocity that is based on, but not directly equal to, the instantaneous ("current")
   angular velocity of crown 108. In these embodiments, device 100 can maintain a calculated
   crown (angular) velocity V in discrete moments in time T according to equation 1:
                                   VT=V(T-1) + AVCROWN     - AVDRAG.                             (EQ. 1)
30 [0073]     In equation 1, VT represents a calculated crown velocity (speed and direction) at time
   T, V(T-1) represents the previous velocity (speed and direction) at time T-1, AVCROWN represents
                                                      9

       WO 2015/034965                                                            PCT/US2014/053957
   the change in velocity caused by the force being applied through the rotation of the crown at time
   T, and   AVDRAG   represents the change in velocity due to a drag force. The force being applied,
   which is reflected through    AVCROWN,    can depend on the current velocity of angular rotation of
   the crown. Thus,    AVCROWN     can also depend on the current angular velocity of the crown. In this
 5 way, device 100 can provide user interface interactions based not only on instantaneous crown
   velocity but also based on user input in the form of crown movement over multiple time
   intervals, even if those intervals are finely divided. Note, typically, in the absence of user input
   in the form of AVCROWN,     VT  will approach (and become) zero based on AVDRAG in accordance
   with EQ. 1, but    VT would not change signs without user input in the form of crown rotation
 0 (AVCROWN)
   [0074]     Typically, the greater the velocity of angular rotation of the crown, the greater the value
   of AVCROWN will be. However, the actual mapping between the velocity of angular rotation of
   the crown and    AVCROWN    can be varied depending on the desired user interface effect. For
   example, various linear or non-linear mappings between the velocity of angular rotation of the
 5 crown and    AVCROWN    can be used. In another example, the mapping can depend on the number
   of icons and/or icon arrangement currently being displayed.
   [0075]     Also, AVDRAG    can take on various values. For example,    AVDRAG   can depend on the
   velocity of crown rotation such that at greater velocities, a greater opposing change in velocity
   (AVDRAG)    can be produced. In another example,     AVDRAG   can have a constant value. In yet
 0 another example,    AVDRAG    can be based on the number of current displayed icons and/or the
   currently displayed icon arrangement. It should be appreciated that the above-described
   requirements of AVCROWN and       AVDRAG    can be changed to produce desirable user interface
   effects.
   [0076]     As can be seen from EQ. 1, the maintained velocity     (VT) can continue to increase as
25 long as AVCROWN is greater than AVDRAG. Additionally,       VT  can have non-zero values even when
   no  AVCROWN    input is being received, meaning that user interface screens can continue to change
   without the user rotating the crown. When this occurs, screens can stop changing based on the
   maintained velocity at the time the user stops rotating the crown and the AVDRAG component.
   [0077]     In some embodiments, when the crown is rotated in a direction corresponding to a
30 rotation direction that is opposite the current user interface changes, the  V(T-1) component can be
   reset to a value of zero, allowing the user to quickly change the direction of the screen changes
   without having to provide a force sufficient to offset the VT
                                                       10

       WO 2015/034965                                                           PCT/US2014/053957
   [0078]    In other embodiments, different physical crown states other than rotation of the crown
   are used to navigate through displayed icons.
   3.      User interface appearance
   [0079]      Icons can take on various visual appearances. For example, icons can be rectangular
 5 in shape, as shown in FIG. 10. As another example, icons can be circular, as shown in FIGs. 2-7.
   Further, icons can take on various spatial arrangement schemes, meaning that icons can be
   arranged along the rows and columns of an invisible grid. Grids can be symmetrical or non
   symmetrical. In FIG. 10, a symmetrical grid is used, for example. In FIG. 5, a non-symmetrical
   grid having x icons arranged on a first row and y icons arranged along a second row is used, for
 0 example.
   [0080]      FIG. 11 illustrates a radial icon arrangement scheme where circular icons are aligned
   along the circumference of invisible circles 1102 and 1104 of different diameters. Invisible
   circles 1102 and 1104 are, but need not be, concentric. Icons, such as icon 1106, arranged along
   different invisible circles can have different sizes. As shown, icons arranged along invisible
 5 circle 1102 are closer to the center of device 100 and are larger than those arranged along
   invisible circle 1104. Also, although not illustrated in FIG. 11, icons in a radial arrangement can
   be arranged along more than two invisible circles.
   [0081]      The distance that a particular icon is position from the center of the radial icon
   arrangement can depend on different factors. For example, the distance can be proportional to
 0 frequency of use of the icon; an icon that is used frequently is closer to the center. As another
   example, the distance can depend on whether an incoming notification has been received for (the
   application corresponding to) the icon. As another example, the distance can be user-defined, or
   can be otherwise determined by device 100 (i.e., curated).
   [0082]      FIG. 25A illustrates an arrangement of icons into icon groups. On grid 2502, four
25 groups of icons, including icon group 2512, are displayed. In response to a touch input, such as
   a finger tap at touchscreen location 2514 on group 2512, the icons within group 2512 can be
   displayed in enlarged form. In grid 2506, the icons within group 2512, including icon 2516, are
   displayed in enlarged form. FIG. 25B illustrates an arrangement of application functionalities
   into groups. On grid 2508, as discussed above, the four icons of icon group 2512 are displayed
30 on grid 2506. A selection of icon 2516 (e.g., via finger tap 2518) can cause a group of functions
   2520 provided by application 2510 (which corresponds to icon 2508) to be displayed.
                                                      11

       WO 2015/034965                                                         PCT/US2014/053957
   [0083]      The size and shape of icon groups can be organic or defined. Icon groups that are
   defined, such as icon group 2512 in grid 2502 (FIG. 25A), share a predefined group size and
   group shape. Organic icon groups, shown in FIG. 42, can be of a user-defined group size and/or
   group shape. For example, icon groups 4204 and 4206 in grid 4202 are of different user-defined
 5 shapes and sizes. In some embodiments, organic icon groups are defined using software running
   on a computer external to the personal electronic device and downloaded onto the personal
   electronic device.
   [0084]      FIG. 30 illustrates an icon arrangement scheme where icons are arranged similar to
   pages of a rolodex. Pages of exemplary rolodex 3002 can flip in response to crown rotation. For
 0 example, page (icon) 3004 can flip downward onto page (icon) 3006 in response to a crown
   rotation.
   [0085]      FIG. 31 illustrates an icon arrangement scheme where icons are arranged on the outer
   circumference of a spinning dial. Exemplary spinning dial 3102 can spin in response to crown
   rotation. For example, a crown rotation in direction 3104 can cause dial 3102 to spin in the same
 5 direction (3106). Also, a crown push (or pull) can change the number of columns in 3102,
   allowing the icons of the remaining columns to be enlarged and/or to have increased fidelity.
   [0086]      FIG. 32 illustrates an icon arrangement scheme in the form of a thumbnailed list 202.
   Icon 3204 within exemplary thumbnailed list 3202 can have corresponding thumbnail 3206. The
   icons of thumbnailed list 3202 can be traversed via crown rotation. A specific icon, such as icon
 0 3204, can be selected directly for display by touching corresponding thumbnail 3206.
   [0087]      FIG. 33 illustrates an arrangement scheme where icons are aligned with the surface of
   an invisible sphere or polyhedron. Icons on the foreground surface of the invisible sphere, such
   as icon 3302, can be displayed. Icons on the far side of the invisible sphere's surface are not
   displayed. The invisible sphere can rotate in response to crown rotation and/or touchscreen
25 input, thereby changing the specific icons that are displayed.
   [0088]      During operation, device 100 (FIG. 1) can use one or more of the icon arrangement
   schemes described above. The particular arrangement(s) used by device 10 can be user-selected
   and/or system-selected. That is, a user may be permitted to identify one or more preferred
   arrangements for display. Also, arrangements can be selected by device 100 based on criteria
30 such as the total number of applications installed on the device, the number frequently accessed
   icons, and so forth.
                                                    12

       WO 2015/034965                                                          PCT/US2014/053957
   [0089]       Further, the specific ordering and placement of icons within a particular icon
   arrangement scheme can be user-selected and/or system-selected. For example, a user can be
   permitted to specify the position of an icon on a given screen. Also, icon placement can be
   determined by device 100 (i.e., curated) based on criteria such as the frequency of use of
 5 particular icons, a calculated relevance, and so forth.
   4.       Responses to user input
   [0090]       Displayed icons can respond to user input. FIGs. 12-14 illustrate a rearrangement of
   displayed icons in response to crown rotation. In FIG. 12, nine icons are displayed along a 3-by
   3 symmetric grid 1202. Icon 1204 is displayed in the top-right position of grid 1202. As
 0 discussed above with respect to FIGs. 4-7, a rotation of crown 108 can cause device 100 to
   reduce the number of displayed icons. For example, a rotation of crown 108 can cause device
   100 to display a 2-by-2 grid, thereby reducing the number of displayed icons. FIG. 13 illustrates
   an exemplary transition to a 2-by-2 grid in response to a crown rotation in direction 1302. As
   shown, in response to crown rotation 1302, icon 1204 is translated visibly on-screen from its top
 5 right position in the 3-by-3 grid of FIG. 12 to its new position in the 2-by-2 grid to be displayed.
   Specifically, as shown in FIG. 14, icon 1204 is translated to the lower-left corner of 2-by-2 grid
   1402. Further, icons that are to remain displayed in the 2-by-2 grid after the transition from grid
   1202 are enlarged and positioned into the 2-by-2 grid 1402.
   [0091]       FIGs. 15-17 illustrate another rearrangement of icons in response to crown rotation.
 0 In FIG. 15, nine icons are displayed along a 3-by-3 symmetric grid 1502. Icon 1504 is displayed
   in the top-right position of grid 1502. As shown in FIG. 16, in response to crown rotation 1602,
   icon 1504 is translated off-screen from its position in grid 1502 (FIG. 15) while it is translated
   into its new position in the 2-by-2 grid to be displayed. To put another way, during the transition
   illustrated by FIG. 16, icon 1504 can be split into two portions that are displayed in two separate,
25 non-abutting positions of the touchscreen of device 100. More specifically, while one portion of
   icon 1504 remains partially displayed in the top-right corner as icon 1504 is translated off
   screen, the remaining portion of 1504 is partially displayed in the lower-left corner as it is
   translated on-screen. As shown in FIG. 17, icon 1504 is translated to the lower-left corner of 2
   by-2 grid 1702. Further, icons that are to remain displayed in the 2-by-2 grid after the transition
30 from grid 1502 are enlarged and positioned into the 2-by-2 grid 1702.
   [0092]       FIGs. 18-20 illustrate another rearrangement of icons in response to crown rotation.
   In FIG. 18, nine icons are displayed along a 3-by-3 symmetric grid 1802. As shown in FIG. 19,
                                                      13

       WO 2015/034965                                                           PCT/US2014/053957
   in response to crown rotation 1902, the icons along the right and bottom boundaries of grid 1802
   (FIG. 18) are removed from display while the remaining icons are enlarged. The remaining
   icons are displayed enlarged as shown in grid 2002 of FIG. 20.
   [0093]      It should be noted that in the exemplary screens shown in FIGs. 12-20, the icon
 5 displayed in the upper-left corner (i.e., marked "A") is anchored, meaning that the above
   described transitions do not cause the icon to move away from the upper-left corner. It is
   possible, however, to unanchor such an icon through user input, as discussed below.
   [0094]      FIG. 21 illustrates a rearrangement of icons in response to touchscreen input. As
   shown, icon 2106 is displayed in the bottom row of 4-by-4 grid 2012. In response to a finger tap
 0 2104 on icon 2106, 3-by-3 grid 2108 is displayed with icon 2106 enlarged in the center.
   Notably, the icon marked "A," which is displayed in grid 2012, is no longer displayed in grid
   2108. FIG. 21 also illustrates an update of displayed icons in response to crown rotation.
   Specifically, in response to crown rotation 2110, icon 2106 is further enlarged and becomes the
   only icon displayed on-screen.
 5 [0095]      FIG. 22 illustrates a rearrangement of icons in response to movement of device 100.
   Device movement can be detected using one or more sensors, for example, a gyroscope. As
   shown, various icons are displayed in grid 2202. In response to tilting of device 100 in direction
   2204, the displayed icons are translated in direction 2206, resulting in the display of different
   icons in grid 2208. Specifically, in response to the leftward tilting of device 100 in direction
 0 2204, the icons of grid 2202 translate in the left direction 2206. In some embodiments, the
   translation may be incremental such that a single row or column transitions off a single row or
   column transitions onto the display. Alternatively, a whole screen of icons may transition off as
   a completely new set of icons transition onto the display.
   [0096]      FIG. 23 illustrates a change in icon appearance in response to touchscreen input. As
25 shown, in response to a touch at location 2304, icon 2306 becomes enlarged. Notably, icon 2306
   is not located at location 2304, rather, icon 2306 (in its unenlarged state) is in row 2310 above
   touch location 2304 which is along row 2312. In this way, user visibility of icon 2306 is
   improved both because the icon is enlarged and because the icon is not blocked from view by the
   potentially opaque object that is touching device 100. It should be noted that more than one icon
30 can be enlarged in response to a nearby touch. Multiple icons can be enlarged at different levels
   of magnification inversely proportional to the distance between each icon being enlarged and the
   touch location.
                                                      14

       WO 2015/034965                                                          PCT/US2014/053957
   [0097]      FIG. 40 illustrates icon movements that account for physical interaction between
   nearby icons. As shown, grid 4002 includes a number of icons arranged in a radial arrangement.
   In response a touch input at location 4010, a number of icons are enlarged to at different levels of
   magnification. Notably, the enlarging of icon 4004 can cause adjacent icons 4006 and 4008 to
 5 move away from icon 4004 so the icons do not block each other from view.
   [0098]      FIG. 24 illustrates icon movements that account for interaction between icons and
   grid boundaries. As shown, a number of icons are displayed according to non-symmetrical grid
   2402. The displayed icons include uncompressed icons 2408. In response to touch input in the
   form of a rightward gesture in direction 2404, icons on the right boundary of grid 2402 can be
 0 compressed into compressed icons 2406 so that icons from the left side of grid 2402 are more
   predominately displayed either in enlarged or unenlarged form. Also, in response to a touch
   gesture in the leftward direction 2406, icons that are on the left boundary of grid 2402 can be
   compressed into compressed icons 2412 so that icons from the right side of grid 2402 are more
   predominately displayed. The above-described interaction allows all, or substantially all, icons
 5 to be simultaneously displayed while allowing a user to easily view and select an icon. Note that
   this compression may occur in a symmetrical grid, although not shown.
   [0099]      FIG. 34 illustrates icon movements that account for interaction between grid
   boundaries and nearby icons. In the radial arrangement of FIG. 34, icons are arranged between
   invisible inner circle 3402 and invisible outer boundary circle 3400. Outer circle 3400 can be
 0 sized based on the physical size the touchscreen of device 100. Inner circle 3402 can be sized
   based on design and/or user preferences. Inner circle 3402 can also be sized based on user input,
   such as a crown rotation. Inner circle 3402 can respond to touchscreen input within its surface
   area. For example, a touch down that occurs within the surface area of inner circle 3402 and
   subsequent touch movement can be interpreted as panning of inner circle 3402. When inner
25 circle 3402 is panned, the icons that are arranged between the inner circle 3402 and outer circle
   3400, such as icons 3404 and 3408, can be resize based on the available spacing between inner
   circle 3402 and outer circle 3400, the number of icons being displayed, and the sizes of adjacent
   icons. For example, in response to the rightward panning of circle 3402, icon 3404 can increase
   in size, and the enlarging of icon 3404 can cause icon 3408 to decrease in size.
30 [00100]     Note, in the absence of user input, displayed icons can be programmed to move on
   screen to prevent screen burn-in. Also, icon arrangements can respond to multi-touch gestures.
   For example, a two-finger downward gesture on the touchscreen of device 100 (FIG. 1) can
   cause the display of system information such as a status bar. As another example, a two-finger
                                                     15

       WO 2015/034965                                                           PCT/US2014/053957
   gesture in which the two fingers move in opposite directions can configure device 100 (FIG. 1)
   for left-handed or right-handed use.
   5.       Additional features
   [00101]     Turning back to FIG. 2, home screen 200 can display system-generated information
 5 such as alerts. For example, home screen 200 can display a reminder that the user has sat for an
   extended duration and exercise is in order. Also, screen 200 can display a suggestion for rest
   because the user has a busy calendar for the next morning. Also turning back to FIG. 3, screen
   300 can be displayed when device 100 is coupled with a dock.
   [00102]     FIG. 26 illustrates the use of wallpaper 2602 to aid user navigation in a grid of icons.
 0 As shown, grid 2600 has a relatively large number of icons. In response to crown rotation 2604,
   a subset of the icons from grid 2600 is enlarged and displayed in grid 2606. In addition, the
   corresponding portion of wallpaper 2602 displayed in the background of the subset is also
   displayed, meaning that, for example, if icons from the upper-left quadrant of grid 2600 become
   displayed in grid 2606, then the upper-left quadrant of wallpaper 2602 is also displayed with grid
 5 2606. Also as shown, in response to a touch gesture in leftward direction 2608, device 100 can
   display another subset of icons from grid 2600. For example, in grid 2610, icons from the upper
   right quadrant of grid 2600 are displayed together with the upper-right quadrant of wallpaper
   2600. In this way, a user can determine the relationship between a set of currently displayed
   icons relative to the totality of icons available for display on device 100.
 0 [00103]     FIG. 27 illustrates an exemplary arrangement of icons where the arrangement
   provides information, for example current time information, to a user. The arrangement can be
   displayed in response to crown movement. Also, the arrangement can be displayed after a
   predetermined period of user input inactivity. For example, screen 2702, which uses icons in
   small sizes to show the current time, can be displayed after a predetermined period of user input
25 inactivity. Further, in response to a crown rotation, screen 2702 can transition through screens
   2704 and 2706 to screen 2708, which shows a grid of icons.
   [00104]     FIG. 28 illustrates an exemplary arrangement of icons (grid 2802) where the color
   and/or intensity of displayed icons can change in response to incoming information. For
   example, icon 2804 corresponding to a messaging application can blink or glow when a new
30 message arrives. In some embodiments, the blink or glow can correspond to the popularity of an
   application in an application store or frequency of use of the application in a larger ecosystem of
                                                       16

       WO 2015/034965                                                           PCT/US2014/053957
   users. Further, the icons of grid 2802 can show icons representing a larger set of applications
   available in an application store, beyond those applications that are installed
   [00105]     FIG. 29 illustrates an exemplary display of a contextual message. A contextual
   message can be displayed in response to detection of a user's touch of crown 108. A contextual
 5 message indicates the current functionality of crown 108, which can take on different functions
   depending on the application that is currently operating in the foreground of device 100. For
   example, when a music application is operating in the foreground of device 100, a touch on
   crown 108 can result in the display of contextual message 2902 in the form of a volume
   indicator, which can indicate to a user that the current functionality of crown 108 is volume
 0 control.
   [00106]     FIG. 35 depicts exemplary process 3500 for providing the user interface techniques
   described above. At block 3510, input based on crown movement and/or crown touch is
   received. The crown movement can be a rotation, a push, and/or a pull. At block 3520, a
   decision is made based on the type of crown movement represented by the received input. If the
 5 received input represents a crown rotation, processing proceeds to block 3530. If the received
   input represents a crown push or pull, processing proceeds to block 3550. If the received input
   represents a crown touch (without a rotation or a push/pull), processing proceeds to block 3560.
   At block 3530, the currently displayed screen and its corresponding position along z-axis 906
   (FIG. 9) can be determined. In addition, an adjacent level of information along the z-axis 906
 0 can be determined. The adjacent level can be determined based on the direction of the crown
   rotation that is represented by the received input. A corresponding grid of icons, such as those
   illustrated by each of FIGs. 4-7, can be displayed. At block 3550, a home screen, such as the
   exemplary screen 200 of FIG. 2, can be displayed. In the alternative, a user-favorites screen,
   such as the exemplary screen 300 of FIG. 3, can be displayed. At block 3560, a contextual
25 message, such as the exemplary contextual message 2902 of FIG. 29, can be displayed.
   [00107]     FIG. 36 depicts exemplary computing system 3600 for providing the user interface
   techniques described above. In some embodiments, computing system 3600 can form device
   100. As shown, computing system 3600 can have bus 3602 that connects I/O section 3604, one
   or more computer processors 3606, and a memory section 3608 together. Memory section 3608
30 can contain computer-executable instructions and/or data for carrying out the above-described
   techniques, including process 3500 (FIG. 35). I/O section 3604 can be connected to display
   3610, which can have touch-sensitive component 3612. 1/0 section 3604 can be connected to
   crown 3614. 1/0 section 3604 can be connected to input device 3616, which may include
                                                     17

       WO 2015/034965                                                         PCT/US2014/053957
   buttons. 1/0 section 3604 can be connected to communication unit 3618, which can provide Wi
   Fi, Bluetooth, and/or cellular features, for example. 1/0 section 3604 can be connected to sensor
   pack 3620, which can have a gyroscope, a GPS sensor, a light sensor, a gyroscope, an
   accelerometer, and/or a combination thereof. Note, one or more of the above-described
 5 components can be part of a system-on-a-chip.
   [00108]     Memory section 3608 of computing system 3600 can be a non-transitory computer
   readable storage medium, for storing computer-executable instructions, which, when executed by
   one or more computer processors 3606, for example, can cause the computer processors to
   perform the user interface techniques described above, including process 3500 (FIG. 35). The
 0 computer-executable instructions can also be stored and/or transported within any non-transitory
   computer readable storage medium for use by or in connection with an instruction execution
   system, apparatus, or device, such as a computer-based system, processor-containing system, or
   other system that can fetch the instructions from the instruction execution system, apparatus, or
   device and execute the instructions. For purposes of this document, a "non-transitory computer
 5 readable storage medium" can be any medium that can contain or store computer-executable
   instructions for use by or in connection with the instruction execution system, apparatus, or
   device. The non-transitory computer readable storage medium can include, but is not limited to,
   magnetic, optical, and/or semiconductor storages. Examples of such storage include magnetic
   disks, optical discs based on CD, DVD, or Blu-ray technologies, as well as RAM, ROM,
 0 EPROM, flash memory, and solid-state memory.
   [00109]     Computing system 3600 is not limited to the components and configuration of FIG.
   36, but can include other or additional components in multiple configurations. In some
   embodiments, system 3600 can form personal electronic device 3700, which is a tablet, as shown
   in FIG. 37. In some embodiments, computing system 3600 can form personal electronic device
25 3800, which is a mobile phone, as shown in FIG. 38. In some embodiments, computing system
   3600 can form personal electronic device 3900, which is a portal music device, as shown in FIG.
   39.
   [00110]     Although the disclosure and examples have been fully described with reference to the
   accompanying figures, it is to be noted that various changes and modifications will become
30 apparent to those skilled in the art. Such changes and modifications are to be understood as
   being included within the scope of the disclosure and examples as defined by the appended
   claims.
                                                    18

   1002019920
                                                   CLAIMS
   WHAT IS CLAIMED IS:
 5 1.         A computer-implemented method comprising:
            displaying a plurality of icons on a touch-sensitive display of a wearable electronic
   device;
            receiving input based on a movement of a physical crown of the wearable electronic
   device, wherein the movement is a rotation in a first direction; and
 0          in response to the received input, launching an application associated with a first icon of
   the plurality of icons.
   2.       The computer-implemented method of claim 1, wherein the first icon of the plurality of
   icons is displayed at a size greater than a second icon from the plurality of icons.
   3.       The computer-implemented method of any of the previous claims, wherein a first icon of
 5 the plurality of icons is displayed centered relative to the remaining icons of the plurality of
   icons.
   4.       The computer-implemented method of any of the previous claims, wherein launching the
   application includes gradually removing all visible icons from the touch-sensitive display while
   gradually displaying, on the touch-sensitive display, the application associated with the first icon
 0 of the plurality of icons.
   5. The computer-implemented method of any of the previous claims, further comprising:
            receiving input based on a movement of a physical crown of the wearable electronic
   device, wherein the movement is a rotation in a second direction opposite of the first direction;
   and
25          in response to the received input, minimizing an application associated with the first icon
   of the plurality of icons, wherein minimizing the application includes gradually displaying, on
   the touch-sensitive display, at least the fist icon of the plurality of icons while gradually
   removing from the touch-sensitive display the application associated with the first icon of the
   plurality of icons.
                                                       19

   1002019920
   6.       The computer-implemented method of any of claims 1-5, wherein the plurality of icons
   correspond to plurality applications stored on the wearable electronic device.
   7.       The computer-implemented method of any of claims 1-5, wherein the plurality of icons
   correspond plurality open applications on the wearable electronic device.
 5 8.       The computer-implemented method of any of claims 1-5, wherein the plurality of icons
   correspond to a user-generated set of applications on the wearable electronic device.
   9.       The computer-implemented method of any of the previous claims, wherein the wearable
   electronic device is a watch.
   10.      The computer-implemented method of any of the previous claims, wherein the rotation
 0 exceeds a predetermined angular velocity threshold.
   11.      The computer-implemented method of any of the previous claims, the method further
   comprising:
            receiving information representing an activity in an application, wherein the application
   corresponds to a displayed icon; and
 5          in response to the received information, altering the appearance of the displayed icon.
   12.      The method of claim 11, wherein the altering is one or more of blinking, changing color,
   and animating.
   13.      The method of any of the previous claims, wherein the physical crown is a mechanical
   crown.
20 14.      The method of any of the previous claims, further comprising:
            detecting a force applied to the touch-sensitive display; and
            replacing information displayed on the touch-sensitive display based on the detected
   force.
   15.      A non-transitory computer-readable storage medium having computer-executable
25 instructions which, when executed by one or more computer processors, cause the one or more
   computer processors to:
                                                     20

  1002019920
           displaying a plurality of icons on a touch-sensitive display of a wearable electronic
  device;
           receiving input based on a movement of a physical crown of the wearable electronic
  device, wherein the movement is a rotation in a first direction; and
5          in response to the received input, launching an application associated with a first icon of
  the plurality of icons.
  16.      An electronic device comprising:
  one or more processors;
  a physical crown operatively coupled to the one or more processors; and
0 a touch-sensitive display operatively coupled to the one or more processors,
  the one or more processors configured to:
           displaying a plurality of icons on a touch-sensitive display of a wearable electronic
  device;
           receiving input based on a movement of a physical crown of the wearable electronic
5 device, wherein the movement is a rotation in a first direction; and
           in response to the received input, launching an application associated with a first icon of
  the plurality of icons.
                                                    21

<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
