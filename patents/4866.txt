 5                                                 Abstract
   An automatic cleaning device includes: a collection unit (10) for collecting a pre-set environment
   parameter of surroundings of the automatic cleaning device; and an application processor (20). The
   application processor (20) includes a central processing unit (201) electrically coupled to the collection
   unit (10) to acquire the pre-set environment parameter collected by the collection unit (10). The
10 application processor (20) further includes a graphic processing unit (202) electrically coupled to the
   central processing unit (201). The graphic processing unit (202) obtains the pre-set environment
   parameter from the central processing unit (201) and then generates a map of the surroundings of the
   automatic cleaning device based on the pre-set environment parameter. The technical solution of the
   present disclosure can enhance the processing capability and the reaction speed of the automatic
15 cleaning device so as to improve the working efficiency of the automatic cleaning device.

        1/6
   AUTOMATIC
CLEANING DEVICE
  COLLECTION
     UNIT 10
   AP20
     CPU201
    "IL"
     GPU202
         Fig. 1

    AUTOMATIC CLEANING DEVICE AND CLEANING
                                            METHOD
TECHNICAL FIELD
[0001]             The present disclosure relates to the field of automatic cleaning technology, and
in particular to an automatic cleaning device and a cleaning method.
BACKGROUND
[0002]             In the related art, a variety of automatic cleaning devices such as automatic
sweeping robots and automatic mopping robots may perform a variety of cleaning operations
automatically, which brings convenience to users. An automatic cleaning device needs to generate
a real-time map of the surrounding environment of the automatic cleaning device, in order to
perform cleaning operations automatically.
[00031             However, since the processing capability of the automatic cleaning device is
limited, the working efficiency of the automatic cleaning device is usually reduced due to the low
speed of map generation.
SUMMARY
[0004]             The present disclosure provides an automatic cleaning device which can solves
the disadvantages of the related art.
[0005]             According to a first aspect of one embodiment of the present disclosure, an
automatic cleaning device is provided and includes: a collection unit configured to collect a
pre-set environment parameter of surroundings of the automatic cleaning device; and an
application processor. The application processor includes a central processing unit electrically
coupled to the collection unit; the central processing unit is configured to acquire the pre-set
environment parameter collected by the collection unit. The application processor further includes
a graphic processing unit electrically coupled to the central processing unit; and the graphic
processing unit is configured to obtain the pre-set environment parameter from the central
processing unit and then generate a map of the surroundings of the automatic cleaning device
based on the pre-set environment parameter.
[00061             Optionally, the collection unit includes a laser ranging device; and distance data
between the laser ranging device and surrounding objects, collected by the laser ranging device, is
taken as the pre-set environment parameter.
                                                    1

[00071            Optionally, the laser ranging device includes a point laser emitter; and the point
laser emitter obtains the distance data between the laser ranging device and surrounding objects by
generating a point laser.
[00081            Optionally, the laser ranging device includes a line laser emitter; and the line
laser emitter obtains the distance data between the laser ranging device and surrounding objects by
generating a line laser.
[0009]            Optionally, the collection unit includes an image acquisition device; and image
data of surrounding objects collected by the image acquisition device is taken as the pre-set
environment parameter.
[0010]            Optionally, the graphic processing unit includes: a memory module configured to
store a positioning algorithm based on particle filter; and a computing module coupled to the
memory module and configured to call the positioning algorithm and calculate and process the
pre-set environment parameter to obtain the map of the surroundings of the automatic cleaning
device.
[0011]            Optionally, the automatic cleaning device further includes a pre-processing unit.
The pre-processing unit is coupled to the collection unit and the central processing unit
respectively, and is configured to pre-process the pre-set environment parameter, thereby allowing
the central processing unit to obtain the pre-set environment parameter after the pre-processing.
[0012]            Optionally, the pre-processing unit includes a digital signal processor (DSP).
[00131            Optionally, the automatic cleaning device is a sweeping robot or a mopping
robot.
[0014]            According to a second aspect of one embodiment of the present disclosure, a
cleaning method for an automatic cleaning device is provided and includes: a data acquisition step
of using a collection unit to collect a pre-set environment parameter of surroundings of the
automatic cleaning device; a data pre-processing step of using a pre-processing unit to pre-process
the pre-set environment parameter and provide the pre-set environment parameter after
pre-processing to a central processing unit; and a data processing step of providing, by the central
processing unit, the pre-set environment parameter after pre-processing to a graphic processing
unit and generating, by the graphic processing unit, map data of the surroundings of the automatic
cleaning device based on the pre-set environment parameter after pre-processing.
[0015]            Optionally, the graphic processing unit includes a memory module and a
computing module coupled to the memory module; and the data processing step further includes:
calling, by the computing module, a positioning algorithm based on particle filter stored in the
memory     module,    calculating   and processing the pre-set       environment     parameter   after
pre-processing to obtain the map of the surroundings of the automatic cleaning device.
[00161            Optionally, the data acquisition step includes: using a laser ranging device to
collect distance data between the laser ranging device and surrounding objects, and taking the
distance data collected by the laser ranging device as the pre-set environment parameter.
[0017]            Optionally, the data acquisition step includes using an image acquisition device
                                                   2

to collect image data of surrounding objects, and taking the image data collected by the image
acquisition device as the pre-set environment parameter.
[00181             According to a third aspect of one embodiment of the present disclosure, a
computer control system for an automatic cleaning device is provided and includes: a central
processing unit, a graphic processing unit, a collection unit and a pre-processing unit. The central
processing unit, the graphic processing unit, the collection unit and the pre-processing unit are
connected through a communication bus. The collection unit is configured to collect a pre-set
environment parameter of surroundings of the automatic cleaning device; the central processing
unit is configured to acquire the pre-set environment parameter collected by the collection unit;
and the graphic processing unit is configured to obtain the pre-set environment parameter from the
central processing unit and then generate a map of the surroundings of the automatic cleaning
device based on the pre-set environment parameter.
[0019]             According to a fourth aspect of one embodiment of the present disclosure, a
mobile electronic device is provided and includes: a communication connection establishment
module configured to establish a communication connection between the mobile electronic device
and the above automatic cleaning device; a position instruction sending module configured to send
a position information request instruction to the automatic cleaning device; a position receiving
module configured to receive position information returned by the automatic cleaning device once
every preset time, wherein the position information includes a real-time positon of the automatic
cleaning device; and a display module configured to display the positon information on an in
interactive interface of the mobile electronic device.
[0020]             Optionally, the mobile electronic device further includes a control instruction
sending module configured to send an action request instruction to the automatic cleaning device.
[0021]             The technical solutions provided in embodiments of the present disclosure can
achieve following beneficial effects.
[0022]             As can be seen from the above embodiments, the application processor of the
automatic cleaning device of the present disclosure employs both of the central processing unit
and the graphic processing unit cooperating with each other, and thus the graphic processing unit
can be dedicated to generating the map of the surroundings of the automatic cleaning device while
the central processing unit can be used for other data processing and process control. Since the
graphic processing unit undertakes the generation of the map, data processing requirements for the
central processing unit can be reduced, thereby enhancing the processing capability and the
reaction speed of the automatic cleaning device so as to improve the working efficiency of the
automatic cleaning device.
[00231             It is to be understood that both the foregoing general description and the
following detailed description are exemplary and explanatory only and are not restrictive of the
disclosure.
BRIEF DESCRIPTION OF THE DRAWINGS
[0024]             The accompanying drawings, which are incorporated in and constitute a part of
this specification, illustrate embodiments consistent with the present disclosure and, together with
                                                   3

the description, serve to explain the principles of the present disclosure.
 [0025]            Fig. 1 is a schematic diagram of an automatic cleaning device according to an
exemplary embodiment;
 [00261            Fig. 2 is a schematic diagram of another automatic cleaning device according to
an exemplary embodiment;
 [0027]            Fig. 3 is a schematic diagram of a GPU according to an exemplary embodiment;
and
 [00281            Fig. 4 to Fig. 7 are schematic views of an automatic cleaning device according to
an exemplary embodiment.
DETAILED DESCRIPTION
 [0029]            Reference will now be made in detail to embodiments, examples of which are
illustrated in the accompanying drawings. The following description refers to the accompanying
drawings in which the same numbers in different drawings represent the same or similar elements
unless otherwise represented. The implementations set forth in the following description of
embodiments do not represent all implementations consistent with the invention. Instead, they are
merely examples of apparatuses and methods consistent with aspects related to the invention as
recited in the appended claims.
 [00301            Fig. 1 is a schematic diagram of an automatic cleaning device according to an
exemplary embodiment. As shown in Fig. 1, the automatic cleaning device may include a
collection unit 10 and an application processor (AP) 20. The collection unit 10 is used to collect a
pre-set environment parameter of surroundings of the automatic cleaning device. The AP 20 may
generate a map of the surroundings of the automatic cleaning device by analyzing and processing
the pre-set environment parameter, thereby allowing the automatic cleaning device to move and
perform operations such as an automatic cleaning operation.
 [00311            In the automatic cleaning device of the present disclosure, the AP 20 may further
include a central processing unit (CPU) 201 and a graphic processing unit (GPU) 202. The CPU
201 is electrically coupled to the collection unit 10 and acquires the above pre-set environment
parameter collected by the collection unit 10. The GPU 202 is electrically coupled to the CPU 201,
and obtains the above pre-set environment parameter that is acquired by the CPU 201 from the
collection unit 10, and then generates the map of the surroundings of the automatic cleaning
device based on the pre-set environment parameter.
 [0032]            In this embodiment, compared with the CPU 201, the GPU 202 is more suitable
for performing the same calculation for a large amount of data due to structural characteristics of
the GPU 202 itself, and the pre-set environment parameter collected by the collection unit 10 is
just a large amount of data of the same type. Therefore, by providing both of the CPU 201 and the
GPU 202 simultaneously in the AP 20, on the one hand, the GPU 202 can share processing loads
with the CPU 201; on the other hand, the structural characteristics and data processing capability
of the GPU 202 itself can be fully utilized, thereby accelerating real-time generation of the map
                                                   4

and improving the working efficiency of the automatic cleaning device.
[00331             1. Data pre-processing
[0034]             As shown in Fig. 2, the automatic cleaning device may further include a
pre-processing unit 30. The pre-processing unit 30 is coupled to the collection unit 10 and the
CPU 201 respectively, and is used to pre-process the pre-set environment parameter, thereby
allowing the CPU to obtain the pre-set environment parameter after the pre-processing. For
example, the pre-processing unit 30 may be a digital signal processor (DSP) which performs the
pre-processing on the pre-set environment parameter collected by the collection unit 10, such as
data format conversion, integration and cleaning, thereby facilitating the GPU 202 to perform final
processing on the pre-set environment parameter.
[00351             2. Data processing
[00361             When the GPU generates the map according to the pre-set environment
parameter, a variety ways of calculation and processing may be adopted. Fusion of sensor data
may be performed by means of a sensor fusion algorithm. For example, the GPU 202 may locate
the automatic cleaning device in a working region and obtains the corresponding map by means of
a positioning algorithm based on particle filter. The generation of the map is implemented by
means of a fusion algorithm, with multiple sensors based on a common time reference. The
utilization of the positioning algorithm based on particle filter in combination with GPU parallel
computation solves the problem of positioning accuracy, avoids the local optimal problem, and
meanwhile achieves real-time requirements through the parallel computation. Using heuristic
search algorithm for path planning can theoretically ensures that the amount of calculation is
greatly optimized while searching for the optimal path, so that the path planning can be solved in
real time.
[0037]             Accordingly, as shown in Fig. 3, the GPU 202 may include a memory module
202A which stores the positioning algorithm based on particle filter; and a computing module
202B that is coupled to the memory module 202A, calls the positioning algorithm in the memory
module 202A, and calculates and processes the pre-set environment parameter based on the
positioning algorithm to obtain the map of the surroundings of the automatic cleaning device. Of
course, GPU and a random access memory (RAM) may be set separately. In one embodiment, the
GPU rasterizes the working region defined and enclosed by connection lines between
light-reflecting points of surrounding objects of the automatic cleaning device, and obtains
coordinate values of each intersection point. The GPU calculates a plurality of second angles
between a variety of connection lines formed by connecting each intersection point to a variety of
reflective points, and the plurality of second angles define a second angle group corresponding to
each intersection point, and then stores each second angle group. When the automatic cleaning
device moves in the working region, a laser emission line emitted by a laser emitter is reflected by
surrounding objects to form laser reflection lines, and the laser reflection lines are received by a
receiver. The surrounding objects have a light-reverse function that enables the laser reflection line
to be parallel with the laser emission line. The receiver is capable of receiving simultaneously
multiple laser reflection lines. An angle encoder can measure a plurality of first angles between a
head orientation line of the automatic cleaning device and the multiple laser reflection lines. The
GPU processes the plurality of first angles to obtain a third angle group of angles between the
                                                  5

laser reflection lines. The GPU compares the third angle group with the second angle group to
obtain a position of a robot in the coordinate system. In this way, the positon of the automatic
cleaning device in the map can be determined by the GPU in real time.
[00381            3. The collection unit 10 and the pre-set environment parameter
[00391            A variety of different types of collection units 10 may be adopted in the
automatic cleaning device, and collected pre-set environment parameters and data processing
methods adopted by the GPU 202 may be varied accordingly. For ease of understanding, the
technical solutions of the present disclosure will be described hereinafter in conjunction with a
sweeping robot as shown in Fig. 4 to Fig. 7.
[0040]            As shown in Fig. 4 to Fig. 7, a sweeping robot 100 (of course, which may be
other types of the automatic cleaning device such as a mopping robot, and this is not limited in the
present disclosure) includes a robot body 110, a sensor system 120, a control system 130, a drive
system 140, a cleaning system 150, a power supply system 160 and a human-machine interaction
system 170.
[0041]            The robot body 110 includes a front part 111 and a rear part 112. The robot body
110 may have a nearly circular shape (i.e., the front part and the rear part form segments of the
circle respectively). The robot body 110 may also have other shapes, including but not limited to a
proximate D-shape, e.g., the front part has a flat outer surface and the outer surface of the rear part
forms an arc.
[0042]            The sensor system 120 includes a position determination device 121 located
above the robot body 110, a bumper sensor 122 disposed on the front part 111 of the robot body
110, a cliff sensor 123, an ultrasonic sensor (not shown), an infrared sensor (not shown), a
magnetometer (not shown), an accelerometer (not shown), a gyroscope (not shown), an odometer
(not shown), and the like. These components of the sensor system 120 provide various position
information and motion information to the control system 130. The position determination device
121 includes the collection unit 10 shown in Fig. 1 or Fig. 2. For example, the collection unit 10
may be a camera, a laser ranging device , etc.
[00431             1) In one case, the collection unit 10 is an image acquisition device (i.e., a
camera); and the pre-set environment parameter collected by the image acquisition device is
image data of surrounding objects of the sweeping robot; and then the GPU 202 analyzes and
processes the image data of surrounding objects to generate a corresponding map.
[0044]            2) In another case, the collection unit 10 is a laser ranging device, distance data
between the laser ranging device and surrounding objects, collected by the laser ranging device, is
taken as the pre-set environment parameter; and then the GPU 202 analyzes and processes the
distance data to generate a corresponding map.
[0045]            How to determine positions is described hereinafter by taking an example of the
laser ranging device based on a triangulation method. The basic principle of the triangulation
method is based on uniform scaling relation of similar triangles, and is not elaborated herein.
[00461            The laser ranging device includes a light emitting unit and light receiving unit.
The light emitting unit may include a light source for emitting light. The light source may include
                                                   6

a light emitting component such as a light emitting diode that emits infrared light, visible infrared
light or visible light. Preferably, the light source may be a light emitting component that can emit
laser beams. In this embodiment, as an example, a laser diode may be taken as the light source.
Specifically, due to monochrome, directional and collimated nature of the laser beam, the light
source that can emit laser beams can make the measurement more accurate than other light source.
For example, compared with the laser beams, the infrared light or visible light emitted by the light
emitting diode may be affected by surrounding environment factors (such as color or texture of an
object), and then measurement accuracy may be reduced. The laser diode may be a point laser for
measuring two-dimensional position information of obstacles, or a line laser for measuring
three-dimensional position information within a certain range of obstacles.
[0047]             The light receiving unit may include an image sensor. Light spots that are
reflected or scattered by obstacles are formed on the image sensor. The image sensor may be a set
of pixels in single row or multiple rows. The light receiving unit can convert light signals into
electrical signals. The image sensor may be a complementary metal oxide semiconductor (CMOS)
sensor or a charge coupled device (CCD) sensor. Preferably, the complementary metal oxide
semiconductor is selected as the image sensor due to its cost advantage. Further, the light
receiving unit may further include a light-receiving lens assembly. Light that is reflected or
scattered by obstacles may travel through the light-receiving lens assembly to form an image on
the image sensor. The light-receiving lens assembly may include one or more lenses.
[00481             A base portion may support the light emitting unit and the light receiving unit.
The light emitting unit and the light receiving unit are disposed on the base portion and are spaced
from each other by a certain distance. In order to detect obstacles in the 360-degree directions
around the robot, the base portion may be rotatably mounted on the robot body 110, or the base
portion itself does not rotate but is provided with a rotation component to enable the light emitting
unit and the light receiving unit to rotate. A rotation angular velocity of the rotation component
may be obtained by means of an optical coupling element and a code disk. The optical coupling
element detects missing teeth of the code disk. An instantaneous angular velocity can be obtained
by dividing a distance between the missing teeth by a time for sliding over the distance between
the missing teeth. The greater the density of the missing teeth in the code disk is, the higher the
measurement accuracy and the measurement precision are, but the more precise the structure is,
and the higher the amount of calculation is. Reversely, the smaller the density of the missing teeth
in the code disk is, the lower the measurement accuracy and the measurement precision are, but
the structure is simpler and the amount of calculation is smaller, thereby reducing cost.
[0049]             A data processing device such as a DSP coupled with the light receiving unit
records distances of obstacles at any angle relative to a 0 degree direction of the robot and sends
the distances to the data processing unit of the control system 130 such as the application
processor including the CPU. The CPU runs the positioning algorithm based on particle filter to
obtain a current position of the robot and then draws a map based on this positon for navigation.
Preferably, the simultaneous localization and mapping (SLAM) algorithm is used as the
positioning algorithm.
[0050]             The front part 111 of the robot body 110 may bear the bumper sensor 122. When
the robot is propelled by a wheel driving module 141 to move on the floor in a cleaning process,
                                                    7

the bumper sensor 122 detects one or more events (or objects) in the moving path of the robot 100
by means of the sensor system such as the infrared sensor. The robot 100 is configured to control
the wheel driving module 141 to act in response to the events/objects detected by the bumper
sensor 1202, such as an obstacle, a wall, and the like, so as to move away from obstacles in the
moving path of the robot 100.
[0051]            The control system 130 is provided on a circuit board in the robot body 110. The
control system 130 includes a processor in communication with a non-transitory memory such as a
hard disk, a flash memory, a random access memory, etc. For example, the processor is a central
processing unit or an application processor. The application processor can implement a positioning
algorithm, such as a simultaneous localization and mapping (SLAM) algorithm, to generate a
real-time map of the surrounding environment of the robot 100, based on the obstacle information
detected and fed back by the laser ranging device. Moreover, by considering the distance
information and speed information detected by the bumper sensor 122, the cliff sensor 123, the
ultrasonic sensor, the infrared sensor, the magnetometer, the accelerometer, the gyroscope, and the
odometer in combination, the application processor can determine the current operation state of
the robot 100, such as whether the robot 100 moves across a door threshold, moves on a carpet,
moves close to a cliff, gets stuck, has a full dust box, is picked up by a user, or the like. The
application processor can also plan the next actions to be performed by the robot 100 based on the
current operation state of the robot 100, such that the operations of the robot 100 can meet the
user's requirement. Furthermore, the control system 130 can plan a most effective and reasonable
cleaning path and/or cleaning mode for the robot, based on the real-time map drawn according to
the SLAM algorithm, so as to greatly improve the cleaning efficiency of the robot.
[0052]            The drive system 140 drives the robot 100 to move on the ground based on a
drive command which includes distance and angle information (e.g., x, y, and 0 components) of
the robot 100. The drive system 140 includes a wheel driving module 141. The wheel driving
module 141 may control a left wheel and a right wheel at the same time. The wheel driving
module 141 further includes a left wheel driving module and a right wheel driving module for
driving the left and right wheels respectively, so as to more precisely control the movement of the
robot 100. The left and right wheel driving modules are oppositely arranged along a lateral axis of
the robot body 110. To improve the stability and/or maneuverability of the robot 100, the robot
100 further includes one or more non-driving wheels 142, for example, one or more universal
wheels. The wheel driving module includes the driving wheel(s), one or more driving motors, and
a control circuit for controlling the driving motor(s). The wheel driving module is also connected
with the odometer and a circuit for measuring the current supplied to the driving motor(s). The
wheel driving module 141 is detachably connected with the robot body 110 for the ease of
maintenance or repair. Each driving wheel has an offset drop-down suspension system, through
which the driving wheel can be fastened on the robot body 110 and kept movable or rotatable. The
driving wheel receives a spring offset extending downward and away from the robot body 110.
The spring offset enables the driving wheel to contact with and grip the ground with a non-zero
force, and the cleaning components of the robot 100 to maintain contact with the ground with a
non-zero pressure.
[00531            The cleaning system 150 may be a dry cleaning system and/or a wet cleaning
system. As a dry cleaning system, the cleaning system includes a sweeping system 151 for
                                                  8

performing the cleaning function of the robot 100. The sweeping system 151 includes a brush roll,
a dust box, a fan, an air outlet, and connection elements for connecting the brush roll, dust box,
fan, and air outlet. The brush roll forms contact with the ground. Dust on the ground is swept and
rolled up by the brush roll to the front of a dust suction inlet located between the brush roll and the
dust box, and then sucked into the dust box by a wind which is generated by the fan and which
passes through the dust box. The dust suction ability of the robot can be presented by the Dust
Pickup Efficiency (DPU). The DPU is determined by many factors, including but not limited to:
the structure of the brush roll and the material for making the brush roll; the efficiency of using the
wind through the wind path formed by the dust suction inlet, the dust box, the fan, the air outlets,
and the connection elements therebetween; and the type and power of the fan. As such, improving
the DPU is a complex system design problem. Compared with common wired-powered dust
cleaners, improving the DPU has more significance to the robot 100, whose power supply is
limited. This is because the improvement of the DPU can directly reduce the energy required by
the robot 100 for cleaning the dust in each unit area. For example, with the improvement of the
DPU, the area that can be cleaned by a fully charged robot 100 may increase from 80 mm 2 to 100
mm 2 or more. Moreover, the improvement of the DPU extends the service life of the battery by
reducing the frequency of recharging the battery, so that the user does not need to frequently
replace the battery. Furthermore, the improvement of the DPU directly affects the user experience,
because users can directly judge if the ground swept or mopped by the robot 100 is clean enough.
The dry cleaning system further includes a side brush 152. The side brush 152 has a rotation axis
forming a non-zero angle with the ground, such that the side brush 152, when rotating, can move
debris into the area reachable by the brush roll of the sweeping system 150.
[0054]             The power supply system 160 includes a rechargeable battery, such as a
nickel-metal hydride battery or a lithium battery. The rechargeable battery is connected with a
charging control circuit, a charging temperature detection circuit, and a low voltage detection
circuit. These circuits are further connected with a single-chip control circuit. The rechargeable
battery is charged by connecting a charging electrode on the side or the bottom of the robot body
to a charging source. If dust is adhered to an exposed charging electrode, charge accumulation on
the charging electrode may be caused, which further causes plastic material around the charging
electrode to be melt and deformed, or even the charging electrode itself to be deformed, thereby
interrupting normal charging.
[0055]             The human-machine interaction system 170 includes a user panel which houses
various buttons for a user to select function(s). The human-machine interaction system 170 also
includes various output devices, such as a display, and/or an indicator light, and/or a speaker, for
indicating the current state of the robot or the function(s) selected by the user. The human-machine
interaction system 170 further includes a mobile client application. For example, if the robot is
capable of path navigation, a mobile client device may display a map of an area surrounding the
robot and mark the position of the robot on the map, so as to provide rich and personalized
information to the user.
[00561             In order to clearly describe the behaviors of the robot, the present disclosure
defines three axes with respect to the robot body 110, and the robot 100 can move on the ground
along the three axes. The three axes are perpendicular to each other and include: a lateral axis x, a
forward-backward axis y, and a vertical axis z. Specifically, the +y direction is defined as the
                                                    9

"forward direction", and the -y direction is defined as the "backward direction". The x axis extends
between the left wheel and the right wheel of the robot and across the center point of the wheel
driving module 141.
[0057]             The robot 100 can rotate around the x axis. When the front part of the robot 100
tilts upward and the rear part of the robot 100 tilts downward, this movement is defined as "nose
up pitch". When the front part of the robot 100 tilts downward and the rear part of the robot 100
tilts upward, the movement is defined as "nose down pitch". In addition, the robot 100 may rotate
around the z axis. When the robot 100 moves in the forward direction, a turn of the robot 100 to
the right side of the +y direction is defined as a "right turning" of the robot 100 around the z axis
to the right side toward the y axis, and a turn of the robot 100 to the left side of the +y direction is
defined as a "left turning" of the robot 100 around the z axis.
[00581             Other embodiments of the present disclosure will be apparent to those skilled in
the art from consideration of the specification and practice of the present disclosure. This
application is intended to cover any variations, uses, or adaptations of the present disclosure
following the general principles thereof and including such departures from the present disclosure
as come within known or customary practice in the art. It is intended that the specification and
examples be considered as exemplary only, with a true scope and spirit of the invention being
indicated by the following claims.
[0059]             It will be appreciated that the present disclosure is not limited to the exact
construction that has been described above and illustrated in the accompanying drawings, and that
various modifications and changes can be made without departing from the scope thereof. It is
intended that the scope of the invention only be limited by the appended claims.
                                                  10

WHAT IS CLAIMED IS:
      1. An automatic cleaning device comprising:
      a collection unit configured to collect a pre-set environment parameter of surroundings of the
automatic cleaning device; and
      an application processor;
     wherein the application processor includes a central processing unit electrically coupled to
the collection unit; the central processing unit is configured to acquire the pre-set environment
parameter collected by the collection unit; the application processor further includes a graphic
processing unit electrically coupled to the central processing unit; and the graphic processing unit
is configured to obtain the pre-set environment parameter from the central processing unit and
then generate a map of the surroundings of the automatic cleaning device based on the pre-set
environment parameter.
     2. The automatic cleaning device of claim 1, wherein the collection unit includes a laser
ranging device ; and distance data between the laser ranging device and surrounding objects,
collected by the laser ranging device, is taken as the pre-set environment parameter.
      3. The automatic cleaning device of claim 2, wherein the laser ranging device includes a
point laser emitter; and the point laser emitter obtains the distance data between the laser ranging
device and surrounding objects by generating a point laser.
     4. The automatic cleaning device of claim 2, wherein the laser ranging device includes a line
laser emitter; and the line laser emitter obtains the distance data between the laser ranging device
and surrounding objects by generating a line laser.
      5. The automatic cleaning device of any one of claims 1 to 4, wherein the collection unit
includes an image acquisition device; and image data of surrounding objects collected by the
image acquisition device is taken as the pre-set environment parameter.
      6. The automatic cleaning device of claim 1, wherein the graphic processing unit includes:
      a memory module configured to store a positioning algorithm based on particle filter; and
                                                   11

      a computing module coupled to the memory module and configured to call the positioning
algorithm and calculate and process the pre-set environment parameter to obtain the map of the
surroundings of the automatic cleaning device.
      7. The automatic cleaning device of claim 1, further comprising a pre-processing unit;
      wherein the pre-processing unit is coupled to the collection unit and the central processing
unit respectively, and is configured to pre-process the pre-set environment parameter, thereby
allowing the central processing unit to obtain the pre-set environment parameter after the
pre-processing.
      8. The automatic cleaning device of claim 7, wherein the pre-processing unit includes a
digital signal processor (DSP).
      9. The automatic cleaning device of claim 1, wherein the automatic cleaning device is a
sweeping robot or a mopping robot.
      10. A cleaning method for an automatic cleaning device comprising:
      a data acquisition step of using a collection unit to collect a pre-set environment parameter of
surroundings of the automatic cleaning device;
      a data pre-processing step of using a pre-processing unit to pre-process the pre-set
environment parameter and provide the pre-set environment parameter after pre-processing to a
central processing unit; and
      a data processing step of providing, by the central processing unit, the pre-set environment
parameter after pre-processing to a graphic processing unit and generating, by the graphic
processing unit, map data of the surroundings of the automatic cleaning device based on the
pre-set environment parameter after pre-processing.
      11. The method of claim 10, wherein the graphic processing unit includes a memory module
and a computing module coupled to the memory module; and the data processing step further
includes:
      calling, by the computing module, a positioning algorithm based on particle filter stored in
                                                   12

the memory module, calculating and processing the pre-set environment parameter after
pre-processing to obtain the map of the surroundings of the automatic cleaning device.
      12. The method of claim 10 or 11, wherein the data acquisition step includes: using a laser
ranging device to collect distance data between the laser ranging device and surrounding objects,
and taking the distance data collected by the laser ranging device as the pre-set environment
parameter.
      13. The method of any one of claims 10 to 12, wherein the data acquisition step includes:
using an image acquisition device to collect image data of surrounding objects, and taking the
image data collected by the image acquisition device as the pre-set environment parameter.
      14. A computer control system for an automatic cleaning device comprising:
     a central processing unit;
     a graphic processing unit;
     a collection unit; and
     a pre-processing unit;
     wherein the central processing unit, the graphic processing unit, the collection unit and the
pre-processing unit are connected through a communication bus; the collection unit is configured
to collect a pre-set environment parameter of surroundings of the automatic cleaning device; the
central processing unit is configured to acquire the pre-set environment parameter collected by the
collection unit; and the graphic processing unit is configured to obtain the pre-set environment
parameter from the central processing unit and then generate a map of the surroundings of the
automatic cleaning device based on the pre-set environment parameter.
      15. A mobile electronic device comprising:
     a communication connection establishment module configured to establish a communication
connection between the mobile electronic device and an automatic cleaning device of any one of
claims I to 9;
     a position instruction sending module configured to send a position information request
                                                  13

instruction to the automatic cleaning device;
      a position receiving module configured to receive position information returned by the
automatic cleaning device once every preset time, wherein the position information includes a
real-time positon of the automatic cleaning device; and
      a display module configured to display the positon information on an in interactive interface
of the mobile electronic device.
       16. The mobile electronic device of claim 15, further comprising a control instruction
sending module configured to send an action request instruction to the automatic cleaning device.
                                                 14

         <removed-apn>   <removed-date>
                                    1/6
Fig. 1

<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
