                                   ABSTRACT
In an implementation, a supplemental sequence parameter set ("SPS") structure
is provided that has its own network abstraction layer ("NAL") unit type and allows
transmission of layer-dependent parameters for non-base layers in a SVC
environment. The supplemental SPS structure also may be used for view
information in an MVC environment. In a general aspect, a structure is provided
that includes (1) information (1410) from an SPS NAL unit, the information
describing a parameter for use in decoding a first-layer encoding of a sequence of
images, and (2) information (1420) from a supplemental SPS NAL unit having a
different structure than the SPS NAL unit, and the information from the
supplemental SPS NAL unit describing a parameter for use in decoding a
second-layer encoding for the sequence of images. Associated methods and
apparatuses are provided on the encoder and decoder sides, as well as for the
signal.

                                10
                                                             1400
       SPS            SUP            18ST LAYER         2ND LAYER
                       sps         ENCODED DATA      EN CODED DATA
            1410        1420                  1430             :1440
                           FIG. 14
ENCODED BITSTREAM         1500                                    1600
   PARSING UNIT                                           ENCODED
    HEADER       ENCODED
    DATA         VIDEO DATA            MEMORY           PROCESSOR
         DECODER1521620
                                                     RECONSTRUCTED
                                                           VIDEO
 RECONSTRUCTED
       VIDEO.FIG.16
  FIG. 15
                                                                1700
        ACCESSING INFORMATION FROM AN SPS NAL UNIT             7
        ACCESSING INFORMATION FROM ASUP SPS NAL UNIT
      HAVING ADIFFERENT STRUCTURE THAN THE SPS NAL UNIT
            ACCESSING AFIRST-LAYER ENCODING AND A
                                                              1730
       SECOND-AYER ENCODING FOR ASEQUENCE OF IMAGES
      GENERATING ADECODING OF THE SEQUENCE OF IMAGES          1740
                           FIG, 17

                                               1
                                     CODING SYSTEMS
    CROSS-REFERENCE TO RELATED APPLICATIONS
           The present application is a divisional application from Australian Patent
    Application No 2015203559 which is a divisional of Australian Patent Application
  5 No 2012238298, which is a divisional of Australian Patent Application No
    2008241568, the entire disclosure of each of which is incorporated herein by
    reference.
    TECHNICAL FIELD
           At least one implementation relates to encoding and decoding video data in
10  a scalable manner.
    BACKGROUND
           Coding video data according to several layers can be useful lwhen
    terminals for which data are intended have different capacities and therefore do
    not decode a full data stream but only part of a full data stream. When the video
15  data are coded according to several layers in a scalable manner, the receiving
    terminal can extract from the received bit-stream a portion of the data according to
    the terminal's profile. A full data stream may also transmit overhead information
    for each supported layer, to facilitate decoding of each of the layers at a terminal.
    SUMMARY
20         According to a first aspect, the present invention provides a decoder
    comprising:
    a parsing unit to receive
           information in a first parameter set contained in a first network abstraction
           layer unit, the first parameter set being a syntax structure which contains
25         syntax elements that apply to zero or more entire coded video sequences,
           and the information describing a parameter for use in decoding multiple
           layers of the video sequences, and
           supplemental information contained in a second network abstraction layer
           unit, the second NAL unit having a different syntax structure than the first

                                             1A
           network abstraction layer unit and corresponding to one layer of said
           multiple layers; and
   a decoding unit to decode said one layer of said multiple layers based on, the
   accessed information from the first NAL unit and the accessed supplemental
 5 information from the second NAL unit.
          According to a second aspect, the invention provides a method comprising:
   receiving information in a first parameter set contained in a first network
   abstraction layer unit, the first parameter set being a syntax structure which
   contains syntax elements that apply to zero or more entire coded video
10 sequences, and the information describing a parameter for use in decoding
   multiple layers of the video sequences;
   receiving supplemental information contained in a second network abstraction
   layer unit, the second NAL unit having a different syntax structure than the first
   network abstraction layer unit and corresponding to one layer of said multiple
15 layers; and
   decoding said one layer of said multiple layers based on, the accessed
   information from the first NAL unit and the accessed supplemental information
   from the second NAL unit.
          According to a third aspect, the present invention provides an encoder
20 comprising:
   a generation unit to generate
           information in a first parameter set contained in a first network abstraction
           layer unit, the first parameter set being a syntax structure which contains
           syntax elements that apply to zero or more entire coded video sequences,
25         and the information describing a parameter for use in decoding multiple
           layers of the video sequences, and
           supplemental information in a second network abstraction layer unit, the
           second NAL unit having a different syntax structure than the first network
           abstraction layer unit, the second NAL unit corresponding to one layer of
30         said multiple layers; and

                                            1B
   an encoding unit to encode said one layer of said multiple layers based on the
   generated information for the first NAL unit and the generated supplemental
   information for the second NAL unit.
          According to a fourth aspect, the present invention provides a method
 5 comprising:
   generating information in a first parameter set contained in a first network
   abstraction layer unit, the first parameter set being a syntax structure which
   contains syntax elements that apply to zero or more entire coded video
   sequences, and the information describing a parameter for use in decoding
10 multiple layers of the video sequences;
   generating supplemental information in a second network abstraction layer unit,
   the second NAL unit having a different syntax structure than the first network
   abstraction layer unit, the second NAL unit corresponding to one layer of said
   multiple layers; and
15 encoding said one layer of said multiple layers based on the generated
   information for the first NAL unit and the generated supplemental information for
   the second NAL unit.
   According to a fifth aspect, the present invention provides a signal having
   decoding parameters, the signal formatted to comprise:
20 information from a first parameter set contained in a first network abstraction layer
   unit, the first parameter set being a syntax structure which contains syntax
   elements that apply to zero or more entire coded video sequences, and the
   information describing a parameter at least for use in decoding multiple layers of
   the video sequences;
25 supplemental information from a second NAL unit having a different syntax
   structure than the first network abstraction layer unit, the second NAL unit
   corresponding to one layer of said multiple layers; and
   data representing said one layer of said multiple layers.

                                          1C
  According to a general aspect, information is accessed from a sequence
  parameter set ("SPS") network abstraction layer ("NAL") unit. The information
  describes a parameter for use in decoding a first-layer encoding of a sequence of
5 images. Information is also accessed from a supplemental SPS NAL unit having
  a different structure than the SPS NAL unit. The------------------------

                                           2
   information from the                  SPS NAL unit describes a parameter for
                                       Iupplemental
   use in decoding a second-layer encoding of the sequence of Images              A
   decoding of the sequence of Images |is generated based on the first4ayer
   enCoding, the second4ayer encoding the accessed information fromt the SPS
 6 NAL unit and the accesseddenformation from the supplemental SPS NAL unit.
          According to another general aspect a syntax structure       li used that
   provides for decoding a sequence of images in multiple layers         The syntax
   structure includes syntax for an SPS NAL unit including information describing
   a parameter for use in decoding a firstlayer encoding of a sequence of
   images..
    0        Thed syntax structure also includes syntax for a supplemental SPS
   NAL unit having a different structure than the SPS NAL unit. The
   supplemental SPS NAL unit includes information desenbing a parameter for
   use in decoding a second-layer ending of the sequence of images. A
   decoding of the sequence of images may be generated based on the first.
15 layer encoding, the second ayer encoding, the information from the S'SP NAL
   unit and the informationfrom the supplemental SPS NAL unit.
          According to another general aspect, asignt is formatted to include
   information froan SP'NL unit The information describes a parameter for
   use in decoding a first-layer encoding of a sequence of images. The signal is
20 further formatted to include information from a supplemental SPS NAL unit
   having a different structure than the SPS NAL unit The information from the
   supplemental SPSi NAL iet describes a pararnter for use in decoding a
   secondplayer encoding of the sequence of images
          According to another general aspect, a SPSNAL units generated that
25 includes information desibing a parameter for use An decoding a first-layer
   encoding of a sequence of images.            A supplemental SPS NAL unit is
   generated that has a different structure than the SPS NAL unit.             The
   supplemental $PS NAL oit includes information that describes a parameter
   for use in decoding a second-layer encoding of the sequence of images A
 0 set of data is provided that includes the firstayer encoding of the sequence of
   Images, the second-layer encoding of the sequence of imagesthe SPS NAL.
   unit and the supplemental SPS NAL unt

                                            3
            According to another general aspect, a syntax structure is vsed that
     provides for encoding a sequence ef image in multiple layers. The syntax
    structure includes syntax for an: SP$ NAL uit. The SPS NAL unit includes
     information that describes a parameter for use in decoding a first-layer
 5   encoding of a sequence of images, The syntax structure includes syntaxfor a
     supplemental SPS NAL unit The supplemental SPS NAL unit has a different
     struture than the SPS NAL unit. The supplemental SPS NAL urit includes
    information that describes a parameter for use in decoding a second-yer
     encoding ote sequence of imaes. A set of data may be provided that
10  includes the first-layer encoding of the sequen-e of imagesthe seco.d-layer
    encoding of the sequence of Imagesthe SPS NAL unit and the supplemental
     SP NAL unit.
            According to another general aspect, fArst laye-dependent information
     is accessed in a first normal parameter set The accessed first layer
15.dependent information is for use in decoding a first-tayer encoding vf a
    sequence of images Second layerdependen information is accessed in a
    second normative parameter set. The second normative parameter set has a
    different structure than the first normative parameter set The acteosed
    second layer-dependent information is for use in decoding a secondlayer
20 encoding of the sequence of images. The sequence of images is decoded
    based on one or more of the accessed first layerlependent information or the
    accessed second layerlependent information.
           According to another general aspect first normative parameter set is
    generated that includes first layer-dependent information The first layer
25  dependent information is for uose in decoding a first-layer encoding of a
    sequence of images. A second normatiVe parameter set Is generated having
    a different structure than the first normative parameter set. The second
    normative parameter set includes second ayier-dependent infrmation for use
    in decoding a second-layerencoding of the sequence ofimages. A set of
30  data is provided that includes the first normative parameter set and the
    second normative parameter set

                                              4
            The details of one or more implementations are set forth in the
    accompanying Mdawings and the description beow. Even if descrbed in one
    particular manner, it should be clear that implementations maybe configured or
    embodied in varIous manners, For example, an implementation may be
 S performed as a method, or em0bodied as an apparatus, such as for example, an
    apparatus confgired to perform a set of Qperations or an apparatus stonng
    instructions for performing a set of operations, or embodied in a signal. Other
    aspects and features will become apparent from the following detailed
    description considered in conjunction with the accompanying drawings and the
10  claims.
    BRIEF DESCRIPTiON OF THE DRAWINGS
            FIG.,Is a block diagram for an implementation of an encoder.
            FIGI1A is block diagram fo anotherimplementation of an encoder.
15          FIG. 2 is a block diagrarfor an implementation of a decoder.
            FIG. 2a is a back diagiram for another ilemnmentationi of a decoder.
           -FIG:3 is a sttutture of an implementation of a Single-Layer Sequence
    Parameter Set (5PS") Network AbstractionLayer (NAL") unit4
            FIG. 4 is a:bock view of an         example of portions of a data stream
20; llustrating use of an SPS NAL unit.
            FIG. 5 is a structure of an"implementation of a supplemental SPS
    (CSUP SPS'1 NAL unit
            FIG. 5 is an implementation of an organizational hierarchy among an
    SPS unit and multiple SUP SPS units.
25          FIG. 7 is a structure of another implementation of a SUP SPS NAL unit.
            FIG. 8 is a functional view of an implementation of a scalable video
      ode that generates SUP SPS units.
            FIG.91is a hierarchical view of an implementation of the generation of a
    data.stream that contains SUP SPS units.
30          FIO 10 is - block view of an example of a data stream generated by
    the implementation of FIG 9,
            FIG. 11 is a block diagram of an irnplementation of an encoder

                                            5
            FIGO 12 is a blok diagram of another implementation of an ehcoder.
            FIG. A is a flow chart of an implementation of an encoding process
   used by the encoders of FIGS: II or12,
            FIG+-14 i a block view Of an example of a data steam geterated by
 5 the process of FIG. 13,
            FIG. 15 is a block diagram of anirplementation of a decoder,
            FIG. 16 is a block diagram of another implementation of a decoder.
            FIG.17 is a fow hart of an implementation of a decoding process
   used by The decoders ofFIG. 15 or1
10
   DETAILEO DESCRIPTION
            Several video coding standards exist today that cancode video data
   according to different layers and(r profiles. Among them, one can cite
   H264/MPEG-4 AVC (the "AVC standard also referenced as the
15  international Organization for Standardization/International Flectrotechnical
   Commission QSOEC) Moving Picture Experts Group 4 (MPEG-4) Part 10
   Advanced Video Coding (AVC) setndardllnternetional Teleommunication
   Union, Teecommunication Sector ITU T) Ha24 recommendation
   Additionally:,extensions to the AVC standard exist. A first such extension is a
20    8oalable video coding (SVC'y extension (Annex G) referred to as
   H264/MPEG-4 AVC, scalable video coding extension (the "SVC extension").
   A second such extension is a mqltviiw video coding               VC"J)extension
   (Annex H) referred to as H264/MPEG-4 AVC, MVC extension (the "MVC
   extenstion")
            2 Atleast one implementation described In this disclosure may be used
   with the AVC standard as well as the SVC and MVC extensions. The
   implementation provides a supplemental ($"UP") sequence parameter set
   ("SPSt1).network abstraction layer ("NAL") unit having a different NAL unit type
   than SPS NAL units. An SPS unit typically Includes but need not, information
30 for at least a single layer. Further, the SUP SPS NAL unit includes layer
   dependent Jnformation for at least one additional layer Thus by accessing

                                              6
    SPS and SUP SPS units, a decoder has available certain (and typically 01
    layerdependent information:needed to decode A bit stream.
            Using this implementation in an AVG system, the SUP SPS NAL unts
    need not be transmitted, and a single-layer SPS NAL unit (as described
 5  bel'w) may be transmitted. Using this implementation in an SV (or MVC)
    system, the SUP SPS NAL units) may be transmitted for the desired
    additional layers (or views in additon to an SPS NAL unit. Using this:
    implementation in a system inUding both AVC-ompatible decoders and
    SVC-compatible (or MVC-compatible) decoders, the AVC-compatible
10  decoders may ignore the SUP SPS NAL units by detecting the NAL unit type
     Ineach case, efficlenty and compatibility are achieved.
             The above implementation          also provides benefits for systems
     (standards or otherwise) thatimpose a requirement that certain layers share
     header information, such as; for example, an SPS or particular information
15  typically carried in an PS For example, if a baseIayer and its composite;
     temporal layers need to share an SPS, then the layer-dependent information
     cannot be transmitted with the shared SPS However, the SUP SPS provides
     amechanism for transmitting the layer-dependent information.
             The SUP SPS of various implementations aso provides an ,fficiency
20   advantage in that the SUP SPS need not chlude, and therefore repeat, all of
     the parameters in the SS         The SUP SPS will typically be focused on the
     layer-dependent parameters However, various implementations include a
     SUP SPS structure that includes non-layer-dependent parameters, or even
      repeats all of an SPS structure.
28           Various implementations (elate to the SVC extension. The SVC
     extension proposes the transmission of video data according to several spatial
     levels, temporal levels,and quality levels. For one spatialIevelone can code
      according to several temporal levels, and for each temporal level according to
      several quality levels. Therefore, when there are defined m spatial levels, n
30:temporalevels and 0 quality levels thevideo data cn be coded according
      to m*n"O different combinations. These combinations are referred to a
      layers, or as interopertbility points ("lOPan) According to the decoder (also

                                            7
    referred to as the receiver or the Olient) capabilities, different layers may be
    transmitted up to a certain layer corresponding to the maximum of the client
    capabilities:
            As used herein "layer-dependent" information refers to informationthat
 5  relates specificaly to a single layer, That is, as the name suggests, the
    information is dependent upon the specific layer. Such information need not
    necessarily vary from layer to layer, but would typically be provided separately
    for each layer.
            As used herein. "high level syntax refers to syntax present in the
10  bitstream that resides hierarchically above the macroblock laye              For
   exam-ple, high levet synta as used herein may refer to, but is notlimited to
   syntax at the slice header levl,Supplemental Enhancement Information (SEl)
    lvel, Piture Parameter Set (PPS) level Sequence Parameter Set (SPS)
   level, andNetwork AbstractionLayer (NAL) unit headerleve
15          Referring to FI. 1an exemplary SVC encoder is indicated generally
   by the reference numeral 100. The SVC encoder 100 may aso be used for
   AVC encoding, that is, for a single layer (for exarmpte, base layer), Further
   the SVC encoder 100 may be used for V encoding as one of ordinary skll
    in the art will appfeiate.     For example various components of the SVC
20 encoder 100, or variations of these components, may be used In coding
   multiple views.
            A first output of a temporal decomposition module 142 is connected in
   signal communication with a first input of an intra prediction for intra block
   module 146. A second output of the temporal decomposition module 142 is
25 connected in signal communication with a first input of a mion coding
   Module 144. An output of the intra prediction for intra block module 464 is
   connected in signal communication with an input of a transformientropy coder
   (signal to noise ratio (SNR) scalable) 149,              A first output of the
   transfrmentropy coder149 is connected in signal communication with a first
30 input of a multiplexer177O.
           A first output of a temporal decorposition module 132 is connected in
   signal communication with a first input of an intra prediction for intra block

     odule 136 A second output of the temporal decomposition module 132 is
   connected in signal communication with a first input Of a. motion oding
   modulOe 134. An output of the intra prediction for intre block module 136 is
   connected in signal communication with an input of a transform/entropy coder
 5 (signal to noise ratio {SNR) scalable) 139.           A first output of the
   transfomentropy coder 139 is connected in signal communication with a first
    input ofo multiplexer 170.
            A second output of the traisform/entropy coder 149 is connected in
   signal communication with an input of a 2D spatial interpolation module 138.
10 An output of 2D spatial interpolation module 138 is connected in signa
   communication with a second iput of the intra prediction for intra bock
   module 136. A second output of the motion coding module 144 is connected
   in signal communication with an input of the motion coding module 1
            A first output of a temporal decomposition module,122 is connected in
15 signal communication with a first input of an intra predictor 126. A second
   output of the temporal decomposition module 122 is connected in signal.
   communication with first input of a motion coding module 124. An output of
   the intra predictor 126 Is connected insignal communication with an input of a
   transform/entropy coder (signal to noise ratio(SNR) scalable) 129. An output
20 of the transformlentropy coder 129 is connected in signal coinuication with
   a first input of a multiplexer 170,
            A second output othe transform/entropy coder 139 is conneted in
   signal communication with an input ofa 20 spatial interpoltion module 128
   An ou~itput of 20 spatial interpolation module 128 is concted in signal
25 communication with a second input of the intra predictor module 126 A
   second output of the motion coding module I34 is connected In signal
   communication with an inputof the motion coding module 124.
            A first output of the motion coding modue 124, a first output of the
   motion coding module 134, and a first output of the motion coding module 144
30 are each connected in signal communication with a second input of the
   multiplexer 170.

                                            9
          A first output of a 2D spatial decimation module 104 is connected in
   signal communication with an input of the temporal decomposition module
   .132. A second output of the 20 spatial decimation module 1041is corActed
   in         common cation    with an input of the temporal decomposition module
                           .ignal
 5  142,
          An :nput of the temporal decomposition module 122 and an input of the
   20 spatial decimation module 104 are available as inputs of the encoder 100:
   for receiving input video 102.
          An output of the multiplexer 170 is available; as an output of the
10 encoder 100, for providing a bitstream 180.
          The temporal decomposition module        122, the temporal decomposition
   module 132 the temporal decomposition module 142, the motion Coding
   module 124, the motion coding module 134, the moon coding module144
   the intra predictor 126, the intra predictor 136, the intra predictor 146, the
f5 transform/entropy coder 129 the transformtentropy coder 139, the
   transformeptropy coder 149, the 21) spatial interpolation module 128 and the
   2D spatial interpolttion module 138 are included in a core encode6 portion
   }87 of the encoder 100.
           FIGA 1 includes three core encoders 187. In the implementation
20 shOwn, the bottom-most core encoder 187 mtay encode a base layerWith the
   middle arnd upper core encoders 187 Oncoding higher layers,
          Turning to FIG. 2, an exemplary SVC decoder is indicated generally by
   the reference numeral 200. The SVC decoder 200 may ao be used for AVC
   decodinthat is,, for a single viw Further the SVC decoder 200 may be
25 used forMVC decoding as one ofoMdinary skill inthe art will appreciate. For
   example, various components of the SVC decoder 200 o variations of these
   componentsmay be used in decoding multiple views
           Note that encoder 100 and decoder 200, as well as other encoders and
   decoders discussed in this dislosure, can beconfigured to perform various
30 methods shown throughoutthis disclosure. In addition to performing encoding
   operations the encoders descrbed in this disclosure may perform various
   decoding operations during a reconstruction process in order to mkror the

                                            10
   expected actions of a decoder. For example, an encoder may decode SUP
   BSI'units to decode encoded video data in order to produce a reconstruction
   of the encoded video data for use in predicting additional video data.
   Consequently, an encoder may perform substantially all of the operations that
 S are performed by a decoder.
            Ant input of a demultiplexer 202 is available as an input to the scalable
   video decoder 200, for receiving a scalable bitstream. A first output of the
   demnultipiexer 202 is connected in signal communication with an input of a
   spatial inverse transform SNR scalable entropy decoder 204, A first output of
10 the :spatial inverse transform SNR scalableentropy decoder 204 is connected
   in signal communication with a first input of a predictions moadule 206. An
   output of the prediction rmodule 206 is connected irn signal communication With
   a ftat input of a combined 230.
            A second output of the spatial irnverse transform SNR scalable entropy
15 decoder 204 is connected in signal communication with a first input of a
   motion vector (MV) decoder 210. An output of the MV decoder 210 is
   connected in signal commurnicationt with an input of a motion compensator
   232; An output of the motion compensator 232 is connected irt signal
   communication with a second Input of the combiner 230.
20          A second output of the demultiplexer 202 is connected i~n signal
   cormmunicatton with an input of a spatial inverse transform SNR scalable
   entropy decoder 212. A first output of the spatial inverse transform $NR
   scalable entropy decoder 212 is connected in signal communication with a
   fist input of a prediction module 214. A first output of the prediction module
25  214 is connected irn signal communication with an input of an interpolatiorn
   module 216. An output of the interpolation module 216 is connected in signal
   communication with la second input of the prediction module 206. A second
    output of the prediction module 214 is connected in signal communication with
   a first irnput of a combiner 240.
30          A second output of the spatial inverse transform SNR scalable entropy
    decoder 212 is connected irn signal communication with a first input of an MV
    decoder 220. A first output of the MV decoder 220 is connected in signal

   communication with a second input ofte MV decoder 210. A second output
   of the MV decoder 220 is connected in signalcommunication with an input of
   a motion compensator 242. An output of the motion compensatory 242 is
   connected in signal communication with a second input of the combiner 240.
 5         A third OutpUt of the demrultitlxer 202 is connected in signal
   communication with an input of a spatial inverse transform SNR scalable
   entropy decoder 222. A first outpt of the spatial inverse transform SNR
   scalable entropy decoder 222 is connected insignal communication with an
   input of aPrediction module 224 A first output of the prediction module 224 is
10 connected in signal cmmunication with an input of an interpolation module
   226; An output of the interpolation module 226 is connected in signal
   communication with a second input of the prediction:module 2i4,
           A second output of the prediction module 224 is connected in sinal
   coniunication with a first input of a combiner 250 A second output of the
15 spatial inverse transform SNR scalable entropy decoder 222 is connected in
   signal communication with an input of an MV decoder 230. A first output of
   the MV decoder 230 is connected in signal communication with a second
   input of the MV decoder 220. A second output of the MV decoder 230 is
   connected in signal communication with an input of a motion compensator
20 252. An output of the motion compensator 252 is connected in signal
   communication with a second input of the combiner 250.
           An output of the comjner 250 is available as an output of the decoder
   200, or outputting a layer 0.:ignal., An output ofthe combiner 240 is available
   as an output of the decoder 200, for outputting a layer 1 signaL An output of
25 the combiner 230 is available as an output of the decoder 20 for outputting a
    layer 2 signal.
           Referring to FIGIa, an exemplary AVG encoder is indicated generally
    by the reference numeral 2100. The AVC encoder 2100 may be used, for
   example( for encoding a single layer (for example, base layer)
30         The video encoder 210 includes a frame ordering buffer 2110 having
    an output in signal communication with a non-inverting input of a combined
   2185. An output of the combined 2185 is connected in signal communication

                                             12
   with a first input of a transformer and quantizer 2125. An output of the
   transformer and quantizer 2125 is connected in signal mmunication with a
   fi-At input of an entropy coder 2145 and a first input of an inverse transformer
   and inverse quantizer 2150. An output of the entropy code 2145 is
 5 connected in signal communication with a first non-hverting input of a
   combiner 2190. An output of the combined 2190 is connected in signal
   commrnricatidnwith a fist input of an output buffer 2135
           A first output of an encoder controller 2105 isdnnected in :signal
   communication with a second input of the frame ordering buffer 2110 a
10 second input of the inverse transformer and inverse quantizet2150, an input
   of a picture-type decision module 2115, an input of a macrbtock-4ype MB
   type) decision module 2120, a second input of an intra prediction module
   2160, a second input of a deblocking filter 2165, a first input of a motdo
   compensator 2170, a first input of a motion estimator 2175, and a second
15 input f a reference picture buffer 2180.
           A second output of the encoder controller 2105 is connected in signal
   communication with a first input of a Supplemental Enhancement information
   ("SEl") inserter 2130,:a second input of the transformer and quantizer 2125 a
   second input of the entropy coder 2145a second input of the output buffer
20 2135Jand an input of the Sequence Parameter Set ($PS) and Pipture
   Parameter Set (PPS) inserter2140k
           A first output of the picture-type decision module 2115 is connected in
   signal communicton with a third input of a frame ordering buffer 2110. A
   second output of the pictureype decision modute 2115 is connected in s.tnol
25 communication with a second input ofa macroblock-type decision module
   2120.
           An output of the Sequence Parameter Set (SPS) and Picture
   Parameter Set ("RPS" inserter 2140 is connected in signal Communication
   with a third non-inverting input of the ombiner 2190, An output of the SEl
30  inserte 2130 is connected in signal communication with a second none
   inverting input of the combiner 2190,

                                          13
           An output of the inverse quantizer and inverse transformer 2150 is
   connected n algnat      communication with a first non-invertng input of a
   combined 2127. An output of the combined 2127 is connected i gna
   communication with a first input of the intra prediction module210 and a first
 5 input of the debocking filter 2165. An output of the deblockingfilter 2165 is
   connected in signal communication with a first input of a reference picture
   buffer 2180, An outputof the reference picture buffer 2180 is connected in
   signal communication with a second input of the motion estimator 2175 and
   with a first input of a motion compensator 2170. A first output of the motion
10 estimator 2175 is connected in signal ommunication with a second input of
   the motion compensator 2170. A second output of the motion estimator 2175
   is connected in signal communication with a third input of the entropy coder
   2145
           An output of the motion compensatory 2170 is cornneted in0sghal
15 communication with a first input of a switch 2197, An:.utput of the intra
   prediction module 2160 is connected in signal communication with a second
   input of the switch 2497. Ah    output of the madroblock-type decision module
   2120 is connected in signal communiation with a thrd input of the switch
   2197 in order to provide a control input to the witch 2197. An output of the
20 switch 2197 is connected in signal communication with a seond non-inverting
   inputof the combiner 2127 and with an Inverting inputOf the combiner 21 85,
            nputs of the lame ordering buffer 2110 and the encoder controller
   2105 are available as input of the encoder 2100 for receiving an input picture
   2101. Moreover, an input of the SESinserter 2130 is avaable as an input of
25 the encoder 2100, for receding metadata. An output of the output buffer 215
   is available as an outputof the encoder 2100, for outputting a bitsirmam,
           Referring to FIG. 2a, a video decoder capable of performing video
   decoding in accordance with the MPEG-4 AVC standard is indicated generally
   bYthe reference numeral 2200.
30        The video decoder 2200 includes an input buffer 2210 having an output
   connected in signal communication with a first input of an entropy decoder
   2245. A fitst output of the entropy decoder 2245 is connected in signal

                                            14.
    communication with a first input of an inverse transformer and inverse
    quantizer 2250. An output of the inverse transformer and inverse quantizer
    2250 is connected in signa comrhunication with a second on-invrting input
    of a combined 2225. An output of the combiner 2225 is connected in signal
 5 communication with a second input of a deblocking filter 220 and a first input
    of an ira prediction module 2260. A second output of the deblocking fiter
    2265 is connected in signal communicaon with a first input of a reference
    picture buffer 2280. An output of the reference picture buffer 2280 is
    connected in signal communication with a second input of a motion
10 compensator 2270.
            A second output of the entropy decoder 2245is connected in signal
    communication with a third nput of the motion compensator 2270 and a first
    input of the deblocking filter 225. A third output of the entropy decoder 2245
    is connected in signal communication with an input of a decode controller
15 2205. A first otput of the decoder COntroller 2205 is connected in signal
    communication with a second input of the entropy decoder 2245. A second
     output of the decoder controller 2205 is connected in signal communication
    with a second input of the inverse transfomer and inverse quantizer 2250. A
     third output of the decoder controller 2205 is connected n signal
20 communication with a third input of the deblocking filter 2265. A fourth output
     of the decoder controller 2205 is connected signal communication with a
     second input of the intr prediction module 2260, with a fist iput of the
     motion compensator 2270, and with a second input of the reference picture
     buffer2280.
25          An output of the motion compensatory 2270 is connected in signal
     communication With a first input of a switch 2297. An output of the intra
     prediction module 2260 is connected in signal communication with a second
     input of the switch 2297. An output of the switch 2297as connected in signal
       emmuricl'tion with a first noninverting input of the combiner 2225.
 30          An input of the input buffer 2210 is available as an input of the decoder
     2200, for receiving an input bitstream. A first output of the deblocking filter

   2265 is available as an output ofthe decoder 2200, for outputting an output
   picture.
            Referring to FIG. 3, a stru ture forsinglelayer SPS $00 is shown.
   SP$ is a syntax structure that generally contains syntax elements that apply
 5 to zero or more entire oded video sequences in the SVC extension the
   values of some syntax elements conveyed in the SPS are ayer dependent
   These tayer-dependent syntax elements include but are not limited to, the
   timing information, HRD (standing for 'Hypothetcal Reference Decoder")
   parameters, and bitstream restriction information. HRD parameters may
10 include, for example, indicators of buffer size, maximum bitrate, and initial
   delay. HRD parameter may allow a receiving system, for example to verify
   the Integrity of a received bit stream and/or to determine f the receiving
   system (for example, a decoder)can decode the bit stream. Therefore, a
    sstem may provide for the transmissio of: the aforementioned yntax
15  elements for each layer.
            The dinglerlayer SPS 300dnludes an SPS4D $10 that provides an
    identifier for the SPSi The singledayer SPS 300 also includes tte VUI
   (standing for Video Usability Infomation) parameter 320 for a single layer.
    The VUI parameters include the HRD parameters 330 for a single layer, such
20  as, for example, the base layer. The singlelayer SPS 300also may include
    additional parameters 340, although implementation need not include any
    additional parameters 340.
            Referrng to FIG4 a block view of a data stream 400 shows a typical
    use of the single-layer SPS 300 In the AVC standard* for example, a typical
25  data stream may include, among other components. an SPS unit multiple
    PPS (picture parameter sequence) units providing parameters for a particular
    picture and mutiple units for encoded picture data         Such a general
    framewod, is followed in FIG4,which includes the SPS 300, a PPS-I 410,
    one or more units 420 including encoded picturedI data, a PPS2 430, and
30  one or more units 440 including encoded picture-2 data, The PPS-1 410
     includes parameters for the encoded picture-I data 420, and the PPS-2 430
     includes parameters for the encoded picture-2 data 440.

                                            10
           The ended pictue-I data 420.,and the ended piures2 date 440,
   are each associated with a particular Sf'S (the PS 300 in the implementation
   of FIG. 4). This is achieved through the use of pointers, as now explained.
   The encoded pictures data 420:includes a PPS4D (not shown) identifying the
 5 PPS-1410, as shown by an arrow 40. The PPS40 may be stored in, for
   example a slice header; The encoded picture-2 data 440 includes a PP$-ID
   (not shown) identifying the PP$-2 430',as shown by an arrow 40. The PPS
   1 410 and the PPS-2 430 each include an SPSlDl (not shown) identifying the
   SP'S 300, as shown by arrows 470 and 480 respectively.
10         Refening to FIG. 5 a structure for a SUP SPS 500 is shown. SUP
   SPS 500 includes an SPS 10 510, a VUI 520 that includes HRD parameters
   530 f4or a single additional layer referred to by (2, T2, Q2 and optional
   additional parameters 540+ "D2, T2, 02" -refers: t a second layer having
   spatial (D) level 2, temporal (T) level 2. and qafity (0) level 2.
15         Note that various numbering schemes may be used to referto layers
   in one numbering scheme, base layers have a,i T, Q of 0, X 0, meaning a
   spatial   eval of zerolany temporal level, and a quanty level of zero. In that
   numbering scheme,:enhancementlayers have a D T,              in which D or Q are
   greater than zero.
20         The use of SUP SPS 500 allows for example, a system to use an POSs
   stncture that only includes parameters for a single layer, or that does not
   include any layer-dependent information. Such a system may create a
   separate SUP SPS for each additional layer beyond these layer; The
   additional layers can identify the SP$ with which they are associated through
25 the use of the SRS 10 S        Cleardy several layers can share a single SPS by
   using a common SPS ID in theft respective SUP SPS units.
           Referring to FIG. 6, an organizational hierarchy 600 is shown among
   an NSP unit 605 and multiple SUP SPSunits 610 and 620$ The UP SPS
   units 610 and 620 are shown as being single-layer SUP SPS units, but other
30 implementations may use one or more multiplelayer SUP SPS units in
   addition to, or in lieu of, single-layer SUP SPS units. The hierarchy 600
   illustrates that, in a typical scenario, multiple SUP SPS units may be

                                           17
   associated with a single SPS uMit implementations may, of course, include
   multiple SPS units, and each of the SPnitsits may have associated SUP SPS
   units.,
           Referring to FIG, 7, a structure for another SUP SPS 700 is shown.
 5 SUP SPS 700 includes parametersmfor multiple layers, whereas SUP SPS 600
   includes parameters for a single layer. SUP $PS 700 includes an SPS ID
   710, e      IVU720, and optional additional parameters 740. The VUI 720
   includes HRD parameters 730 for a first additional layer (02; T2, 02) and for
   other-additional layers up to layer (Dn, Tn, Qn),
10         Referring again to FIG. 6, the hierarchy 600 may be modified to usea
   multiple layer SUP SPS. For example, the combination of the SUP SPS 610
   and 620 may be replaced with the SUP SPS 700 if both the SUP BPS 610
   and 620 include the same SPS ID,
           Additionallyhe SUP SPS 700 may be used, for exaniple ith an SPS
1$ that includes parameters for a single layer, or that includes parameters for
   mutiple layers, or that does not include lyer-dependent parameters for any
   layers. The SUP SPS 700 allows a system to provide parameters for multiple
   layers with little overhead,
            Other inpementations may be bsed, fo example, on an SP$ that
20 Includes all the needed parameters for -all possible layers. That is, the SPS of
   such an implementation includes all the corresponding spatial (Di),Iporal
   (T), and quality (Q) levls that are available to be transmitted, wther       a
   layers are transmitted or not. Even with such a system, however, a SUP SPS
   may be used to provide an ability to change the parameters fo one or more
25 layers without tansmitting the entire SPS again.
            Referring to Table 1,syntax is provided for a specific implementation of
    a singled4ayer SUP SPs. The syntax includes sequencejparameter_setd to
   identify the associated SPS, and the identifiers of temporaLtevel,
    dependencyjd, and qualityjevel to identify a scalable layer.           The.VU?
30  parameters are included through the use of sVc.ui1parareters() (see Table
    2), which includes HRD parameters through the use of hrdparameters( The

     syritax below allows each layer to specify its own layer-dependent
     parameters, such as, for example, HRD parameters.
      sup-eqra tergsetsv(                                                C     DrrIptr
           sequeneopaameter set d                                        0      e()
            qarmpnriI!eve                                                0      (3
           qutality.l   I                                                      u~
              svcv r. metmarnnts()
   S                                 sqtlag)
                          utparameters                          OLSres. kt
             .5                                  Table I
     The semantics for the syntax of sup Seqparameter set 5sc( is as follows.
                sequenceparameter_setd identifies the sequence parameter set
10   which the current SUP SF'S maps to for the current layer;
                  temporaijevel,       dependencyid,    and qualityevel specify the
     temporal level dependency identifier, and quality level for the current layer.
      Dependencyid generally indicates spatial level.          However. dependenoyJd
     also is used to indicate the Coarse Grain Scalability ("CGS') hierarchy, which
15   includes both partial and SNR scalability, with SNR salability beipg a
      traditional quality scalabitity     A4cordingly qualityjeveiand dependegcyjd
      may both be used-to distinguish quality levels.
                   vuparameterspresentsvqflag            equals  to  1 specfies tbat
      svc_vu[ parameters()         syntx structure as defined       below is present
20    vuiparameters_present avt flag             equals     to    0    specifies    that
         efuparameters() syntax structure is not present
               Tble 2 gives the syntax for svjuiarameterso,                    The VAl
      parameters are therefore separated for each layer and put into individual SUP
25    SPS units Other implementations, however, group the VU parameters for
      multiple layers into a single SUP SFS.

                                                                                           I18O
                                   svciuj~ratnter()                            C    Dscrp~0
            nurn unitsin lick                                                          2.
            0Xinx         e-te                                                      uling
        nag:l_lnramtters pmcent.j.g n____00)
        It( na tirpn646me trt,.6prwntj~~
            hrd Jgamieter7(
        vicstresent                       lag                                  0tU(9
        bitr' .rd pmstrictirnfli                -c*Lh~ prae(mpi)n               0
            nitruonct-rs            oerktotndfaga                               0uf
              i~xbytes.erjic dnom                                               0Ueqv)
                inab ts..per Mb44 ,n                                            0    eov
                 IogZ~nvngh~rzna                                                     .ev
                                                   Table 2
   5 Th fie'10's ofite                .V ip atameters() s$yntaxof Table 2arei defined inh e..
      verionof he VCextfensionth. exste"inAp61-2007 ude                                  '7TU20.1
      Amnex E E. 1. in priclr:                       rjrmtrs)i          sdfined fom the AVC
     standard. Note alO that voupRaetr(inldsviosay
           deenen nformation, includ n FDreMated parameters The HRD-related
10   parameters inGlUdO nUm Units, In tiC'k,ftme scaife, fixed frameja;tejag-,
     na  1hrd-parametesyresetjlag,
                                                            vcl hrd parameters.reetaq
     brdO.pararneterst), owdeay                rdj lag, and pic_sruct-presentjtag. Further,

                                                    20
    the syntax eemeris in the btsrear estrictionj)ftg if l p                           layera
                                                                                      1re
    dependent evenhoghnot HRD-related
               As mentioned aboVe the SUP SP$ isdefined as a new type of NAL
    unit. Table 3 lists some of the NA..unit codes as defined by the standard
 S  J/T-U2,01 but modified to assign type 24 to the SUP SPS The einpis
    between NAL unit types and 16. ahdbotween 18 and24 indicate that those
    types are unchanged. The ellipsis between NAL unit types 25 ah 31 means
    that those types are all unspecified, The mpementatio of Table 3 below
    changes            type     24     Of     the    standard fronm       specifiede"       to
10  "supseqIarameter set. sscQ                   "Unspecfied" is generally reserved for user
    applications.          Reserved", on the other hand, I generally reserved for future
     standard medications. Accordingly; another implementation changes one of
    the "reserved             types (for example, type I6, 17:or 4I)                        to
     "supseqparameter-set svO f Changing an "unspecified" type results in an
1(5  implementation for a given user, whereas changing a Oreserved* type results
     in en implementation that changes the standard for all users,
        .: , vIe qa
          nalynittype
                     .  V.     '.C
                               Content of NAL unit and IRBSP syntax structure          C
                              0.Unspe   fied
                    I          Coded       slice    of   a    nor-OR      picture   2     4
                                  l.eoayer withoutpaItitonajbsp
                   I-18        Resemed
                   24          sup'seqarameter set s cO
              25       31      Unspecifed
                                                     Table 3
20
                 FIGa 8 shows a functional view of an implementation of a scalable
      video coder 800 that generates SUP SPS units. A video is received at the

                                            21
   input of the scal0ble video coder I. The video Is coded according to different
   spatialtevels, spatia levels mainly refer to different levels of resolution of the
   same video. For example, as the input of a Scalable video eoder one can
   have a CIF sequence (352 per 288) or a QIF sequence (176 per 144) which
 5 represent each one spatial level.
           Each of the spatial levels is sent to an erncoder. The spatial level i is
   sent to an encoder 2", the spatial level 2 is sent to an encoder 22and the
   spatial level m is sent to an encoder 2.
           The spatial levels are coded with 3 bits, using the dependencyid,
10 Therefore, the maximum number of spatial levels in this implementation is 5.
           The encoders 2 2 and 2" encode one or more layers having the
   indicated spatial level. The encoders 2 'aard 2 may be designed to have
   particular quality levels and temporal levels, o the qualtylevels and temporal
    level rmay be conIgurable. As can be seen from FIG. the encoders 2 2
15  and 2" are hierarchically arranged. That is, the encoder 2" feeds the encoder
    21%which in tuM feeds the encoder 2. The hierarchical arrangement indiates
    the typical idenaito inwhich higher layers use a lower players) as a references
            After the coding, the headers are prepared for each of the layers rn
    the implermentation shown for each spatial level, an SPS message, a PPS
20  message, and multiple SUP_SPS messages are created. SUP SPS
    messages (or units) may be created,for example, for layers corresponding to
    the vadous different quality and temporaevels.
            For spatial levol I. SPS and PPS 5" are created and a set of
     SUPSPS SUPSPS, -SUP _SPS_., are also created.
25           For spatial level 2, SPS and PPS 5' are created and a set of
     SUP.PS SUP -SFS .s SUP SPSk are also created
             For spatial level m, SPS and PPS 5 are created and a set of
     $up0sPST SUP                      SUP:_SPS are also created.
                                      SPS.
             The bitstreams. 7 7, and 7T encoded by the encoders 2, 2', and 2'
30   typically follow the plurality of SPS, PPS, and SUPSPS (also referred to as
     leaders, unitS or messages) Inthe gloal bitstream.

                                            22
           A bitstream$ includes SPS and PPS 5" SUP SPS                y SPS.
                                                                      SUP_
   SUPSPS          0' and encoded video bitstream       7",  which constitute all the
   encoded data associated with spatial level 1
           A bitstream 8includes SPS and PPS6, SUPSPS                 SUP SPS
 SSUPSPS            6~   nd encoded video bItstream 7i Which constitute all the
   encoded data associated with spatial level 2.
           A bitstream 8 includes SPS and PPS 5S UP SPS" sUP                S'S
   SUPSPS          66 and encoded video bitstream 7, which constitute al the
   encoded data associated withsptial levAm.
10         The different SUP.SPS headers are compliant with the headers
   described in Tables 1-3,
            The eno der800 depicted in FIG, 8 generates one SS for each
   spatial level However, other implementations may generate multiple SPS for
   each spatial level or may generate anSPSthat serves multiple spatial levels,
15         The bitstreams 8, 8, and 8" are combinedd in a multiplexer 9 which
   produces an SVC bitstream, as shown in FIG e.
            Referring to FIG. 9, a hierarchical view 900 Illustrates the generation of
   a data stream that contains SUP SPS units. The view 900 may be used to
   illustrate the possible bitstreams generated by the scalable video encoder 800
20 of FIG BA The view 000 provides an SVC bitstream to a transmission
    interface 17
            The SVG bitstream may be generated, for example. according to the
    implementation of FIG. 8 and comprises one SPS for each of the spatial
    levels. When rn spatial levels are encoded, the SVC bitstream comprises
25  SPSISPS2 and SP$m represented by 10, 10' and 10 inFlG 9.
            In the SVC bitstream. each SPS codes the general information relative
    to the spatial level. The PS is followed bya header 11, 11             3, 13 13',
                                                                          11i
    15, 15': and 15" of SUPSPS type. The SUPSPS is followed by the
    corresponding encoded video datg 12, I 12"             .1414i,14    16, and 16
30  which each correspond to one temporal level (n) and one quality level (0).

                                            23
            Therefore, when one layer is not transMitted; the correspondig
    SUP.SPS is also ot transmitted. This Ia because the e is typically one
    SUP.SPS header corresponding to each layer
            Typical implerentations use a numbering chteme for layers in which
  5 tie base layer has a ID.a-id 0 of zero. If such a nuibering scheme is used for
    the view 9001 then the view 900 does riot expicitly showa base layer. That
    does not preclude the use of a base layer. Additional, however, the view
    900 may be augmented to explicitly show a bitstreanifor a base layer, as well
    as, for example, a separate SPSfor a base layer. Further, the:View 900 may
10  use an atemate numbering scheme for baselayers in whidh one or more of
    the bitstreams (1, 1,1iYthrough (M n ) refers a base layer.
            Referring to FIG. 0i, a block view is provided of a data stream 1000
    generated by the implementation of FIGS.'        and 9. F.     10 iustrtes the
    transmission of the following layers:
15     - oLayer (1, 1, 1): spatial level 1 tempo uralevel i, quality level 1; which
            includes transmission of blcks 10, t and 12;
            Layer (1,1)      spatial level.  termporal level 2 quality level Ti; hich
            includes the addtional transmission of blocks 11' and 12*;
            Layer (2 1, 1) spatial level 2 temporal level 1, quality level i; which
20          includes the additional transmission of blocks 113and 14;
         o Layer (3, 1 1) spatial level 3, temporal level I quality level 1t which
            indlude- the addition transmission of blocks 10 i,Sand 18;
          o Layer-(3, 21): spatial level 3, temporal level 2,quality level 1 which
            includes the additionatransmissionmf blocks 15 and 16;
25       i  Layer (3 3 1) spatial leve 3,temporal leel 3, qualitylevel1; which
            includes the additionaltransmission of blocks 5"and 17.
            The block view of the data stream 1000 illustrates that SPS 10 is only
    sent once and is used by both Layer (1,t1. 1) and Layer (1, 2, 1) and that
 30  SPS 10" i6 only sent once is used each of Layer (3,11 Layer (3, 2, 1), and
     Layer (3, 3, 1), Further, the data stream 1000 lustrates that the parameters
     for al of the layers are not transmitted, but rather only the parameters

                                          24
   coeresponding to the transmitted layers      Por example, the parameters for
   layer (2 2 1) corresponding to $UP $PS' are nottransmitted because that
   layer is not transmitted. This provides an effiiency for thisimplementation
          Referring toFIG.ian engoder 1100 includes an SPS generation unit
 5 1110. a video encoder 1120 and a formatter 1130. The video encoder 1120
   receives input video, encodes the input video and provides the encoded input
   video to the formatter 1130.      The encoded input video may include, for
   example, multiple layers sudh as, for example, an encoded base layer and an
   encoded enhancement layer. The SPS gentation unit 1110 generates
16 header information, such as, for example, SPS units and SUP SIS units, and
   provides the header information to the formatted 1130. The SPS generation
   unit 1110 also communicates with the video encoder 1120 to provide
   parameters used by the vdeo encoder10 in encoding the input video.
          The SPS generation unit 1110 may be configured, for example, to
15 generate an SPS NAL nunit.nit                      may indde information that
   describes a. parameter for use in decoding a first-layer encoding of a
   sequence of images. The SPS generation unit110 also may be configured,
   for example, to generate a SUP SPS NAL unit having a different; structure
   than the SPS NALunit. The SUP SPS NAL unit may include information that
20 describes a parameter for use in decoding a second4ayer encoding of the
   sequence of images. The firslayer encoding and the second-layer encoding
   may be produced by the video encoder 1120
          The formatter 1130 multiplexes the encoded video from the video
   encoder 1120, and the header information from the SPS generation unit 1110
25 to produce an output encoded bitstream. The encoded bitstream may be a
   set of data that includes the firstayer ending of the sequence of image,
   the second-ayer encoding of the sequence of m0gesthe SPS NAL unit, and
   the SUP SPS NAL unit.
           The components 1110 112O,      and 1130 of the encoder 1100 may take
30 many forms. One or more of the components i11, 1120. and 1130 may
   include hardware, software, fitmware, or a combination, and may be operated

   from a variety Of platforms, such as, for example, a dedicated encoder or a
   generaprocessor configured through software to function as an encoder
          FIGS. 8 and 1 may be compared. The SPS generation unit 1110 may
   generate the SS and the various SU SPS% shown in FIG 8. The video
 5 encoder 1120 may generate the bitstreams 7, 7. and 7" (whi-h are the
   encodings of the input video) shown.in FIG. 8 The video encoder 1120 May
   correspond.,for example, to one or more of the encoders 22. or 2". The
   formatter 1130 may generate the hierarhically arranged data shown, by
   reference numerals 8 8, 8 as well as perform the operation of the
10 multiplexer 9 to generate the SVC bitstream of FIGA   :.
          FIGS. 1 ahd 11 also may be compared. The video encoder 1120 May:
   correspond, for example, to block 104 and 1 f M7     FIG 1. The formatter 1130
   may correspond, for example, to the multiplexer 170. The SPS generation
   unit 1110 is not explicitly shown in FIG. I although the functionality of the SPS
15 generation unit 1110 may be performed, for example, by the multiplexer 170.
          Other implementations of encoder 1100 do not include the video
   encoder 1120 because, for example, he data is preencoded. The encoder
   1100 also may provide additional outputs and provide additional
   communication between the components. The encoder 1100 also may be
20 modified to provide additional components which may, for example, be
   located between existing coprnPonents.
          Referring to FG. 12 an encode1200 it shown that operstes in the
   same manner as the encoder 1100. The encoder 1200 includes a memory
   1210 in communication with a processor 1220. The memory 1210 may be
25 used, for exAmple, to store the input video, to store encoding or decoding
   parameters, to store intermediate or finalresults during the encoding process,
   or t0store instructionsfor performing an encoding method. Such storage may
   be temporary or permanet.
          The processor 1220 receives nput video ard encodes inputnputideo.
30 The processor 120 alo generates header information, and formats an
   encoded bitstream that inclUdes header information and encoded input video.
   As in the encoder 1100, the header information provided by the processor

   1220 may include separate structuresor conveying header information for
   multiple layers. The processor 1220 may operate according to instructions
    tored onor otherwise resident on or part of, for example, the processor 1220
   or the memory 1210.
 5        Referring to G.13 a process 1300sshown for encoding input video.
   The process 1300 may be perfoned by, for example, either of the encoders
   1100 or 1200.
          The process 1300 includes generating an SPS NAL unit (1310) The
   SP' NAL unit includes information that describes a parameter for use in
10 decoding the first-layer encoding of the sequence of images. The S#S NAL
   unit may be defined by a coding standard or not. If the SPS NAL unit is
   defined by a coding standard, then the coding standard may require a
   decoder to operate in accordance with received SPS NAL units, Such a
   requirement is generally referred to by stating that the SPS NAL unt is
15  normative, SFS for example, are normativein the AVC standard, whereas
   suipplementat enhancement Information ("SEI") messages, for example, are
   not normative., Accordingly, AVC-compatibe decoders may ignore received
   SEI messages but must operate in accordance with received SPS,
          The SPS NAL unit includes information describig one or more
20 parameters for decoding a first layer. The parameter may be, for example,
   information that is layer-dependent, or is not layerAependent Examples of
   parameters that are typically layer-dependent include a VUI parameter or an
   HlRD parameter.
          Operation 1310 May be performed, forexample, by the SFS generation
25 unit 1110, the processor 1220, or the SPS and PPS Inserter 2140.          The
   operation 1310 also nay correspond to the generation of SPS in any of blocks
   5 5', 5" in FIG.
          Accordingly; a means for performin: the operation 1310         that is,
   generating an SPS NAL unit, may include various components. For example,
30 such means may include a module tor generating $PS 56,         or 5"an entire
   encoder system of FIG. 1, , 11 or 12, an SPS generation unit 1110, a
    processor 1220 or an SPS and PP inserter 2140, or their equivalents

   including known and future-developed encoders
           The process 1300 includes generating a supplemental ($UP") F'S
   NAL unit having a different structure than the SPS NAL unit (1320). The SUP
   SPIS NAL unit in ludes information that describes a parameter for use in
 5 decoding the second-ayer encoding of the sequence of images The SUP
   SFS NAL unit may be defined by a coding standard, or not. Ifthe SUP SPS
   NAL unit is defined by a coding standard, then the coding standard may
   require a decoder to operate it accordance with received SUP SF' NAL
   units., As discussed above with respect to operation 1310 such requirement
10 is generally referred to by stating that the SUP SPS NAL unit is "normative".
           Various implementations indluade normative SUPSPS messages. For
   example, SUPySPS messages, may be normative for decoders that decode
   more than one layer (for exam pie.VC-compatible deoodersk) Such muti
   layer decoders (for example:,SVCcompatible decoders) would be required to
15 operate inaccordance with the information conveyed in SLP SPS messages
   ,However; singlelayer decoders (for example, AVC-compatible decoders)
   could ignore SUP SPS messages., As another example, SOP SPS messages
   may be normative for aI decoders, including singlelayer and multiayer
   decoders. It is not surprising that many implementations include normative
20 SUP SPS messages, given that SUP SPS messages are based in large part
   on $P S messages, and that S PSmessages are normative in the AVC
   standard and the SVC and MVC extensions. That is, SUP SPS messages
   carry similar data as SPS messages, serve a similar purpose as SPS
   messages and may bOeconsidered to be a type of SPS message. It should
25  be clear that implementations having normative SUP S S messages may
   provide compatibility advantages. for example, allowing AVC and SVC
   decoders to receive a common data stream.
           The SUP SPS NAL uhit (also referred to as the SUP SPS message)
    inlodes one or more parameters for decoding a second layer. The parameter
$0  may be, fdr example, information that Is layer-dependent, or is not layer
   dependent.      Specific examples include a VUI paramieter or an HRD
    paranete. the SUP SPS may also be used for decoding the first layer.in

                                          28
   addition to beingused for decoding the second layer.
           Operation 1320 may be performed, for example, by the SPS generation
   unit 11 0 the processor 1220, or a module analogous to the SPS and PPS
   Inserter 2140. The operation 1320aso may correspond tothe generation of
 5 $UPSPS in any of blocks f6,6 6" in PIG. 8.
           Accordingly, a means for performing the: operation 1320, that is,
   generating a SUP SPS NAL unit may include various components. For
   example, such means may include a module for generating SUPSPS 6,
   or 6", an entire encoder system of FIG. 1 811 or 12 an SPS generation unit
10 1110, a processor 1220, or a module analogous to the SPS arnd PPS Inserter
   2140,.or their equivalents including known andfuture-developed endoders.
           The process 1300 includes enooding a first-layer ending, such as, for
   example, the base layer, for a sequence of images, and encoding a second
   layerencoding for the sequence of images (1330) These encoding of the
15 sequence of images produce the firs-layer encoding and the second-layer
   encoding. The fstjayer encoding may be formatted into a sees of units
   deferred to as first-layer encoding units, and the secondI.ayer encoding may
   be formatted into a series of nits referred to as second-ayer encoding units.
   The operation 1330 may be performed, for example by the video encodrt
20  1120, the processor 1220, the encoders 2, 2' or 2* of FIG.8, or the
   implementation of Fi.
           Accordinglya means for performing the operation 1330, may include
   various components: For example, suchmeans mayJaclude anencoder 22
   or 2" an entire encoder system of:.FlG 1, u4:8:.11r12, a video encoder 1120,
25 A processor 1220, or one or more core encoders 187 (possibly including
   decimation module 104) or their equivalents including known and future
   developed enoOders.
           The process 1300 includes providing a set of data (1340). The set of
   data includes the fitstayer encoding ofthe sequence of images the second
30  layer encoding of the sequence of images, the SPS NAL unit, and the SUP
    SP$ NAL unit. The set of data may be, for example, a bitstream, encoded
    according to a known standard, to be stored in memory or transmitted to one

                                         29
   or more decoders-. Operation 13 may be performed, for example, by the
   formatter 1130, the processor 120, or the multiplexer W0 of FIG. T.
   Operation 1340 may also be performed in FIG. 8 by the generation of any of
   the bitstreams 8B, and 8", as wel as the generation of the multiplexed SVC
 5 bitsteam.
           Accordingly, a means for performing the operation 1340; that is,
   providing a set of data, may Include various components. For eaAle, such
   means may include a module for generating the bitstream 8, S or 8' a
   multiplexer 9. an entire encoder systen-Of FIG 1 8 11, of 12 a formatter
10 1130, a processor 1220, or a multiplexer 170 or their equivalents including
   know and future-developed encoders.
           The process 1300 may be modified i various ways. For example
   operaton 1330 may be removed from the proess 1300 in implementationsin
   whidh, for examplethe data is pneendoded. Further in addition to removing
15 operation 1330, operation 1340 may be removed to provide a process
   directed toward generating description units for multiple layers
           Referring to FIG 14, a date team 1400 is shown that may be
   generated, for example, by the process 1300 The data stream 1400 includes
   a portion 1410 for an SPS NAL unit, a portion1420 for a SUP $PS NA unit,    A
20 a portion 1430 for the first-layer encoded data and a portion 1440 for the
     ecoand-layer encoded data, The frstlayer encoded data 1430 is the first
    layer encoding, which may be formatted as first-layer encoding units, The
   second4ayer encoded data1440 Is the second-4ayer encoding, which may be
   formatted as second-4ayer encoding units. The data stream1400 may include
25 additional portions which may be appended after the portion 1440 or
   interspersed between the portions 1410-1440.                Additionally, other
    implementations may modify one or more of the portions 1410440
           The data stream 1400 may be compared to FIGS. 9 and 10 The SPS
    NAL unit 1410 may be. for exampleany of the SPSI 10. the SPS2 10', or the
30  SPSm 10". The SUP SPS NAL. init 1420 may be: for example, any of the
   SUPSPS headers 11, 11' 11", 13, 13' 13", 15, 15, or I5*" The firstiayer
    encoded data 1430 and the secondilayer encoded data 1440 may be any of

                                            30
    the bitstreams for the individual layers shown as Bitstream of Layer (1, 1,
     12 through (m, n, 0) 16", and, including the bitstream 12, 12 1", 14, 14
      1   16; 16, and16". It is possible for the first-layer ero ded data 1430 to be
    a bitstream with a higher set of levels than the second-layer encoded data
 5  1440. For example, the frst-ayer encoded data 1430O may be the Bitstream of
    Layer (2, 2, 1) 14 and the second-layer encoded data 1440 may be the
     Bitstream of Layer (1, 11 12.
             An implementation of the data stream1400 may also correspond to the
    data stream 1000. The SPS NAL uhit 1410 may correspond to the SPS
10  module 10 of the data stream 1000. The SUP SPS NAL unit 1420 may
    correspond to the :SUPSPS module 11 of the data stream 1000. The first
     layer encoded data 1430 may correspond to the Bitstream of Layer (1, 1, 1
     12 of the datastteamn 1000. The second-layer encoded data 1440 may
     correspond to the Bitstream of Layer (1, 2, 1) 12' of the data stream 1000.
15  The SUP_SPFS module 11'of the data stream 1000 may be interspersed
     between the firstiayer encoded data 1430 and the second4ayer encoded data
     1440. The remainirNg blocks ('6")       shown in the data stream1000 may be
     appended to the data stream 1400 in the same order shown in the data
     stream 1000
20           FIGS and I10 may suggest that the SPS modules do not include any
     layer-specific parameters. Var(us implementations do operate in this
     manner, and typically require a SUPSPS for each layer However, other
     implementations allow the SPS to include layer-specific parameters for one or
     more layers, thus allowing one or mnre layers to be transmitted Without
25    requiring a SUP_SPS.
              FIGS. 9 and 10 suggest that each spatial level has its own SPS. Other
      implementation vary this feature. For example, other implementations
      provide a separate SPS for each temporal level, or for each quality level. Still
      other implementations provide a separate SPS for each layer, and other
 30   implementations provide a single SPS that serves alllayers.
              Referring to FIG. 15, a decoder 1500 includes a parsing unit 1510 that
      receives a enrcded bitstream, such as, for example, the encoded bitstream

                                            31
    provided by the encoder 1100, the encoder 1200, the process 1300, or the
    data.stream 1400. The parsing unit 1510 iscoupled to a decoder 1520.
            The parsing unit 1510 is configured to access information from an SPS
    NAL unit. The information from the SPS NAL unit describes a parameter for
 5  use in decoding   a first-ayer encoding of a sequence of images, The parsing
    unit 1510 is further configured to access information from a SUP SPS NAL
    unit having a different structure than the SPS NAL unit The information from
    the SUP SPS NAL unit describes a parameter for use in decoding a second
    layer encoding of the sequence of images. As described above in conjunction
10  with FIG, 13, the parameters may be layerdependent or nondayer
    dependent.
             The parsing unit 1510 provides parsed header data as an output, The
    header data indudes the Infrmation accessed from the SPS NAL unitand
    also includes the information accessed from the SUP SPS NAL unt. The
15   parsing unt 1510 also provides parsed encoded video data as an output The
    encoded video data includes the first4ayer encoding and the second4ayer
    encoding. Both the header data and the encoded video data are provided to
    the decoder:1520I
             The decoder 1520 decodes the first-layer encoding using the
20   information accessed from the SPS NAL unit.          The decoder 1520 also
     decodes the second-layer encoding using the information accessed from the
     SUP IPS NAL unit The decoder 1520 further generates a reconstruction of
     the sequence of images based on the decoded first-ayer and/or the decoded
     secondlayer. The decoder 120 provides a reconstructed video as an output
25   The reconstructed video may be, for example, a reconstruction of the first
     layer encoding or reconstruction of the second4ayer encoding.
             Comparing FiGS. 15, 2, and 2a, the parsing unit 1510 may corresponds
     for example, to the demultiplexer 202, and/or one or more of the entropy
     decoders 204, 212, 222, or 2245, in some implementation. The decoder
 30  -520 may correspond, for example, to the remaining blocks in FG2
             The decoder500 also may provide additional outputs and provide
      additional communication between the components. The decoder 1500 also

                                           32
   may be modified to provide additional components which ma for example,
   be located between existing components.
           The components 1510 and 1520 of the decoder 1500 may take rany
   forms. One or more of the components 1510 and 1520 may include
 5 hardware, software firmwareor a combination and may be operated from a
   variety of platforms, such as, for example, a dedicated decoder or a general
   processor configured through software function as a decoder.
           Referdng to FIG. 16 a decoder 1800 is shown that operates in the
   same manner as the decoder 1500. The decoder 1600 includes a memor
10 1610 in communicatioh wth a processor 1620. The memory 1610 may be
   used, for example, to store the input encoded bitstream, to stoAe decoding or
   encoding parameters to store intermediate or final results during the decoding
   process, or to store instructions for pforormaing a dOoding method. SuOO
   storagemay be temporary or permanent,
15         The processor 1620 receives an encOded bitstream and deodes the
   endeded bitstream into a reconstructed video. The encoded bitstream
   includes, for example, (1) a first-layerencoding of a sequnce of images, (2) a
   second4ayer encodding of the sequence of images, (3) an SPS NAL unit
                                                             In
   having infomion that describes a parameteror use tIdecoding            the first
20  layer encoding, and (4) a SUP SPS NAL unit having a different structure than
   the SPS NAL unit, and havig information that describes a parameter for use
    in decoding the second4ayer encoding.
            The processor 1620 produces the reconstructed video based on at
    least the first-layer encoding, the second-ayer encoding, the information from
25 the SPS NAL unit, and the information from the SUP SPS NAL unit. The
    reconstructed video may be- for example, a reconstruction of the first-layer
    encoding or a reconstruction of the second layer encoding. The processor
    1620 may operate according to instructions stored on, or otherwise resident
    on or part of for example, the processor 1620 or the mpmory 1510.
30          Referring t6 FIG. 17 a process 1700 is shown for decoding an
    encoded bitstream. The process 1700 may be performed by, for example,
    eher of the decoders 1500 or 1600.

                                          3$
          Tbe process 1700 includsaccesinginformation from an SPS NAL
   unit (1710) The accessed information describes a parameter for usein
   decoding a first-layer enCoding of a sequence of Imagest.
          The SPS NAL unit mnay be as described earlier with respect to tIG. 13.
 5 Furtherthe accessed information may b for examp an -HRDpaamete
   Operation1710 ray be performed, for example, by the parsing unit 1510, the
   processor 1620, an entropy decoder 204, 212,222 or 2245, or decoder
   control 2205. Operaton 1710 also may be performed in a reconstruction
   process at an encoder by one or more components of an encoder.
10        Accordingly, a means for performing the operation 1710, that is.
   accessing information from an SPS NAL unit, may include vareogs
   components. For example, such means may include a parsing unit 1610: a
   processor 1620, a single-layer decoder, an entire decoder system of FIG. 2
   15, or 10. or one or more components of a decoder, or one or more
15 component of encoders 800, 1100, or 1200, or their equivalents including
   kanwn and future-developed decoders and encoders,.
          The process 1700 includes accessing information from a SUP SPS
   NAL unit having a different structure than the SPS NAL unit (1720). The
   information accessed from the SUP SPS NAL unit descibes a parameter for
20 use in decoding a second-layer encoding of the sequence of images.
           The SUP SPS NAL unit may be as described earlier with respect to
   FIG. 3. Further, the accessed information may be, for example, an HRD
   parameter. Operation 1720 May be performed, for example, by the parsing
   unit 1510the processor 1620 an entropy decoder 204, 212, 222,.or 2245, or
25 decoder control 2205. Operation 1720 also may be performed In a
   reconstruction process at an encoder by one or More components of an
   encoder.
           Accordingly, a means for performing the operation 1720, that is,
   accessing information from a SUP SPS NAL unit, may include various
30 components, For example, such means may include a parsing unit 1510, a
   processor 1620, a demultiplexer 202, an entropy decoder 204 212: or 222, a
   single-layer decoder: or an entire decoder system 200, 1600, or 1600, or one

                                        3~4
   or more components of a decoder, or one or more components of encoders
   800,1100,or 1200, or their equivalents including known and Mure-developed
   decoders and encoders.
          The process 1700 includes accessing a first-layer encoding and a
 5 second-layer encoding for the sequence of images (1730. The first-layer
   encoding may have been formatted into first-layer encoding units, and the
   second-layer encoding may have been formatted into second-4ayer encoding
   units. Operation 1730 may be performed for example, by the parsing unit
   1510, the decoder 1520, the processor 1020, an entropy decoder 204 212,
10 222, or 2245 or various other blocks downstream of the entropy decoders.
   Operation 130 also may be performed in a reconstruction process at an
   encoder by one or more components of an encoder,
          Accordingly, la means for performing the operation 1730 may include
   various components- For example, such rneans May indude a parsing uit
15 1510, a decoder 1520, a processor 1620, A demultiplexer 202, an entropy
   decoder 204 212. or 22, a single-layer decoder, a bitstream receiver, a
   receiving device, t an entire decoder system 200, 1500, or 160, or one or
   more components of a decoder, or one or more components of encoders 800,
    1100, or 1200, or their equivalents including known and future-developed
20 decoders and erIcoders.
           The process 1700 includes generating a decoding of the sequence of
    images (1740). The decoding of the sequence of images may be based on
   the first-ayer encoding, the secondlayer encoding the accessed information
   from the SPS NAL unit, and the accessed information from the SUP S'PS NAL
25  unit. Operation 1740 may be performed, for example, by the decoder 1520,
   the processor 1020, or various blocks downstream of demultiplexer 202 and
   input buffer 2210. Operation 1740 also may be performed in a reconstruction
    process at an encoder by one or more components of an encoder.
           Accordingly, a means fr performing the operation 1740 may include
30  various components. For example, such means may include a decoder 1530
    a processor 1620, a singledayer decoder an entire decoder system 200
    1500, cr 1600, or one or more components of a decoder, an enodet

    performing a reconstruction or one or more components of encoders 800,
        QQ,1 .or 1200 er their equivalents including k.nW. and future-developed
    decoders or encoders.
             Another implementation performs an encoding method that inCudes
  5 accessing ifirstatnWinafirst                             normative parameter set
    The accessed first layer-depnenent information is for use in decoding a first
    layer encoding of a sequence of images. The first normative parameter set
      nay be, for example, an SPS that includes:,HRD-related parameter or other
    layer-dependent information. However, the first normative parameter set
10  need rnot be anSI'$ and need not be related to an    l    264 standard.
              in addition to the first parameter set being normative, which requires a
    decoder to operate in accordance with the first parameter set if such a
    parameter set is received, the first parameter set may also be required to be
     received in an implementation. That is an implementation may further requite
15   that the first parameter set be provided to adecoder.
              The encoding method of this impterentation further includes accessing
     second layer-dependent information in a second normative parameter set
     The second normative parameter set has a different structure than the first
     normative parameter set. Also, the accessed second layer-dependent
20   information is for use in decoding a second-layerencoding of the sequence of
     images. The second normative parameter set may be, for example a
     supplemental SPS& The supplemental SPS has a structure that is different
     from, for example; an UPS. The supplemental SPS also include HRD
     parameters or other layer-dependent information for a second layer (different
 25  from the first layer),
               The encodin method of this implementation further includes decoding
      the sequence of images based on one or more of the accessed first layer
      dependent information or the accessed second layer4ependent information.
      This may include 1 for example, decoding a base layer or an enhancement
 30   layer.
               Corresponding apparatuses are also provided! in                     their
      implementations        for implementing the encoding method of this

   implementation.      Such apparatuses include, for example programmed
   encoders, programMed processors, hardware implementationsj or processor
   readabie media having instrudtions for performing the encoding method The
   systems I110 and 1200., for example, may implement the encoding method of
   this iOpementationf                            d
           Corresponding signals: and media storing such signals or the data of
   such signals are also provided, Such signals are produced, for exampleby
   an encoder that performs the encoding method of this implementationr
            Another implementation performs a decoding method analoous tothe
10 above encoding method. The. decoding method incldes generating a first
   nominative parameter set that includes first layer-dependent information The
   first layerfdependent information is for use in decoding a firstlyer encoding
   of a sequence of images, The decoding method also includes generating a
   second normative parameter set having a different structure than the first
15 normative parameter set       The second normatve parameter set includes
   second layer-dependent information for use in: decoding a second4ayer
   encoding of the sequence of images. The decoding method further inluldes
   providing a set of data including the first normative parameter set and the
   se cond normative parameter set.
20          Corresponding apparatuses are also provided in other
   implementations, for implementing the above decoding method of this
   implementation,      Such apparatuses include, for example, programmed
   decoders, programmed processors, hardware implementations- or processor
    readable media having instructions for performing the decoding methd The
25  systems 1500 and 1600; for example, may implement the decoding method of
   this implementation.
            Note that the term "supplementar as used above, for example, in
    referring to upplemental SPS" is a descriptive term. As such, supplementall
    SPS" does not preclude units that do not include the term supplemental" in
30  the unit narme. Accordingly and by way of example, a current daf of the
    SVC extension defines a subset SPS" synta structure and the "subset SP$
    syntax structure isfully encompassed by the descriptive term: supplementaf'.

                                          37
   So thathe "subset SP'S" of the current SVC extensIon is one implementation
   of a SUP SPS as described ir this disclosure.
           implementations may use other types of messages in addition to, or as
   a replacement for, the SPS NAL units and/or the SUP S'PS NAL units. For
 5 example, at least one implementations generates, transmits, receives,
   accesses, and parses other parameter sets having layerdependent
   Information,
           Further, although SPS and supplemental SPS have been discussed
   largely in the context of H264 standards, ether standards also may include
10 SPS, supplemental SPS or variations of SPS or supplemental $
   Accordingly, other standards (existing or future-developed) may include
   structures referred to as SPS or supplemental SPSand such structures may
   be identical to or be varations of the SPS and supplemental SPS described
   herein. Such other standards may, ft example, be related to current H.264
15 standards (for eXample, an amendment to an existing H.264 standard         or be
    completely new standards. Aternatively, other standards (existing or future
   developed) may include structures that are not referred to as SPS or
   supplemental SP$, but such structures may be identicalto, analogous toi or
   Variations of theSPS arsupplemental SPS described herein.
20          Note that a parameter set is a set of data including parameters, For
    example, an SPS, a PPS, oir supplemental SPS,
             n vaous
                 1     implementations, data is said to be "accessed" "Accessing"
    data may icludek for example, receiving, storing traqmitting, or processing
    data.
25          Various   implementations are provided and described.             These
    Implementations can be used to solve a variety of problems. One such
    problem arises when multiple interoperability points (lOPs) (also referred to as
    layers) need different values for parameters that are typically carried in the
    SPS. There is no adequate method to transmit the layer dependent syntax
30  elements in the SPS for different layers havng the same SS identified it is
    problematic to send separate SPS data for each such laye. For example, in
    many existing systems a base layer and its composite tempoal layers share

   the same SPS identifier.
           Several implementations provide a different NAL unit type for
   supplemental SPS data. Th"s, multiple NAL units may be sent, and each
   NAL unit may include supplemental SPS information for a different SVC layer
 5 buteach NAL unit may be identified by the same NAL unittype. The
   supplemental SPS information may, in one implementation, be provided in the
   "subset SPS NAL. unit type of the current SVO extension.
           It should be clear that the implementations described in this disclosure
   are not restricted to the SVC extension or to any other standard. The
1D concepts and features of the disclosed implementations may be used with
   other standards that exist now or are developed in the future, or may be used
    in systems that do not adhere to any standard. As one example, the concepts
   and features disclosed herein may be used for implementations that work in
   the environment of the MVC extension. For example MVC views may need
15 different SPS information, or$VC layers supported within the MVC extension
    may need different SPS information. Addiinally, features and aspects of
    described implementations may also be adapted for yet other
    implementations. Accordingly although implementations described herein
    may be described in the context SPS for SVC layerssuch desarptions shoUd
20  in no way be taker as Ulmiting the features and concepts to such
    implementations or contexts.
           The implementations described herein may be impremented in, for
    example, a method or process, an apparatus, or a software program. Even if
    onlydiscussed in the context of a single form of implementation (for example,
25  discussed ony as a method) the implementation of features discussed may
    also be implemented in other forms (for example, an apparatus or program).
    An apparatus may be implemented in, for example, appropriate hardware,
    software, and firmware. The methods may be implemented in for example,
    an apparatus such as, for example, a processor, which refers to processing
30  devices in general, including, for example, a computer, a micropoessor, an
    integrated circuit, or a programmable logic device. Processors also include
    communication devices, such as, for example, computers, cel phones,

   portable/personal digital assistants ("PDAs") and other devices that facilitate
    ooMmuniation of information between and-users,
           Implementations of the various processes and features described
   herein may be embodied in a variety of different equipment or application,
 5 paricuarly; for example, equipment or applications associated With data
   encoding and decoding. Examples of equipment include video oders, video
   decode, video codes, web servers, set-top boxes laptops, personal
   computers, cell phones, PDAs, and other communication devices. As shoud
   be clear, the equipment may be mobile and even installed in a mnbie vehicle.
10         Additionally., the methods may be implemented by instructions being
   performed by a procedsor, and such instructions may be stored on a
   processor-readable medium such as, for example an integrated circuit a
   software arrer or other storage device such as: for example, a hard disk, a
   tompact diskette, a random access memory (ERAM'* -or a read-only memory
15 ("OM)          The instrctojns may form an application program tangibly
   embodied on a processor-readable medium. Instructions may be, for
   example, in hardware, firmware software, or a combination. lnstructions may
   be found in, for example, an operating system, a separate application, or a
    combination of the two. A processor may be characteiod therefore, as, for
20 example, both a device configured to carry out a process and a device that
    includes a computer readable medium having instructions for carrying out a
    process.
           As will be evident to one of skill in the art, implementations may
    produce a variety of signals formatted to carry information that may be for
25 example, stored or transmitted, The information may include, for example,
    instructions for performing a method, or data produced by one of the
    described implementations. For example, a signal may be formatted to carry
    as data the rules for writing or reading the syntax of a described embodiment,
    or to carry as data the actual syntax-values written by a described
30  embodiment         Such a signal may be formatted, for example: as an
    electromagnetic wave (for example, using a adio frequency portion of
    spectrum) or as a baseband signal The formatting may inclde, for example,

                                             40
   encoding a data stream and modulating a carrier with the encoded data stream,
   The information that the signal:carries may be, for example anaog     I     digital
   information. The signal may be transmitted over a variety of different wired or
   wireless links as rs known
 5         A number of implementations have.been describedL Nevertheless, ft will
   beOnderstood that various modifications may be made. For example elements of
   different implementations may be combined, supplementermodified or removed
   to produce other implermentations, Additionally, one of ordinary skill will
   understand that other- structures and processes may be substituted for those
10 disposed and the resulting implementations will perform at least substantially the
   same function(s), in at least substantially the same way(sto achieve at least
   substantially the same result(s) as the implementations discosed. Accordingly
   these and other implementations are contemplated by this application and are
   within the scope of the following claims.
15         Where the term comprisee* " comprises, "cmprised- or comparingg" are
   used in this specificationi nluding the claims) they are to be interpreted as
   specifying the presence of'the stated features, integers, steps or components, but
   not precluding the presence of ore or more other features; integers; steps or
   components, or group thereof.
20

                                                     41
                                                 CLAIMS
        1. A decoder comprising:
   a parsing unit to receive
 5          information in a first parameter set contained in a first network abstraction layer unit, the
            first parameter set being a syntax structure which contains syntax elements that apply to
            zero or more entire coded video sequences, and the information describing a parameter
            for use in decoding multiple layers of the video sequences, and
            supplemental information contained in a second network abstraction layer unit, the
10          second NAL unit having a different syntax structure than the first network abstraction
            layer unit and corresponding to one layer of said multiple layers; and
   a decoding unit to decode said one layer of said multiple layers based on, the accessed
   information from the first NAL unit and the accessed supplemental information from the second
   NAL unit.
15
       2.   The decoder of claim 1 wherein the supplemental information includes (i) an identifier
   of the first parameter set to indicate that the second NAL unit is used to supplement the first
   NAL unit, (ii) a video usability information ("VUl") parameter having layer dependent
   information for use in decoding said one layer of said multiple layers.
20
       3. A method comprising:
   receiving information in a first parameter set contained in a first network abstraction layer unit,
   the first parameter set being a syntax structure which contains syntax elements that apply to zero
   or more entire coded video sequences, and the information describing a parameter for use in
25 decoding multiple layers of the video sequences;
   receiving supplemental information contained in a second network abstraction layer unit, the
   second NAL unit having a different syntax structure than the first network abstraction layer unit
   and corresponding to one layer of said multiple layers; and
   decoding said one layer of said multiple layers based on, the accessed information from the first
30 NAL unit and the accessed supplemental information from the second NAL unit.

                                                     42
       4.   The method of claim 3 wherein the supplemental information includes (i) an identifier
   of the first parameter set to indicate that the second NAL unit is used to supplement the first
   NAL unit, (ii) a video usability information ("VUI") parameter having layer dependent
   information for use in decoding said one layer of said multiple layers.
 5
       5. A computer-readable medium comprising computer interpretable instructions arranged
   to put into effect, when executed by one or more processors of a computer, the method of claim
   3 or claim 4.
10     6. An encoder comprising:
   a generation unit to generate
            information in a first parameter set contained in a first network abstraction layer unit, the
            first parameter set being a syntax structure which contains syntax elements that apply to
            zero or more entire coded video sequences, and the information describing a parameter
15          for use in decoding multiple layers of the video sequences, and
            supplemental information in a second network abstraction layer unit, the second NAL
            unit having a different syntax structure than the first network abstraction layer unit, the
            second NAL unit corresponding to one layer of said multiple layers; and
   an encoding unit to encode said one layer of said multiple layers based on the generated
20 information for the first NAL unit and the generated supplemental information for the second
   NAL unit.
       7. The encoder of claim 6 wherein the supplemental information includes (i) an identifier
   of the first parameter set to indicate that the second NAL unit is used to supplement the first
25 NAL unit, (ii) a video usability information ("VUI") parameter having layer-dependent
   information for use in decoding said one layer of said multiple layers.
       8. A method comprising:
   generating information in a first parameter set contained in a first network abstraction layer unit,
30 the first parameter set being a syntax structure which contains syntax elements that apply to zero

                                                      43
   or more entire coded video sequences, and the information describing a parameter for use in
   decoding multiple layers of the video sequences;
   generating supplemental information in a second network abstraction layer unit, the second NAL
 5 unit having a different syntax structure than the first network abstraction layer unit, the second
   NAL unit corresponding to one layer of said multiple layers; and
   encoding said one layer of said multiple layers based on the generated information for the first
   NAL unit and the generated supplemental information for the second NAL unit.
10      9. The method of claim 8 wherein the supplemental information includes (i) an identifier
   of the first parameter set to indicate that the second NAL unit is used to supplement the first
   NAL unit, (ii) a video usability information ("VUI") parameter having layer-dependent
   information for use in decoding said one layer of said multiple layers.
15      10. A computer-readable medium comprising computer interpretable instructions arranged
   to put into effect, when executed by one or more processors of a computer, the method of claim
   8 or claim 9.
        11. A signal having decoding parameters, the signal formatted to comprise:
20 information from a first parameter set contained in a first network abstraction layer unit, the first
   parameter set being a syntax structure which contains syntax elements that apply to zero or more
   entire coded video sequences, and the information describing a parameter at least for use in
   decoding multiple layers of the video sequences;
   supplemental information from a second NAL unit having a different syntax structure than the
25 first network abstraction layer unit, the second NAL unit corresponding to one layer of said
   multiple layers; and
   data representing said one layer of said multiple layers.
        12. The signal of claim 11 wherein the supplemental information from the second NAL unit
30 includes (i) an identifier of the first parameter set to indicate that the second NAL unit is used to

                                              44
supplement the first NAL unit, (ii) a video usability information ("VUI") parameter having
layer-dependent information for use in decoding said one layer of said multiple layers.

<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
