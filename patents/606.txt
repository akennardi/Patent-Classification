                                          ABSTRACT
Disclosed        is    a  three-dimensional               image    visualization             system,
comprising          a   selectively        transparent           projection          device       for
projecting an image toward an eye of a viewer from a projection
device position in space relative to the eye of the viewer, the
projection          device    being     capable         of    assuming         a  substantially
transparent state when no image                     is projected. An occlusion mask
device     is    coupled     to    the   projection            device      and    configured       to
selectively block light traveling toward the eye from one or more
positions       opposite       of   the   occlusion           mask    from the        eye     of  the
viewer      in      an   occluding       pattern           correlated         with     the      image
projected        by    the  projection         device.         An   integrated          module     is
coupled       to     the   projection        device          comprising:         a   diffraction
waveguide       element      configured        to    filter      by    trapping       within      the
diffraction waveguide element at                     least a first diffraction order
of     light    of     the   image     based       on      a   mode,      and     a   zone      plate
diffraction patterning device interposed between the eye of the
viewer and the diffraction waveguide element configured to cause
at least       a second diffraction order                    of light       of the image         from
the projection device to have a simulated focal distance from the
eye based at          least in part upon a selectable geometry.

  THREE DIMENSIONAL VIRTUAL AND AUGMENTED REALITY DISPLAY SYSTEM
                      RELATED APPLICATION DATA
      The present application claims the benefit under 35 U.S.C.
§  119 to U.S. Provisional Applications   Serial No. 61/563,403
filed November 23,  2011.   The foregoing application is hereby
incorporated by reference into the present application in its
entirety.
                       FIELD OF THE  INVENTION
      The present invention relates to virtual reality and
augmented reality imaging and visualization systems.
                             BACKGROUND
      In order for a 3D display to produce a true sensation of
depth, and more specifically, a simulated sensation of surface
depth, it  is desirable for each point in the display's visual
field to generate the accommodative response corresponding to
its virtual depth.   If the accommodative response to a display
point does not correspond to the virtual depth of that point, as
determined by the binocular depth cues of convergence and
stereopsis, the human eye may experience an accommodation
conflict, resulting in unstable imaging, harmful eye strain,
headaches,  and, in the absence of accommodation information,
almost a complete lack of surface depth.     Referring to Figure 1,
an augmented reality scenario   (8) is depicted with views to the
user of actual objects within the user's reality, such as
landscaping items including a concrete stage object    (1120) in a
                                  I

park setting, and also views of virtual objects added into the
view to produce the "augmented" reality view; here a robot
statue  (1110)  is shown virtually standing upon the stage object
(1120),  and a bee character   (2) is  shown flying in the airspace
near the user's head.    Preferably the augmented reality system
is 3-D capable, in which case it provides the user with the
perception that the statue    (1110)  is standing on the stage
(1120),  and that the bee character     (2) is flying close to the
user's head.    This perception may be greatly enhanced by
utilizing visual accommodation cues to the user's eye and brain
that the virtual objects    (2, 1110) have different depths of
focus, and that the depth of focus     or focal radii for the robot
statue  (1110)  is approximately the same as that for the stage
(1120).   Conventional stereoscopic 3-D simulation display
systems,  such as that depicted in Figure 2, typically have two
displays  (74,  76), one for each eye, at a fixed radial focal
distance  (10).   As stated above, this conventional technology
misses many of the valuable cues utilized by the human eye and
brain to detect and interpret depth in three dimensions,
including the accommodation cue, which is associated with the
eye's repositioning of the crystalline lens within the eye
complex to reach a different depth of focus with the eye.       There
is a need for an accommodation accurate display system which
takes into account the accommodation aspects of the human
eye/brain image processing complex.
                                SUMMARY
     In one example embodiment there is provided a three
dimensional image visualization system, comprising:      a
selectively transparent projection device for projecting an
                                   2

image toward an eye of a viewer from a projection device
position in space relative to the eye of the viewer, the
projection device being capable of assuming a substantially
transparent state when no image is projected;  an occlusion mask
device coupled to the projection device and configured to
selectively block light traveling toward the eye  from one or
more positions opposite of the occlusion mask from the eye of
the viewer in an occluding pattern correlated with the image
projected by the projection device;  and an integrated module
coupled to the projection device comprising a diffraction
waveguide element configured to filter by trapping within the
diffraction waveguide element at least a first diffraction order
of light of the image based on a mode, and a zone plate
diffraction patterning device interposed between the eye of the
viewer and the diffraction waveguide element configured to cause
at least a second diffraction order of light of the image from
the projection device to have a simulated focal distance from
the eye based at least in part upon a selectable geometry.
     Another example embodiment is directed to  a three
dimensional image visualization system, comprising a selectively
transparent projection device for projecting an image toward an
eye of a viewer from a projection device position in space
relative to the eye of the viewer, the projection device being
capable of assuming a substantially transparent state when no
image is projected;  an occlusion mask device coupled to the
projection device and configured to selectively block light
traveling toward the eye from one or more positions opposite of
the projection device from the eye of the viewer in an occluding
pattern geometrically corresponding to the image projected by
the projection device;  and a zone plate diffraction patterning
                                 3

device comprising a diffraction pattern, the zone plate
diffraction patterning device being interposed between the eye
of the viewer and the projection device and configured to cause
light from the projection device to pass through said
diffraction pattern having a selectable geometry as it  travels
to the eye and enter the eye with a simulated focal distance
from the eye based at least in part upon the selectable geometry
of the diffraction pattern. The system further may comprise a
controller operatively coupled to the projection device,
occlusion mask device, and the zone plate diffraction patterning
device and configured to coordinate projection of the  image and
associated occluding pattern, as well as interposition of the
diffraction pattern at the selectable geometry. The controller
may comprise a microprocessor. The projection device may
comprise a substantially planar transparent digital display
substantially occupying a display plane. The display plane may
be oriented substantially perpendicularly from a visual axis of
the eye of the viewer. The substantially planar transparent
digital display may comprise a liquid crystal display.   The
substantially planar transparent digital display may comprise an
organic light emitting diode display.  The projection device may
be configured to project the image toward the eye in a
collimated form such that the depth of focus for the eye of the
viewer is an infinite depth of focus.  The projection device may
comprise a high-speed mini-projector coupled to a substrate
guided delay exit pupil expander device configured to expand the
size of the image before delivery to the eye of the viewer.   The
mini-projector may be mounted substantially perpendicularly to a
visual axis of the eye of the viewer, and wherein the  substrate
guided delay exit pupil expander device is configured to receive
the image from the mini-projector and deliver it to the zone
                                4

plate diffraction patterning device and to the eye of the viewer
in the expanded size with an orientation substantially aligned
with the visual axis of the eye.    The zone plate diffraction
patterning device and projection device may comprise at least
one common structure.  the  zone plate diffraction patterning
device may be integrated into a waveguide, such that the
projection device comprises a high-speed mini-projector coupled
to the waveguide and configured pass the image through the
diffraction pattern before the image exits the waveguide en
route to the eye of the viewer.    The mini-projector may be
mounted substantially perpendicularly to a visual axis of the
eye of the viewer, and the waveguide may be configured to
receive the image from the mini-projector and deliver it to the
eye of the viewer, and the waveguide may be configured to
receive the image from the mini-projector and deliver it to the
eye of the viewer in an expanded size with an orientation
substantially aligned with the visual axis of the eye.    The
occlusion mask device may comprise a display configured to
either occlude or pass light at each of a plurality of portions
of the display, depending upon a pertinent command to occlude or
pass light at each portion.   The occlusion mask device may
comprise one or more liquid crystal displays.    The zone plate
diffraction patterning device may comprise a high-frequency
binary display configured to either occlude or pass light at
each of a plurality of portions of the display, depending upon a
pertinent command to occlude or pass light at each portion.     The
zone plate diffraction patterning device may have a refresh rate
of between about 50OHz and about 2,000Hz.    The zone plate
diffraction patterning device may have a refresh rate of about
720Hz.  The controller may be configured to operate the
projection device and occlusion mask device at between about 30
                                 5

and about  60 frames per second, and to operate the zone plate
diffraction patterning device to digitally display up to about
12 different diffraction patterns for each frame of the
projection device and occlusion mask device.                               The projection
device, occlusion mask device, and the                        zone plate diffraction
patterning device collectively may comprise an imaging module
for a single eye of the viewer, and the system further may
comprise a second imaging module for another eye of the viewer.
                     BRIEF DESCRIPTION OF THE DRAWINGS
     Figure   1   depicts            an    illustration         of    an     augmented  reality
scenario  with       certain           virtual          reality     objects,      and    certain
actual reality objects viewed by a person.
     Figure   2   illustrates               a    conventional        stereoscopy      system    to
simulate three-dimensional imaging for the user.
     Figures    3A    and       3B     illustrate          aspects      of    an accommodation
accurate display configuration.
     Figures    4A-4C         illustrate              relationships        between   radius     of
curvature  and focal radius.
     Figures    5-6C      illustrate             aspects     of  diffraction       gratings     as
applied to the subject configurations.
     Figures 7A-7C illustrate three different focal mechanisms.
     Figure 7D illustrates                 a Fresnel zone plate.
                                                      6

     Figure   8A-8C      illustrate         various   aspects       of    diffraction
system focusing issues.
     Figure  9  illustrates            one   embodiment   of    a    waveguide    with
embedded diffraction grating.
     Figure  10  illustrates            one   embodiment   of   a    waveguide    with
embedded  diffraction           grating     designed  to    allow       one  mode   to
escape and the other modes to remain trapped in the waveguide.
     Figures  11A-11B illustrate             aspects of  a diffractive        imaging
module embodiment.
     Figures  12A-12B illustrate             aspects of  a diffractive        imaging
module embodiment.
     Figures  13A-13B       illustrate       aspects of  a  diffractive       imaging
module embodiment.
                                            7

                            DETAILED DESCRIPTION
      Referring to Figures 3A and 3B, various aspects of an AAD
system are depicted.    Referring to Figure 3A, a simple
illustration shows that in the place of two conventional
displays as in stereoscopy (Figure 2),    two complex images, one
for each eye, with various radial focal depths      (12) for various
aspects  (14) of each image may be utilized to provide each eye
with the perception of three dimensional depth layering within
the perceived image.
      Referring to Figure 3B, we have determined that the typical
human eye is able to interpret approximately 12 layers       (layers
Ll-L12  in Figure 3B -  drawing element 16)  of depth based upon
radial distance.   A near field limit   (78) of about 0.25 meters
is about the closest depth of focus;     a far-field limit    (80) of
about  3 meters means that any item farther than about 3 meters
from the human eye receives infinite focus.      The layers of focus
get more and more thin as one gets closer to the eye;       in other
words, the eye is able to perceive differences in focal distance
that are quite small relatively close to the eye, and this
effect dissipates as objects fall farther away from the eye, as
shown in Figure 3B.    Element 82 illustrates that at an infinite
object location, a depth of focus / dioptric spacing value is
about 1/3 diopters.    One other way of describing the import of
Figure 3B:   there are about twelve focal planes between the eye
of the user and infinity.    These focal planes,   and the data
within the depicted relationships, may be utilized to position
virtual  elements within an augmented reality scenario for a
user's viewing, because the human eye is contantly sweeping
around to utilize the focal planes to perceive depth.
                                   8

       Referring to Figures 4A-4C, if K(R) is a dynamic parameter
for curvature equal to 1/R,       where R is the focal radius of an
item relative to a surface, then with increasing radius            (R3, to
R2, up to R1),    you have decreasing K(R).        The light field
produced by a point has a spherical curvature, which is a
function of how far away the point is from the eye of the user.
This relationship may also be utilized for AAD systems.
       Referring to Figure 3,     a conventional diffraction grating
 (22) is shown, with light passing through the grating spacing
 (18)  at an angle    (theta -  20) which is related to the
diffraction order      (n),  spatial frequency, and K factor, which
equals 1/d, using the following equation:
d*sin(theta)=n*wavelength       (or alternatively substituting the K
factor, sin(theta) = n*wavelength*K.          Figures 6A-6C illustrate
that with decreased spacing        (18, 28, 30) in the diffraction
pattern    (22, 24,  26),   the angle   (20, 32, 34)   becomes greater.
       Referring to Figure 5,     three different     focusing mechanisms
are depicted - refraction through a lens          (36),  reflection with a
curved mirror    (38),   and diffraction with a Fresnel      zone plate
 (40),  also shown in Figure 7D      (40).
       Referring to Figure 8A, a simplified version of diffraction
is shown to illustrate that an N=-1 mode could correspond to a
virtual image;      an N=+1 mode could correspond to a real image,
and an N=0 mode could correspond to a focused-at-infinity image.
These images could be confusing to the human eye and brain, and
particularly problematic if all focused on-axis, as shown in
Figure 8B.     Referring to Figure 8C, an off-axis focus
configuration may be utilized to allow for blocking of
modes/images that are unwanted.          For example, a collimated (r    =
infinity) image may be formed by the N=0 mode;            a divergent
virtual   image may be formed by the N=-1 mode;          and a convergent
                                       9

image may be formed by the N=+1 mode.       The difference in spatial
location of these modes/images and their trajectories allows for
filtering out or separation to prevent the aforementioned
problems associated with diffraction imaging, such as
overlaying, ghosting, and "multiple exposure" perception
effects.
      Referring to Figure 8, a waveguide is shown having an
embedded diffraction grating;      such waveguides are available,
for example, from suppliers such as BAE Systems PLC of London,
U.K. and may be utilized to intake an image from the left of
Figure 9 as shown, pass the image through the embedded
diffraction grating    (44), and pass the resultant image out at an
angle   (in Figure 9, for example, through the side of the
waveguide).    Thus a dual use of redirection and diffraction may
be achieved with such an element.      Indeed, off-axis focal
techniques, such as those described in reference to Figure 8C,
may be combined with diffraction waveguide elements such as that
shown in Figure 9 to result in a configuration such as that
shown in Figure 10, wherein not only are redirection and
diffraction accomplished, but also filtering, since in the
depicted embodiment the geometry of the diffracting waveguide is
such that the N=-1 mode     (say the virtual image) is passed out of
the waveguide and into the eye of the user, and the other two
modes  (N=0 and N=+1) are trapped inside of the waveguide by
reflection.
      Referring to Figures 11A-13C, the aforementioned concepts
are put into play with various augmented reality display
configurations.
      Referring to Figure 11A, an AAD system comprises an imaging
module   (46, 48) in front of each eye    (4, 6) through which the
user sees the world.     Figure 11B illustrates a larger view of
                                    10

the module  (46) with its associated     (coupled via the depicted
electronic control leads;     leads may also be wireless)
controller (66),  which may be a microprocessor, microcontroller,
field programmable gate array     (FPGA), application specific
integrated circuit    (ASIC), or the like.    The controller
preferably is coupled to a power supply and also an information
exchange device, such as a wireless internet or Bluetooth
adaptor, to allow for the exchange of information between the
outside world and the controller (66).       The system may be
configured to operate at an image refresh rate, such as a rate
between 30 and 60 frames per second.       The controller may be
configured to operate a high-refresh rate digital high
resolution display (52),    such as a ferro-liquid, bluephase, or
bent-corr display, to display various zone plate geometries
quickly in succession, pertinent to each of the 12 or so depth
layers.  For example, in an embodiment wherein 60 frames per
second overall performance is desired, the zone plate display
(52) may be operated at 12 times this, or 720Hz, to be able to
provide simulated accommodation to each of the 12 depth layers
as shown in Figure 3B.     The occluding mask display (54) is
configured to display a blacked out image geometrically
corresponding to the image displayed before it on the
transparent projector layer (56) - blacked out to prevent light
from the other side of the occluding mask display from bleeding
through or interfering with display of a desired virtual or
augmented image in the projector layer (56).       Thus in an
augmented reality configuration, as shown, light from the real
background passes through the non-masked portions of the
occlusion mask  (54),   though the transparent   (i.e., not
broadcasting a portion of an image) portions of the transparent
projector layer  (56),   and into the zone plate layer    (52) for
                                    11

accommodation treatment;        images projected at the projecting
layer  (56)  receive mask blocking from background light at the
occlusion layer     (54)  and are projected forward into the zone
plate layer (52)     for accommodation treatment.     The combination
of these, or the associated perception of the augmented reality
to the user,   is  very close to "true 3-D".
      Figures 12A-12B depict another embodiment wherein an
imaging module    (58)   comprises high-resolution   mini projector
oriented at an angle approximately perpendicular to the visual
axis of the eye;       a waveguide comprising a substrate guided
delay exit pupil expander device        (70) magnifies and redirects
the image from the small mini projector and into the zone plate
layer  (52);   the occluding layer (54) provides similar masking
functions to protect perception of the projected images from
background lighting.
      Figures 13A-13B depict another embodiment elements 52 and
70 are combined such that the zone plate and projecting layer
are essentially housed within the same integrated module          (72)
which intakes a small image from the mini projector        (68),
redirects and magnifies it, and also diffracts it, for passage
to the eye;    the occluding layer      (54) provides similar masking
functions to protect perception of the projected images from
background lighting.
      Various exemplary embodiments of the invention are
described herein.      Reference is  made to these examples in   a non
limiting sense. They are provided to illustrate more broadly
applicable aspects of the invention. Various changes may be made
to the invention described and equivalents may be substituted
without departing from the true spirit and scope of the
invention. In addition, many modifications may be made to adapt
a particular situation,      material,   composition of matter,
                                      12

process, process act(s) or step(s) to the objective(s),  spirit
or scope of the present invention. Further, as will be
appreciated by those with skill in the art that each of the
individual variations described and illustrated herein has
discrete components and features which may be readily separated
from or combined with the features of any of the other several
embodiments without departing from the scope or spirit of the
present inventions. All such modifications are intended to be
within the scope of claims associated with this disclosure.
     The invention includes methods that may be performed using
the subject devices. The methods may comprise the act of
providing such a suitable device. Such provision may be
performed by the end user. In other words, the "providing" act
merely requires the end user obtain, access, approach, position,
set-up, activate, power-up or otherwise act to provide the
requisite device in the subject method. Methods recited herein
may be carried out in any order of the recited events which is
logically possible, as well as in the recited order of events.
     Exemplary aspects of the invention, together with details
regarding material selection and manufacture have been set forth
above. As for other details of the present invention, these may
be appreciated in connection with the above-referenced patents
and publications as well as generally known or appreciated by
those with skill in the art. The same may hold true with respect
to method-based aspects of the invention in terms of additional
acts as commonly or logically employed.
     In addition, though the invention has been described in
reference to several examples optionally incorporating various
features, the invention is not to be limited to that which is
described or indicated as contemplated with respect to each
variation of the invention. Various changes may be made to the
                                13

invention described and equivalents (whether recited herein or
not included for the sake of some brevity) may be substituted
without departing from the true spirit and scope of the
invention. In addition, where a range of values is provided, it
is understood that every intervening value, between the upper
and lower limit of that range and any other stated or
intervening value in that stated range, is encompassed within
the invention.
     Also, it is contemplated that any optional feature of the
inventive variations described may be set forth and claimed
independently, or in combination with any one or more of the
features described herein. Reference to a singular item,
includes the possibility that there are plural of the same items
present. More specifically, as used herein and in claims
associated hereto, the singular forms "a,"   "an,"  "said," and
"the" include plural referents unless the specifically stated
otherwise. In other words, use of the articles allow for "at
least one" of the subject item in the description above as well
as claims associated with this disclosure. It is further noted
that such claims may be drafted to exclude any optional element.
As such, this statement is intended to serve as antecedent basis
for use of such exclusive terminology as   "solely,"  "only" and
the like in connection with the recitation of claim elements, or
use of a "negative" limitation.
     Without the use of such exclusive terminology, the term
"comprising" in claims associated with this disclosure shall
allow for the inclusion of any additional element--irrespective
of whether a given number of elements are enumerated in such
claims, or the addition of a feature could be regarded as
transforming the nature of an element set forth in such claims.
Except as specifically defined herein, all technical and
                                14

scientific terms used herein are to be given as broad a commonly
understood meaning as possible while maintaining claim validity.
     The breadth of the present invention is not to be limited to
the examples provided and/or the subject specification, but
rather only by the scope of claim language associated with this
disclosure.
     Throughout this specification and the claims which follow,
unless the context requires otherwise, the word "comprise",    and
variations such as "comprises" or "comprising", will be
understood to imply the inclusion of a stated integer or step or
group of integers or steps but not the exclusion of any other
integer or step or group of integers or steps.
     The reference in this  specification to any prior publication
(or information derived from it),    or to any matter which is
known, is not, and should not be taken as,    an acknowledgement or
admission or any form of suggestion that that prior publication
(or information derived from it)   or known matter forms part of
the common general knowledge in the field of endeavour to which
this specification relates.
                                  15

The claims defining the                 invention are as follows:
1.    A     three-dimensional                      image            visualization                  system,
      comprising:
      a.   a     selectively               transparent              projection             device        for
           projecting an image toward an eye of a viewer from a
           projection             device       position          in   space       relative          to   the
           eye       of      the       viewer,         the       projection            device         being
           capable           of       assuming           a     substantially               transparent
           state when no image is projected;
      b.   an     occlusion            mask     device         coupled       to     the      projection
           device          and      configured             to     selectively            block        light
           traveling            toward the           eye     from one         or more          positions
           opposite           of    the     occlusion           mask     from the           eye     of   the
           viewer         in     an     occluding          pattern        correlated            with     the
           image projected by the projection device;                                        and
      c.   an      integrated              module          coupled         to      the       projection
           device comprising:
                     a    diffraction            waveguide            element         configured          to
                filter            by       trapping             within         the         diffraction
                waveguide             element         at     least      a     first        diffraction
                order of light of the image based on a mode, and
                     a     zone         plate        diffraction             patterning              device
                interposed             between        the      eye    of    the     viewer        and    the
                diffraction              waveguide          element       configured            to    cause
                at     least        a    second       diffraction            order       of     light     of
                the      image         from     the      projection           device         to    have     a
                simulated             focal      distance           from      the      eye      based     at
                least in part upon a selectable geometry.
2.    The   system        of     claim      1,    further           comprising          a    controller
      operatively          coupled         to    the      projection           device,         occlusion
      mask    device,           and      the     integrated            module         configured          to
      coordinate           projection             of        the      image        and        associated
                                                   16

    occluding        pattern,         as      well    as   interposition               of      the
    diffraction pattern at the                   selectable geometry.
3.  The     system of       claim     2,    wherein     the   controller            comprises
    a microprocessor.
4.  The     system     of      claim      1,   wherein     the    projection             device
    comprises        a     substantially           planar      transparent             digital
    display substantially occupying a display plane.
5.  The      system     of     claim      4,    wherein    the     display          plane         is
    oriented       substantially             orthogonal     to     a    visual        axis        of
    the eye of the viewer.
6.  The     system of       claim     4,    wherein     the   substantially              planar
    transparent         digital       display       comprises        a   liquid        crystal
    display.
7.  The     system of       claim     4,    wherein     the   substantially              planar
    transparent         digital       display       comprises        an    organic          light
    emitting diode display.
8.  The     system of       claim     1,    wherein     the projection             device         is
    configured         to    project        the   image     toward        the      eye       in      a
    collimated form such that the depth of focus for                                   the eye
    of the viewer is              an infinite depth of focus.
9.  The    system of claim 1, wherein the diffraction waveguide
    element       comprises         a    substrate-guided          delay        exit        pupil
    expander       device         configured       to   expand       the     size       of     the
    image before delivery to the eye of the viewer.
10. The      system     of       claim     9,    wherein     a    mini-projector                  is
    mounted      substantially             perpendicularly         to     a    visual         axis
    of    the    eye    of      the   viewer,      and    wherein        the      substrate
    guided delay exit pupil expander device is                              configured to
                                              17

    receive the image from the mini-projector                         and deliver     it
    to    the    zone  plate       diffraction        patterning       device    and  to
    the      eye   of  the     viewer          in  the    expanded     size     with  an
    orientation       substantially              aligned     with   the  visual     axis
    of the      eye.
11. The     system of claim 1, wherein the occlusion mask device
    comprises       a display configured to either occlude or pass
    light at each of a plurality of portions of the display,
    depending       upon     a   pertinent         command       to occlude     or  pass
    light at each portion.
12. The     system of claim 1, wherein the occlusion mask device
    comprises one or more liquid crystal displays.
                                             18

<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
