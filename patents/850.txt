                                          Abstract
  A method for providing position information for controlling at least one function of a
  vehicle provided with a vehicle coordinate system comprises the steps of receiving
  image information associated with at least one image of at least one part of the vehicle
5 captured by a camera of a mobile device, the mobile device being separate from the
  vehicle, determining a position associated with the mobile device in the vehicle
  coordinate system according to the image information associated with the at least one
  image, and providing position information indicative of the position associated with
  the mobile device in the vehicle coordinate system to control at least one function of
0 the vehicle according to the position. There is also provided a method and system
  which provides movement information indicative of a movement associated with the
  mobile device relative to the vehicle coordinate system to control at least one function
  of the vehicle according to the movement.
                                               1

                                                1
              Method and system for providing position or movement information
                          for controlling at least one function of a vehicle
 5
   The present disclosure is related to a method and system for providing position or move
   ment information for controlling at least one function of a vehicle.
   In current times, modem vehicles like cars have various systems or functions that are ad
10 justable for certain positions inside the vehicle in order to have a desired performance. For
    example, a sound system of a car interior can be adjusted to optimize the sound experience
   for drivers sitting in the front seat and passengers sitting in the passenger seat and/or back
    seats. The same is the case for systems like ambient light systems and climate systems of a
   vehicle. Users sometimes may have problems to specify a position in 3D space for adjust
15  ing one or more functions of such systems and, thus, rarely do it. Particularly, it is chal
   lenging or even not possible for a user to specify a desired position inside the car for ad
   justing or controlling such systems of the car. Furthermore, changing from one desired po
    sition to another desired position inside the car is also challenging for the user.
20 Zhang et al. in reference [1] propose a method for self-calibration of camera positions rela
    tive to a ground plane for a camera attached to a vehicle. They solve a problem that the
   height of the attached camera depends on the load of the vehicle, which will change from
   time to time. Their method determines a height of the camera above the ground while the
   vehicle is moving. They first define a ground plane in camera coordinates according to two
25 image features in at least two camera images, and then determine a height of the camera
   above the ground, in which determining the camera height includes calculating an inner
   product between a mean of the featured points and a norm of the ground plane.
   Breed in reference [7] discloses a method for obtaining information about an occupying
30  item in a vehicle. The method requires images of an area in the vehicle in which the occu
   pying item may be situated and employs a trained neural network to classify the item in the
   images.
   Breed et al. in reference [8] propose to acquire images of an occupant or occupying item in
35 a vehicle from a single camera arranged in the vehicle; and analyze the images acquired
   from the single camera to determine a classification of the occupant or occupying item.

                                                2
   Grossmann et al. in reference [2] disclose determining a camera position relative to a dis
   play device according to images of visual contents displayed on the display device cap
   tured by the camera. Osman in reference [3] proposes a method for locating a camera of a
   gaming console relative to a display device. He discloses determining a camera position
 5 relative to a display device by analyzing images of visual contents displayed on the display
   device captured by the camera. However, references [2, 3] do not motivate to mount the
   display device to a vehicle and to control a function of the vehicle based thereon.
   It is an object of the invention to provide a method and system which enables a user to pro
10 vide information which is appropriate for controlling at least one function of a vehicle
   based on a position or movement.
   According to a first aspect, there is provided a method for providing position information
   for controlling at least one function of a vehicle provided with a vehicle coordinate system,
15 the method comprising receiving image information associated with at least one image of
   at least one part of the vehicle captured by a camera of a mobile device, the mobile device
   being separate from the vehicle, determining a position associated with the mobile device
   in the vehicle coordinate system according to the image information associated with the at
   least one image, and providing position information indicative of the position associated
20 with the mobile device in the vehicle coordinate system to control at least one function of
   the vehicle according to the position.
   The invention can advantageously make use of the fact that modem vehicles often com
   prise, e.g., a display device mounted inside the vehicle at a known position relative to the
25 vehicle and toward drivers and/or passengers sitting in the car, and that a personal mobile
   device, such as a mobile phone or tablet computer, often comprises a camera.
   According to the present invention, at least one function of a vehicle may be controlled
   based on a determined position associated with a mobile device comprising a camera,
30 which position is determined by using the camera to capture at least one image of a part of
   the vehicle. For example, the captured part of the vehicle includes a visual content dis
   played on a display device mounted to the car. In this way, the invention provides a meth
   od and system which enables a user to determine a position inside a vehicle for controlling
   at least one function of the vehicle based on the determined position. For example, a func
35 tion of a sound system, a lighting system and/or an air conditioning of the vehicle may be
   controlled according to the position of the mobile device.

                                                 3
   To this end, according to an embodiment, the invention proposes to determine a position of
   a mobile device in a coordinate system of a vehicle by using, for example, a display device
   mounted to the vehicle, a camera of the mobile device, and images of visual contents dis
   played on the display device captured by the camera of the mobile device. Furthermore, at
 5 least one function of the vehicle is controlled based on the determined position. For exam
   ple, the function is related to a sub-system of the vehicle, such as a sound system, an ambi
   ent light system, an air conditioning system, or their combination.
   According to an embodiment, the method further comprises providing or receiving a posi
10 tion of the at least one part of the vehicle in the vehicle coordinate system.
   According to an embodiment, the at least one part of the vehicle comprises a visual content
   displayed on a display device mounted to the vehicle.
15 According to an embodiment, determining the position associated with the mobile device
   in the vehicle coordinate system comprises determining a camera position of the camera
   relative to the at least one part of the vehicle when capturing the at least one image accord
   ing to the image information associated with the at least one image, and determining the
   position associated with the mobile device in the vehicle coordinate system according to
20 the camera position and the position of the at least one part of the vehicle in the vehicle
   coordinate system.
   According to a further embodiment, the at least one image is a first image and the camera
   is a first camera, and determining the position associated with the mobile device in the ve
25 hicle coordinate system comprises receiving image information associated with a second
   image of the at least one part of the vehicle captured by a second camera of the mobile de
   vice, and reconstructing a model of the at least one part of the vehicle according to the im
   age information associated with the first and second images.
30 In a further development, the method further comprises receiving image information asso
   ciated with a third image captured by a third camera of the mobile device, wherein the
   third image captures at least a part of the vehicle represented by at least part of the recon
   structed model (this at least a part of the vehicle could be different from the at least one
   part of the vehicle mentioned above; however, the at least a part of the vehicle is included
35 in the reconstructed model), determining a camera position of the third camera relative to
   the reconstructed model when capturing the third image according to the at least part of the
   reconstructed model and image information associated with the third image, and determin-

                                                 4
   ing the position associated with the mobile device in the vehicle coordinate system accord
   ing to the camera position of the third camera.
   According to an embodiment, the method further comprises determining a camera position
 5 of the first camera relative to the at least one part of the vehicle when capturing the first
   image according to at least part of the image information associated with the first image,
   and determining a camera position of the second camera relative to the at least one part of
   the vehicle when capturing the second image according to at least part of the image infor
   mation associated with the second image.
10
   According to a further development, the at least one part of the vehicle is a first part of the
   vehicle, and the method further comprises receiving image information associated with a
   fourth image captured by a fourth camera of the mobile device, wherein the fourth image
   captures at least part of the first part of the vehicle and at least a second part of the vehicle,
15 and extending the reconstructed model to include the first part of the vehicle and the sec
   ond part of the vehicle.
   Preferably, the reconstructed model at least describes depth information of at least part of
   the vehicle.
20
   According to an embodiment, at least two of the first camera, the second camera, the third
   camera, and the fourth camera are the same camera.
   According to another embodiment, at least two of the first camera, the second camera, the
25 third camera, and the fourth camera are different cameras.
   According to an embodiment, the at least one function is a function which is related to at
   least one of a sound system of the vehicle, an ambient light system of the vehicle, and an
   air conditioning system of the vehicle, and which is controlled according to the position.
30
   According to the first aspect, there is also provided a system for providing position infor
   mation for controlling at least one function of a vehicle provided with a vehicle coordinate
   system, the system comprising a first processing device configured to receive image in
   formation associated with at least one image of at least one part of the vehicle captured by
35 a camera of a mobile device, the mobile device being separate from the vehicle, the first
   processing device configured to determine a position associated with the mobile device in
   the vehicle coordinate system according to the image information associated with the at

                                               5
   least one image, and a second processing device configured to provide position informa
   tion indicative of the position associated with the mobile device in the vehicle coordinate
   system to control at least one function of the vehicle according to the position.
 5 According to a second aspect, there is provided a system for providing movement informa
   tion for controlling at least one function of a vehicle provided with a vehicle coordinate
   system, comprising a first processing device configured to receive image information asso
   ciated with at least two images captured by at least one camera of a mobile device, the mo
   bile device being separate from the vehicle, and each of the at least two images capturing
10 at least one part of the vehicle, the first processing device configured to determine a
   movement associated with the mobile device relative to the vehicle coordinate system ac
   cording to the image information associated with the at least two images, and a second
   processing device configured to provide movement information indicative of the move
   ment associated with the mobile device relative to the vehicle coordinate system to control
15 at least one function of the vehicle according to the movement.
   The following embodiments as well as other embodiments described herein are equiva
   lently applicable in connection with, both, the first and second aspect.
20 According to an embodiment, the first processing device and the second processing device
   are the same processing device.
   According to an embodiment, at least one of the first and second processing devices is
   comprised in the mobile device. According to another embodiment, at least one of the first
25 and second processing devices is comprised in the vehicle. According to a further em
   bodiment, at least one of the first and second processing devices is comprised in a com
   puter device which communicates with the mobile device and the vehicle.
   According to the second aspect, there is also provided a method for providing movement
30 information for controlling at least one function of a vehicle provided with a vehicle coor
   dinate system, the method comprising receiving image information associated with at least
   two images captured by at least one camera of a mobile device, the mobile device being
   separate from the vehicle, each of the at least two images capturing at least one part of the
   vehicle, determining a movement associated with the mobile device relative to the vehicle
35 coordinate system according to the image information associated with the at least two im
   ages, and providing movement information indicative of the movement associated with the

                                               6
   mobile device relative to the vehicle coordinate system to control at least one function of
   the vehicle according to the movement.
   According to an embodiment, the movement associated with the mobile device relative to
 5 the vehicle coordinate system can be determined according to two positions associated
   with the mobile device in the vehicle coordinate system. The two positions associated with
   the mobile device can be determined according to the image information associated with
   the at least two images respectively. The at least one part of the vehicle captured in the
   each of the at least two images may have common parts or be different.
10
   According to a further embodiment, the movement associated with the mobile device rela
   tive to the vehicle coordinate system can be determined according to two camera positions
   of the at least one camera while capturing the at least two images.
15 Aspects and embodiments of the invention described above or in the following with re
   spect to the first aspect related to determining positions associated with the mobile device
   can equivalently also be applied to the second aspect related to determining a movement
   associated with the mobile device.
20 According to an embodiment, the movement associated with the mobile device relative to
   the vehicle coordinate system can be determined according to image positions of the at
   least one part of the vehicle captured in the each of the at least two images. This requires
   that the at least one part of the vehicle captured in the each of the at least two images are
   same or have common parts. However, this does not require known positions of the at least
25 one part of the vehicle in the vehicle coordinate system.
   According to the present invention, at least one function of a vehicle may be controlled
   based on a determined movement associated with a mobile device. For example, a func
   tion of a sound system, a lighting system and/or an air conditioning of the vehicle may be
30 controlled according to the movement of the mobile device. The movement may be used to
   change volume of the sound system. The lighting system may change a current illuminated
   position to a new illuminated position according to the determined movement of the mo
   bile device. For example, the determined movement may define how far away from the
   current illuminated position to the new illuminated position. In another example, the de
35 termined movement may define a rotation such that the lighting system may rotate from a
   current illuminating direction to a new illuminating direction according to the rotation.

                                              7
   Preferably, the mobile device is a hand held device, such as a mobile phone, a tablet com
   puter or a mobile computer.
   For example, the at least one part of the vehicle has a position in the vehicle coordinate
 5 system which could be provided by the manufacturer of the vehicle.
   The at least one part of the vehicle captured in an image could be any physical part of the
   vehicle. The at least one part of the vehicle may include a display device mounted to the
   vehicle or a part of the display device. The at least one part of the vehicle may further in
10 clude one or more visual contents displayed on the display device.
   The display device is a device for visually presenting of information. The display device
   could be based on any displaying technologies or materials, such as Cathode ray tube
   (CRT), Light-emitting diode display (LED) and Liquid crystal display (LCD). The display
15 device may include a 2-dimensional planar display or a display having a curved shape. The
   display device may also be a foldable display device comprising multiple planar sub
   displays, each of which could be moved with others.
   The display device may be mounted to the vehicle. It is preferred to be mounted towards
20 eyes of drivers and/or passengers sitting in the vehicle, such that the drivers and/or passen
   gers could see visual contents displayed on the display device. For example, the display
   device may be mounted on a front control panel of the vehicle, or mounted on a back of a
   front seat of the vehicle.
25 The display device could be used to display menus, maps, graphical user interfaces of soft
   ware programs, etc.
   The visual content is any visually perceivable information to anatomical eyes or optical
   imaging devices. For example, the visual content may emit or reflect visible light that
30 could be captured by human eyes or cameras. The visual content may also emit or reflect
   invisible light that could be not captured by human eyes, but could be captured by a cam
   era. The visual content could be a text, a figure, an image generated by computers or cap
   tured by cameras, a symbol, a drawing, their combinations, or a part of each of them. For
   example, the visual content may be a menu, a button, an icon, a digital map, a graphical
35 user interface of a software program, their combinations, or a part of each of them. The
   visual content can be displayed on the display device.

                                                 8
   The mobile device is portable and comprises one or more cameras. The one or more cam
   eras may have known positions relative to the mobile device. The mobile device could on
   ly be a camera. For example, the mobile device is any of the camera, the first camera, the
   second camera, the third camera, and/or the fourth camera, i.e. the mobile device and the
 5 respective camera are the same device.
   In one embodiment, the mobile device may have at least one processing device, such as a
   computing processor. In another embodiment, the mobile device may not have a computing
   processor, but may have a transmitter to transmit data (e.g. image data of images captured
10 by the camera) to another device (e.g. the vehicle). The mobile device could be, but is not
   limited to, a mobile phone, a tablet computer, or a laptop. The camera may be separate
   from the mobile device, but communicate with the mobile device via a cable or wirelessly.
   The one or more cameras are optical imaging devices that could capture imagery informa
15 tion of optical information.
   The proposed invention can be applied with any camera providing images. It is not re
   stricted to cameras providing color images in the RGB format. It can also be applied to any
   other color format and also to monochrome images, for example, to cameras providing im
20 ages in grayscale format. The camera may further provide an image with depth data. The
   depth data does not need to be provided in the same resolution as the (color/grayscale) im
   age. A camera providing an image with depth data is often called RGB-D camera. A RGB
   D camera system could be a time of flight (TOF) camera system. The camera may also
   capture light that is invisible to human eye, such as infrared light. For example, the camera
25 may be a thermal imaging camera.
   A position of a camera in the vehicle coordinate system may include translations, or rota
   tions, or their combination, in the vehicle coordinate system.
30 A visual appearance of the displayed visual content describes shape, texture, geometry or
   their combinations. The visual appearance may or may not include color information.
   A physical geometry of an object describes size, shape, dimension, planarity, or their com
   binations of the object as it is in the real world.
35
   A resolution of the display device is the number of distinct pixels in each dimension that
   can be displayed on its display area. The display device may have a known resolution. The

                                               9
   display device may further have a known physical geometry for its display area. The phys
   ical geometry of the display device refers to the physical geometry of the display area of
   the display device. Having the pixel position of the displayed visual content in a coordi
   nate system of the display device, and the resolution and the physical geometry of the dis
 5 play device, a spatial relationship between the displayed visual content and the display
   device can be determined. This defines a position of the displayed visual content relative
   to the display device. Further, a physical geometry of the displayed visual content can also
   be determined. The position of the displayed visual content in the vehicle coordinate sys
   tem may be determined according to the position of the displayed visual content relative to
10 the display device and a position of the display device relative to the vehicle coordinate
   system.
   A camera position of the camera relative to the at least part of the vehicle while the first
   image is captured by the first camera can be determined according to at least part of the
15 image. Having a physical geometry of the at least part of the vehicle, various vision based
   camera position estimation methods, such as based on 2D-3D point correspondences (see,
   e.g., reference [9]), can be employed to determine the camera position.
   Particularly, it is preferred to have the at least part of the vehicle to include a displayed
20 visual content. The image of the camera thus captures the displayed visual content. The
   visual content could provide rich texture and features (e.g. contrasting corners or edges),
   which will make vision based camera position estimations robust. In this example, the
   camera position of the camera can be determined relative to the display device mounted to
   the vehicle. A position of the display device relative to the vehicle coordinate system could
25 be provided from the vehicle manufacturer, for example.
   Having the known visual appearance of the displayed visual content and its physical ge
   ometry, a camera position of the camera relative to the visual content can be determined
   with a correct scale factor according to at least part of the image information of the first
30 image. Camera position estimation could be based on correspondences between image fea
   tures of the captured image and corresponding features of the visual content displayed on
   the display device. The camera position in the vehicle coordinate system is then deter
   mined according to the camera position relative to the displayed visual content and the po
   sition of the displayed visual content in the vehicle coordinate system.
35
   The camera position of the camera in the vehicle coordinate system while the camera cap
   tures the image can be determined from the camera position relative to the at least one part

                                                10
   of the vehicle and the position of the at least one part of the vehicle in the vehicle coordi
   nate system.
   In one example, the position of the camera in the vehicle coordinate system could deter
 5 mine the position that can be provided to the vehicle to control the at least one function of
   the vehicle. The position associated with the mobile device may be the same as the posi
   tion of the camera in the vehicle coordinate system. The position associated with the mo
   bile device may have a displacement in space from the position of the camera in the vehi
   cle coordinate system.
10
   In another example, the position of the camera in the vehicle coordinate system may not be
   appropriate to specify the position associated with the mobile device. For example, the
   position of the camera may not be a desired position to be provided to the vehicle to con
   trol the at least one function.
15
   According to an embodiment, the present invention proposes to further capture a second
   image of the at least one part of the vehicle by a second camera of the mobile device (with
   the previously described camera and image being a first camera and first image, respec
   tively). The second image and the first image are captured when the second camera and the
20 first camera are at different positions.
   A camera position of the second camera relative to the at least one part of the vehicle
   while the second image is captured may be determined according to the at least part of the
   second image. The disclosed method of determining the camera position of the first camera
25 may also be used to determine the camera position of the second camera.
   A model of at least one part of the vehicle may be reconstructed according to the first and
   second images and the camera positions of the first and second cameras.
30 In one embodiment of reconstructing the model, correspondences between image features
   of the at least one part of the vehicle in the first and second images are determined. Then, a
   triangulation method can be used to determine the model from the image feature corre
   spondences and the camera positions of the first camera and second camera, see for exam
   ple reference [9].
35

                                              11
   A model of an object, as described above, at least describes depth information of at least
   part of the object. The model further may include one of the following attributes, but is not
   limited to, shape, symmetry, planarity, geometrical size, color, texture and density.
 5 As the physical geometry of the at least one part of the vehicle captured in the first and
   second images could be known, a correct scale factor for the reconstructed model could be
   determined as taught, e.g., in reference [4]. The reconstructed model can be represented as
   3D vertices, polygonal faces and/or edges spanned by these vertices. Edges and faces of
   the model may also be represented as splines or NURBS surfaces.
10
   The reconstructed model may be determined in the vehicle coordinate system. The recon
   structed model may also be determined in an arbitrary coordinate system, such as its own
   coordinate system. In this case, the reconstructed model can be related to the vehicle coor
   dinate system based on the position of the at least one part of the vehicle in the vehicle
15 coordinate system.
   According to an embodiment, a third camera of the mobile device may capture a third im
   age. The third image includes a part of the vehicle, which is represented by at least part of
   the reconstructed model. The part of the vehicle does not need to include the at least one
20 part of the vehicle captured by the first camera, or includes only a part thereof. Particu
   larly, the part of the vehicle captured in the third image does not need to include the dis
   play device of the vehicle or any visual content displayed on the display device.
   A camera position of the third camera relative to the model while the third image is cap
25 tured may be determined according to at least part of the reconstructed model and at least
   part of the third image. For example, a SLAM method (see reference [4]) could be em
   ployed for determining the camera position of the third camera.
   In one example, the position of the third camera in the vehicle coordinate system while the
30 third camera captures the third image may be used to determine the position associated
   with the mobile device in the vehicle coordinate system. The position associated with the
   mobile device may be the same as the position of the third camera in the vehicle coordinate
   system. The position associated with the mobile device in the vehicle coordinate system
   may have a displacement in space from the position of the third camera in the vehicle co
35 ordinate system.

                                                12
   The camera position of the third camera in the vehicle coordinate system can be deter
   mined from the camera position of the third camera relative to the model and a spatial rela
   tionship between the model and the vehicle coordinate system.
 5 Furthermore, the model can further be used to initialize a vision based Simultaneous Lo
   calization and Mapping (SLAM) method, such as described in references [4,5,6], for track
   ing the camera(s) of the mobile device in the vehicle coordinate system and/or extending
   the reconstructed model by adding other reconstructed parts of the vehicle.
10 For example, a fourth image of at least one second part of the vehicle is captured by a
   fourth camera of the mobile device. The fourth image may further capture a part of the ve
   hicle that is represented by at least part of the reconstructed model. Then, the reconstructed
   model could be extended to have the first part and second part of the vehicle based on the
   SLAM method. This may require to compute a camera pose of the fourth camera relative
15 to the model while capturing the fourth image based on matching image positions of the
   part of the vehicle and the at least part of the reconstructed model of the part of the vehi
   cle.
   The position associated with the mobile device can be determined according to a camera
20 position of a camera of the mobile device in the vehicle coordinate system. The camera
   position could be estimated according to at least part of the reconstructed model and at
   least one image captured by the camera based on the SLAM method. For this, the at least
   one image captures a part of the vehicle represented by the at least part of the recon
   structed model. The position associated with the mobile device may be the same as the
25 position of the camera while the camera captures the at least one image.
   The determined position or the determined movement associated with the mobile device in
   the vehicle coordinate system can be provided to the vehicle to control the at least one
   function of the vehicle according to the position or the movement. The at least one func
30 tion may be related to one or more sub-systems of the vehicle. Sub-systems of the vehicle
   could be, but are not limited to, a sound system, an ambient light system, and an air condi
   tioning system.
   The at least one function could control or configure one or more sub-systems of the vehicle
35 according to the determined position associated with the mobile device in the vehicle co
   ordinate system. For example, the position could specify a center position of an area in
   space where the ambient light system should illuminate or the air conditioning system

                                               13
   should monitor temperature. A listening area could also be specified by the position such
   that the sound system would be controlled or adjusted for orientating it towards the speci
   fied listening area.
 5 The mobile device may communicate with the vehicle directly or via a computer network.
   The mobile device may communicate with the vehicle indirectly via other devices, e.g. via
   a web service computer.
   The computer network may be a telecommunications network that connects processing
10 devices (e.g. computers) to allow communication and data exchange between systems,
   software applications, and users. The processing devices may be connected via cables, or
   wirelessly, or both via cables and wirelessly. For example, the computer network could be
   an Internet, intranet, local area network, or wide area network.
15 In one embodiment, the mobile device may comprise one camera. The first camera, the
   second camera, the third camera, and the fourth camera are the same camera.
   In another embodiment, the mobile device may comprise at least two cameras. At least two
   of the first camera, the second camera, the third camera, and the fourth camera are differ
20 ent cameras.
   In another embodiment, at least two of the first camera, the second camera, the third cam
   era, and the fourth camera are the same camera.
25 Camera intrinsic parameters for the first camera, the second camera, the third camera,
   and/or the fourth camera may be provided or calibrated based on a camera calibration
   method. The camera intrinsic parameters may be used to determine camera positions or
   camera movements based on camera images.
30 In one embodiment, the system according to the invention could be electronically coupled
   with or be a part of the mobile device. It could be separate from the vehicle. The system
   may communicate with the vehicle via cable, wirelessly or via a computer network. The
   system could determine the position or the movement associated with the mobile device in
   the vehicle coordinate system and send the position or the movement to the vehicle for
35 controlling the at least one function.

                                                14
   In a further embodiment, the system could receive vehicle information from the vehicle.
   The vehicle information may include at least one of the vehicle coordinate system, a visual
   appearance of a displayed visual content, a resolution of a display device used for the dis
   play, a position of the display device (i.e. the at least one part of the vehicle) in the vehicle
 5 coordinate system, a physical geometry of the display device (i.e. the at least one part of
   the vehicle), or their combinations.
   In another embodiment, the system could be electronically coupled with or be a part of the
   vehicle and separate from the mobile device. The system may communicate with the mo
10 bile device via cable, wirelessly or via a computer network. The mobile device could send
   camera images to the system. The mobile device may further need to send camera intrinsic
   parameters (e.g. focal length and principal point) to the system. The camera intrinsic pa
   rameters may be used to determine camera positions based on camera images.
15 In another embodiment, the system could be separate from the mobile device and separate
   from the vehicle. The system may communicate with the mobile device and/or the vehicle
   via cable, wirelessly or via a computer network. The system could receive vehicle informa
   tion from the vehicle and receive camera images and camera intrinsic parameters from the
   mobile device. Then, the system could determine the position or the movement associated
20 with the mobile device in the vehicle coordinate system and send the position or movement
   to the vehicle or to one or more sub-systems of the vehicle related to the at least one func
   tion for controlling the at least one function.
   According to another aspect, the invention is also related to a computer program product
25 comprising software code sections which are adapted to perform a method according to the
   invention. Particularly, the computer program product is contained on a computer readable
   medium and is non-transitory. The software code sections may be loaded into a memory of
   one or more of the processing devices as described herein.
30 According to an embodiment, the method may be implemented as an application which
   runs on one or more processing devices of a mobile device, such as a mobile phone, and
   which communicates directly or indirectly with the vehicle.
   According to another embodiment, the method may be implemented as an application
35 which runs on one or more processing devices of the vehicle, and which communicates
   directly or indirectly with the mobile device and/or camera.

                                              15
   According to another embodiment, the method may be implemented as an application
   which runs on one or more processing devices of a computer, such as a mobile computer or
   a personal computer, communicating directly or indirectly with the mobile device and/or
   camera and with the vehicle.
 5
   Aspects and embodiments of the invention will now be described with respect to the draw
   ings, in which:
   Fig. 1      shows a flowchart of an exemplary embodiment of the present invention,
10
   Fig. 2      shows a flowchart of another exemplary embodiment of the present invention,
   Fig. 3      shows an exemplary scene according to an embodiment of the present inven
               tion.
15
   In the following, aspects and embodiments of the invention will be explained with refer
   ence to the exemplary embodiments as shown in Figures 1 to 3. The following embodi
   ments are described with reference to using a mobile phone, but the invention may be ap
   plied in principle with any mobile device which is associated through a specified spatial
20 relationship with a camera for capturing images.
   Fig.3 shows an exemplary scene of a vehicle environment, in which a part of the vehicle
   3001 includes a front control panel 3009 and a light source 3007. A display device com
   prises a screen 3004 mounted to the front control panel 3009. A potential visual content
25 displayed on the screen 3004 is a 2D map 3005, but may also be any other visual content.
   A vehicle coordinate system 3006 is associated to the vehicle 3001.
   In the exemplary scene shown in Fig.3, the mobile device as used herein is a mobile phone
   3002 that comprises a camera 3003. Camera intrinsic parameters of the camera 3003 are
30 provided to the mobile device.
   In a potential use scenario, the vehicle 3001 sends vehicle information to the mobile phone
   3002 wirelessly via a computer server. The vehicle information includes at least part of
   imagery information (i.e. visual appearance) of the displayed 2D map 3005, a resolution of
35 the screen 3004, a position of the screen 3004 in the vehicle coordinate system 3006, and a
   shape and size of the screen 3004.

                                              16
   In another embodiment, the screen 3004 may show an iconic outline of the mobile phone
   3002. The iconic outline has a known position in a display coordinate system of the screen
   3004, and thus could also have a known position in the vehicle coordinate system 3006. If
   the camera 3003 has a known position relative to the mobile phone 3002, then the camera
 5 3003 could have a known initial position in the vehicle coordinate system 3006 when the
   mobile phone 3002 is placed on the position indicated by the iconic outline on the screen
   3004. This initial position of the camera 3003 in the vehicle coordinate system 3006 may
   be used for tracking the camera 3003 and/or reconstructing a part of the vehicle 3001. A
   position of the camera 3003 may be determined relative to its own initial position, i.e. de
10 termining a motion of the camera 3003, for example based on inertial sensors attached to
   the camera 3003 or based on corresponding image features between two images captured
   by the camera 3003. Thus, the camera 3003, and accordingly the mobile phone 3002 asso
   ciated with the camera 3003, can be tracked in the vehicle coordinate system 3006.
15 The mobile device, here mobile phone 3002, has at least one or more processing devices,
   such as one or more microprocessors and associated circuitry, which are commonly used in
   the art and not shown in the Figures, since they are internal to the mobile phone 3002. An
   internal processing device is indicated with reference number 3011 in Fig. 3. Among other
   tasks as commonly used and applied in the art, with regard to the present invention the pro
20 cessing device 3011 is configured to communicate with the camera 3003 and to perform
   tasks and steps as described herein in connection with the invention, such as the steps as
   described with reference to Figs. 1 and 2. In this example, the mobile phone 3002 may be
   held by a user. Camera intrinsic parameters of the camera 3003 are provided to the proc
   essing device 3011 or may be determined by a camera calibration procedure.
25
   Moreover, the vehicle 3001 may comprise at least one or more processing devices, such as
   one or more microprocessors and associated circuitry, which are commonly used in the art
   and designated in Fig. 3 with reference number 3021. Among other tasks as commonly
   used and applied in the art, with regard to the present invention the processing device 3021
30 is configured to display the visual content 3005 on the screen 3004. The processing device
   3021 is further applicable to perform tasks and steps as described herein in connection
   with the invention, such as the steps as described with reference to Figs. 1 and 2.
   According to an embodiment, each of the processing devices 3011 and/or 3021, or in any
35 combination with each other, is appropriate and may be configured to perform any of the
   steps according to the invention as described herein, such as to receive image information
   associated with images captured by a camera (such as camera 3003) directly from the cam-

                                               17
   era or from another processing device, to determine a position associated with the mobile
   device in the vehicle coordinate system according to the received image information, and
   to provide position information indicative of the position associated with the mobile device
   in the vehicle coordinate system. For example, such position information may be provided
 5 to a control device of the vehicle via direct communication, or indirectly via another proc
   essing device (such as a server computer), to control at least one function of the vehicle
   according to the position.
   These tasks and steps may also be performed by another one or more processing devices,
10 such as processing device 4001, which is neither contained in the mobile phone 3002 nor
   in the vehicle 3001, but in another device, such as a server computer 4000, communicating
   with the mobile phone 3002 and the vehicle 3001, e.g. wirelessly over a computer network.
   Further, it is possible that all or some of the tasks and steps according to the invention as
   described herein may be shared or distributed between the processing devices 3011, 3021
15 and 4001.
   The camera 3003 and the housing of the mobile phone 3002 have fixed positions relative
   to each other. A spatial relationship between the camera 3003 and any part of the mobile
   phone 3002 may be provided by the manufacturer of the mobile phone 3002 or may be cal
20 ibrated as commonly known in the art.
   Turning now to the process as described with reference to Fig. 1, in the exemplary em
   bodiment of the invention as shown in Fig.1, a display device mounted to the vehicle,
   which is provided with a vehicle coordinate system, displays a figure on its screen in step
25 1001, such as a visual content in the form of a 2D map 3005 as shown in Fig. 3. The vehi
   cle sends vehicle information from the vehicle to the mobile phone that comprises a cam
   era via Internet in step 1002. The camera of the mobile phone captures an image of the
   figure displayed on the display device in step 1003. In the exemplary scene shown in Fig.3,
   the camera 3003 captures an image of the displayed 2D map 3005. The image may include
30 only a part of the displayed 2D map 3005.
   Step 1004 determines, in this embodiment on the mobile phone, a camera position in the
   vehicle coordinate system while the camera captures the image. In the exemplary scene
   shown in Fig.3, a camera position of the camera 3003 in the vehicle coordinate system
35 3006 while the camera 3003 captures the image can be determined, which is performed on
   the processing device 3011 of mobile phone 3002 according to received image information
   associated with the captured image. The determination of the camera position could be

                                              18
   based on matching the image captured by the camera 3003 and the imagery information of
   the 2D map 3005 received at the mobile phone 3002. From the determined camera posi
   tion, the position associated with the mobile device 3002 in the vehicle coordinate system
   3006 may be determined which may be used as an input for controlling at least one func
 5 tion of the vehicle. A known spatial relationship between the camera 3003 and any part of
   the mobile device 3002 may be used for this determination.
   Step 1005 sends the determined camera position from the mobile phone to the vehicle. In
   the exemplary scene shown in Fig.3, the camera position of the camera 3003 in the vehicle
10 coordinate system 3006 is provided from the mobile phone 3002 to the vehicle 3001.
   The vehicle then may control at least one function of the vehicle according to the received
   camera position in step 1006. In the exemplary scene shown in Fig.3, the processing device
   3021 of vehicle 3001 may control an illuminating direction of the light source 3007. The
15 light source 3007 could be directed to illuminate the area 3008 along a direction defined
   by the camera position of the camera 3003.
   Fig. 2 shows a flowchart of another exemplary embodiment. Step 2001 displays a figure on
   a display device mounted to a vehicle provided with a vehicle coordinate system. The ve
20 hicle sends vehicle information to a mobile phone that comprises a camera in step 2002.
   The camera of the mobile phone captures a first image of the displayed figure in step 2003.
   Step 2004 determines, on the mobile phone, a camera position P1 in the vehicle coordinate
   system while the camera captures the first image according to the first image and the dis
   played figure. In step 2005, the camera, i.e. the mobile phone, is moved to another position
25 that is different from the position Pl. The camera of the mobile phone captures a second
   image of the displayed figure in step 2006. Step 2007 determines, on the mobile phone, a
   camera position P2 in the vehicle coordinate system while the camera captures the second
   image according to image information of the second image and the displayed figure. Step
   2008 reconstructs a model of at least part of the vehicle on the mobile phone based on the
30 image information of the first image and the second image and the camera positions P1 and
   P2. This could be realized using a triangulation method, as e.g. disclosed in reference [9].
   In step 2009, the camera is moved. The camera captures a third image in step 2010. Step
   2011 determines, on the mobile phone, a camera position P3 in the vehicle coordinate sys
35 tem while the camera captures the third image according to the model. This could be im
   plemented based on a SLAM method, see e.g. reference [4]. In step 2012, it is determined
   if the position P3 is a desired position. The desired position indicates that a user wants to

                                               19
   configure or control a function of the vehicle according to the desired position. For exam
   ple, the user may read a book. The desired position may indicate a center position of an
   area around the book where an ambient light system of the vehicle should illuminate. If it
   is not a desired position, then go to step 2008, and extend the model according to the third
 5 image using, e.g., the SLAM method (see, e.g., reference [4]). On the other hand, if it is
   the desired position, then send the position P3 from the mobile phone to the vehicle (step
   2013). The vehicle is then capable to control at least one function of the vehicle according
   to the received position P3 (step 2014).
10 The steps and system components as described above related to the first aspect of a method
   and system for providing position information for controlling at least one function of a ve
   hicle may analogously be applied with same or similar components in connection with the
   second aspect of a method and system for providing movement information for controlling
   at least one function of a vehicle, with the   modification of providing image information
15 associated with at least two images captured   by at least one camera of a mobile device, and
   the following steps considering this image     information as described above. Further, the
   components, such as mobile device, camera,     and/or processing devices, as described above
   may also be configured to perform the method of the second aspect for providing move
   ment information for controlling at least one function of a vehicle.
20
   Throughout this document it is described that image information associated with an image
   is provided or received. It is known to the skilled person that this may include providing or
   receiving any processed or non-processed information (version) of an image, part of an
   image and/or features of an image which allows for position or pose estimation. The inven
25 tion does not require providing or receiving any raw image data. Processing thereby in
   cludes any one of compression (e.g. JPEG, PNG, ZIP), encryption (e.g. RSA encryption,
   Schnorr signature, EI-Gamal encryption, PGP), conversion to another color space or gray
   scale, cropping or scaling the image or conversion into a sparse representation based on
   feature descriptors, extraction, and their combinations. All these image processing meth
30 ods can optionally be performed and are covered by the terminology of image information
   of or associated with an image.
   References:
35
   1.   US 8 373 763 B1
   2.   US 2012/0287287 A

                                          20
   3. WO 2011/075226 Al
   4.  Davison, Andrew J., et al. "MonoSLAM: Real-time single camera SLAM." Pattern
      Analysis and Machine Intelligence, IEEE Transactions on 29.6 (2007): 1052-1067.
   5.  Strasdat, Hauke, J. M. M. Montiel, and Andrew J. Davison. "Scale drift-aware large
 5    scale monocular SLAM." Proceedings of Robotics: Science and Systems (RSS). Vol.
      2. No. 3. 2010.
   6.  Lemaire, Thomas, et al. "Vision-based slam: Stereo and monocular approaches." In
      ternational Journal of Computer Vision 74.3 (2007): 343-364.
   7. US 7 660 437 B1
10 8. US 7 415 126 B1
   9.  Hartley, Richard, and Andrew Zisserman. Multiple view geometry in computer vi
      sion. Vol. 2. Cambridge, 2000.

                                               21
                                               Claims
 5 1. A method for providing position information for controlling at least one function of a
   vehicle (3001) provided with a vehicle coordinate system (3006), the method comprising
   - receiving image information associated with at least one image of at least one part of the
   vehicle (3004) captured by a camera (3003) of a mobile device (3002), the mobile device
   being separate from the vehicle,
10 - determining a position associated with the mobile device (3002) in the vehicle coordinate
   system (3006) according to the image information associated with the at least one image,
   and
   - providing position information indicative of the position associated with the mobile de
   vice (3002) in the vehicle coordinate system (3006) to control at least one function of the
15 vehicle according to the position.
   2. The method according to claim 1, further comprising providing or receiving a position
   of the at least one part of the vehicle (3004) in the vehicle coordinate system (3006).
20 3. The method according to claim 2, wherein the at least one part of the vehicle comprises
   a visual content (3005) displayed on a display device (3004) mounted to the vehicle
   (3001).
   4. The method according to claim 2 or 3, wherein determining the position associated with
25 the mobile device (3002) in the vehicle coordinate system (3006) comprises
   - determining a camera position of the camera (3003) relative to the at least one part of the
   vehicle (3004) when capturing the at least one image according to the image information
   associated with the at least one image, and
   - determining the position associated with the mobile device (3002) in the vehicle coordi
30 nate system (3006) according to the camera position and the position of the at least one
   part of the vehicle (3004) in the vehicle coordinate system (3006).
   5. The method according to one of claims 2 to 3, wherein the at least one image is a first
   image and the camera (3003) is a first camera, and wherein determining the position asso
35 ciated with the mobile device (3002) in the vehicle coordinate system (3006) comprises,
   - receiving image information associated with a second image of the at least one part of the
   vehicle (3004) captured by a second camera (3003) of the mobile device (3002), and

                                                22
   - reconstructing a model of the at least one part of the vehicle (3004) according to the im
   age information associated with the first and second images.
   6. The method according to claim 5, further comprising
 5 - receiving image information associated with a third image captured by a third camera of
   the mobile device (3002), wherein the third image captures at least a part of the vehicle
   represented by at least part of the reconstructed model,
   - determining a camera position of the third camera relative to the reconstructed model
   when capturing the third image according to the at least part of the reconstructed model
10 and image information associated with the third image, and
   - determining the position associated with the mobile device (3002) in the vehicle coordi
   nate system (3006) according to the camera position of the third camera.
   7. The method according to claim 5 or 6, further comprising
15 - determining a camera position of the first camera (3003) relative to the at least one part
   of the vehicle (3004) when capturing the first image according to at least part of the image
   information associated with the first image, and
   - determining a camera position of the second camera relative to the at least one part of the
   vehicle (3004) when capturing the second image according to at least part of the image
20 information associated with the second image.
   8. The method according to one of claims 5 to 7, wherein the at least one part of the vehi
   cle (3004) is a first part of the vehicle and further comprising
   - receiving image information associated with a fourth image captured by a fourth camera
25 of the mobile device (3002), wherein the fourth image captures at least part of the first part
   of the vehicle and at least a second part of the vehicle, and
   - extending the reconstructed model to include the first part of the vehicle and the second
   part of the vehicle.
30 9. The method according to any of claims 5 to 8, wherein the reconstructed model at least
   describes depth information of at least part of the vehicle.
    10. The method according to any of claims 5 to 9, wherein at least two of the first camera,
   the second camera, the third camera, and the fourth camera are the same camera (3003).
35
    11. The method according to any of claims 5 to 9, wherein at least two of the first camera,
   the second camera, the third camera, and the fourth camera are different cameras.

                                              23
   12. The method according to any of claims 1 to 11, wherein the at least one function is a
   function which is related to at least one of a sound system of the vehicle, an ambient light
   system of the vehicle, and an air conditioning system of the vehicle, and which is con
 5 trolled according to the position.
   13. A method for providing movement information for controlling at least one function of
   a vehicle (3001) provided with a vehicle coordinate system (3006), the method comprising
   - receiving image information associated with at least two images captured by at least one
10 camera (3003) of a mobile device (3002), the mobile device being separate from the vehi
   cle, each of the at least two images capturing at least one part of the vehicle,
   - determining a movement associated with the mobile device (3002) relative to the vehicle
   coordinate system (3006) according to the image information associated with the at least
   two images, and
15 - providing movement information indicative of the movement associated with the mobile
   device relative to the vehicle coordinate system (3006) to control at least one function of
   the vehicle according to the movement.
   14. The method according to claim 13, wherein the movement associated with the mobile
20 device (3002) relative to the vehicle coordinate system (3006) is determined according to
   at least two positions associated with the mobile device in the vehicle coordinate system.
   15. The method according to claim 13 or 14, wherein the movement associated with the
   mobile device (3002) relative to the vehicle coordinate system (3006) is determined ac
25 cording to at least two camera positions of the at least one camera (3003) while capturing
   the at least two images.
   16. The method according to one of claims 13 to 15, wherein the movement associated
   with the mobile device (3002) relative to the vehicle coordinate system (3006) is deter
30 mined according to image positions of the at least one part of the vehicle (3004) captured
   in the each of the at least two images.
    17. The method according to one of claims 13 to 16, wherein the at least one function is a
   function controlled based on a determined movement associated with the mobile device,
35 particularly a function which is related to at least one of a sound system, a lighting system
   and an air conditioning of the vehicle controlled according to the movement of the mobile
   device.

                                              24
    18. A system for providing position information for controlling at least one function of a
   vehicle (3001) provided with a vehicle coordinate system (3006), comprising
   - a first processing device (3011, 3021, 4001) configured to receive image information as
 5 sociated with at least one image of at least one part of the vehicle (3004) captured by a
   camera (3003) of a mobile device (3002), the mobile device being separate from the vehi
   cle,
   - the first processing device (3011, 3021, 4001) configured to determine a position associ
   ated with the mobile device (3002) in the vehicle coordinate system (3006) according to
10 the image information associated with the at least one image, and
   - a second processing device (3011, 3021, 4001) configured to provide position informa
   tion indicative of the position associated with the mobile device (3002) in the vehicle co
   ordinate system (3006) to control at least one function of the vehicle (3001) according to
   the position.
15
   19. A system for providing movement information for controlling at least one function of a
   vehicle (3001) provided with a vehicle coordinate system (3006), comprising
   - a first processing device (3011, 3021, 4001) configured to receive image information as
   sociated with at least two images captured by at least one camera (3003) of a mobile de
20 vice (3002), the mobile device being separate from the vehicle, and each of the at least two
   images capturing at least one part of the vehicle,
   - the first processing device (3011, 3021, 4001) configured to determine a movement asso
   ciated with the mobile device (3002) relative to the vehicle coordinate system (3006) ac
   cording to the image information associated with the at least two images, and
25 - a second processing device (3011, 3021, 4001) configured to provide movement informa
   tion indicative of the movement associated with the mobile device relative to the vehicle
   coordinate system (3006) to control at least one function of the vehicle according to the
   movement.
30 20. The system according to claim 18 or 19, wherein the first processing device and the
   second processing device are the same processing device (3011, 3021, 4001).
   21. The system according to one of claims 18 to 20, wherein at least one of the first and
   second processing devices (3011) is comprised in the mobile device (3002).
35
   22. The system according to one of claims 18 to 21, wherein at least one of the first and
   second processing devices (3021) is comprised in the vehicle (3001).

                                            25
   23. The system according to one of claims 18 to 22, wherein at least one of the first and
   second processing devices (4001) is comprised in a computer device (4000) which com
   municates with the mobile device (3002) and the vehicle (3001).
 5
   24. The system according to one of claims 18 to 23, wherein the mobile device (3002) is a
   hand held device, particularly a mobile phone, a tablet computer or a mobile computer.
   25. A computer program product comprising software code sections which are adapted to
10 perform a method according to any of the claims 1 to 17 when loaded into the internal
   memory of a processing device.

<removed-apn> <removed-date>
<removed-apn> <removed-date>
<removed-apn> <removed-date>
